strptime(Sys.Day(),format="day")
strptime(Sys.Date(),format="day")
strptime(Sys.Time(),format="day")
strptime(Sys.Date(),format="day")
format(Sys.Date(),"%d")
currentDay = format(Sys.Date(),"%d")#
currentMonth = format(Sys.Date(),"%m")
currentDat
currentDay
currentMonth
tb[,1]
tb[,1]
which(is.numeric(tb[,1]))
is.numeric(tb[,1])
grep("^[0-9*$]",tb[,1])
workTable= tb[grep("^[0-9*$]",tb[,1]),]
workTable
workTable= tb[grep("^[0-9]*$]",tb[,1]),]
workTable
workTable= tb[grep("^[0-9]*$",tb[,1]),]
workTable
as.Date(currentMonth,format="%m")-1
currentMonth
as.Date(currentMonth,format="%M")
as.Date(currentMonth,format="%M")-1
as.Day(currentMonth,format="%M")-1
Sys.Date()
Sys.Date()-1
Sys.Date()-3
workTable
workTable[,1]
currentDat
currentDay
as.numeric(currentDay)-workTable
as.numeric(currentDay)-as.numeric(workTable)
as.numeric(currentDay)-as.numeric(workTable[,1])
as.numeric(currentDay)-workTable[,1]
as.numeric(currentDay)-as.numeric(as.character(workTable[,1]))
currentMonth
as.Date("12-05")
as.Date("12-05","%m-%d")
as.Date("12-05","%m-%d")
currentDay = format(Sys.Date(),"%d")#
currentMonth = format(Sys.Date(),"%m")#
currentYear = format(Sys.Date(),"%y")#
lastMonth = as.numeric(currentMonth)-1#
lastYear = currentYear#
if(currentMonth == "1") lastMonth = 12#
iif(currentMonth == "1") lastYear = as.numeric(currentYear)-1
if(currentMonth == "1") lastYear = as.numeric(currentYear)-1
workTable= tb[grep("^[0-9]*$",tb[,1]),]#
subtractDays = as.numeric(currentDay)-as.numeric(as.character(workTable[,1]))
as.Date(paste(lastYear,"-",lastMonth,"-",workTable[modifyIndex,1])
)
modifyIndex = c(25:40)
as.Date(paste(lastYear,"-",lastMonth,"-",workTable[modifyIndex,1]))
as.Date(paste(lastYear,"-",lastMonth,"-",workTable[modifyIndex,1],sep=""))
lastYear
currentYear
currentDay = format(Sys.Date(),"%d")#
currentMonth = format(Sys.Date(),"%m")#
currentYear = format(Sys.Date(),"%Y")#
lastMonth = as.numeric(currentMonth)-1#
lastYear = currentYear#
if(currentMonth == "1") lastMonth = 12#
if(currentMonth == "1") lastYear = as.numeric(currentYear)-1
as.Date(paste(lastYear,"-",lastMonth,"-",workTable[modifyIndex,1],sep=""))
subtractDays = as.numeric(currentDay)-as.numeric(as.character(workTable[,1]))#
newDates = Sys.Date()-subtractDays#
if(any(subtractDays<1)){#
	modifyIndex = which(subtractDays<1)#
	changeMonthDates = as.Date(paste(lastYear,"-",lastMonth,"-",workTable[modifyIndex,1],sep=""))#
	newDates[modifyIndex] = changeMonthDates#
}
newDates
workDatOut = workTable
workDatOut[1,]
as.Date(paste(newDates,workDat[,2]))
?as.Time
strtime()
?strptime
?as.Date
format(paste(newDates,workDat[,2]))
format(paste(newDates,workTable[,2]))
format(paste(newDates,workTable[,2]))[1]-1
Sys.time-format(paste(newDates,workTable[,2]))[1]
Sys.time()-format(paste(newDates,workTable[,2]))[1]
format(paste(newDates,workTable[,2]))[1]
?Sys.time()
date(format(paste(newDates,workTable[,2]))[1])
date(format(paste(newDates,workTable[,2])))
format(paste(newDates,workTable[,2]))
dateTime = format(paste(newDates,workTable[,2])) #will prb need mod
workTable[1,]
tb[1,]
tb[2,]
tb[1,]
workTable= tb[grep("^[0-9]*$",tb[,1]),]#
subtractDays = as.numeric(currentDay)-as.numeric(as.character(workTable[,1]))#
newDates = Sys.Date()-subtractDays#
if(any(subtractDays<1)){#
	modifyIndex = which(subtractDays<1)#
	changeMonthDates = as.Date(paste(lastYear,"-",lastMonth,"-",workTable[modifyIndex,1],sep=""))#
	newDates[modifyIndex] = changeMonthDates#
}#
#
dateTime = format(paste(newDates,workTable[,2])) #will prb need mod#
colPull = c(1,3,4,5,6,7,11,16)#
outputTable = workTable[,colPull]#
outputTable[,1] = dateTime
outputTable
convertedTimes = strptime(tb[,2],format="%H:%M")#
selectFirst = which(convertedTimes <strptime(timeToSearch,format="%H:%M"))[1]#
selectSecond = which(convertedTimes==convertedTimes[selectFirst])[2]#
rangeTable = c(selectFirst:selectSecond)#
totalRainfallInPeriod = sum(as.numeric(as.character(tb[rangeTable,16])),na.rm=T)#
#
thisOut = c(timePeriods[1],vagueWeatherDescription[1],currentTextDescription[1],totalRainfallInPeriod)#
fullOut = rbind(thisOut,fullOut)
startDate = as.Data("03-01")
startDate = as.Date("03-01")
startDate = as.Date("2015-03-01")
endDate = rep(as.Date("2015-02-28"),times=10)
startDate-endDate
library(rjson)#
library(XML)#
setwd("~/Desktop/currentWeather")#
#so pass each field center lat lng here in here:#
dat = fromJSON(file="http://forecast.weather.gov/MapClick.php?lat=38.4247341&lon=-86.9624086&FcstType=json")#
#
stationID = dat$currentobservation$id#
stationLocation = c(dat$location$longitude,dat$location$latitude)#
currentObservations = dat$currentobservation#
#
currentTextDescription = dat$data$text[1]#
vagueWeatherDescription = dat$data$weather#
timePeriods = dat$time$startValidTime#
fullOut = c()#
#
timeToSearch = "4:00" #4am, its on military time#
searchTable = paste("Output/",stationID,".csv",sep="")#
if(file.exists(searchTable )==F){#
	#potentially hang on to these tables and re-use the tables without having to re-scrape these too much#
	 nextLevelURL = paste("http://forecast.weather.gov/data/obhistory/",stationID,".html",sep="")#
	 doc = htmlParse(readLines(nextLevelURL))#
	 tableNodes = getNodeSet(doc, "//table")#
	 tb = readHTMLTable(doc=tableNodes[[4]],header=T) #
	 write.csv(tb,paste("Output/",stationID,".csv",sep=""),row.names=F)#
#
 }else{#
 	tb = read.csv(searchTable ,stringsAsFactors=F)#
 }#
currentDay = format(Sys.Date(),"%d")#
currentMonth = format(Sys.Date(),"%m")#
currentYear = format(Sys.Date(),"%Y")#
lastMonth = as.numeric(currentMonth)-1#
lastYear = currentYear#
if(currentMonth == "1") lastMonth = 12#
if(currentMonth == "1") lastYear = as.numeric(currentYear)-1#
#
workTable= tb[grep("^[0-9]*$",tb[,1]),]#
subtractDays = as.numeric(currentDay)-as.numeric(as.character(workTable[,1]))#
newDates = Sys.Date()-subtractDays#
if(any(subtractDays<1)){#
	modifyIndex = which(subtractDays<1)#
	changeMonthDates = as.Date(paste(lastYear,"-",lastMonth,"-",workTable[modifyIndex,1],sep=""))#
	newDates[modifyIndex] = changeMonthDates#
}
dateTime = format(paste(newDates,workTable[,2])) #will prb need mod#
colPull = c(1,3,4,5,6,7,11,16)#
outputTable = workTable[,colPull]#
outputTable[,1] = dateTime
outputTable
ncol(outputTable)
outputTable[1,]
outputTable[1,2]
outputTable[1,3]
list.of.packages = c("rgdal","sp","maptools","alphahull","TSP","mapproj","geosphere","rgeos","rjson","gtools","plyr","XML")#
#
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]#
if(length(new.packages)) install.packages(new.packages)#
#
library(rgdal)#
library(sp)#
library(maptools)#
library(alphahull)#
library(TSP)#
library(mapproj)#
library(geosphere)#
library(rgeos)#
library(rjson)#
library(XML)#
library(plyr)#
library(gtools)
---#
subtractAltitude = F#
#for testing#
#
setwd("~/FlightPlan")#
inputFile = "public/R/Input/MWO.json"#
dat = fromJSON(readLines(inputFile))#
uniqueInputID = "MWO"#
subtractAltitude  =T#
#
#-----#
#
#remove fields with no available fieldBlockGeometry#
realFields = which(unlist(lapply(dat$fields, function(x){ if(is.null(x$cutout)==F){#
		return(T)#
	}else{#
		return(F)#
	}#
}))==T)#
dat$fields = dat$fields[realFields]#
#
pixelWidth = as.numeric(dat$general$resolution)#
turnTime = as.numeric(dat$general$turn_time)#
cameraPixW = as.numeric(dat$general$horizontal_swath_pixels)  ####fix this!!!#
flightSpeed = as.numeric(dat$general$speed)#
flight.range = as.numeric(dat$general$flight_range)#
overlapRatio = as.numeric(dat$general$overlap)#
directionType = dat$general$loopDirection#
turnTime = as.numeric(dat$general$turn_time)#
#lets hard code the minimum and target overlap#
if(length(overlapRatio)<1) overlapRatio = .5#
#
minimumOverlap = .6#
pilotWidthTolerance = .05#
overlapRatio = minimumOverlap+( 2 * pilotWidthTolerance)#
paintWidth = (1-minimumOverlap)#
#
overlapRatio = 1-overlapRatio#
#
if(overlapRatio<0 || length(overlapRatio)<1) stop("overlapRatio is bad")#
#
swathWidth = pixelWidth*cameraPixW#
#need to do something for camera trigger time here, and maybe camera capacity overall#
#
airfield.location = array(dim=c(1,2),c(as.numeric(dat$general$start_airport['lng']),as.numeric(dat$general$start_airport['lat'])))#
airfield.end.location = array(dim=c(1,2),c(as.numeric(dat$general$end_airport['lng']),as.numeric(dat$general$end_airport['lat'])))#
cutOutContainers = list()#
for(cutOutType in c("cutout","alphaHull")){#
	rawDat = list()#
	fieldNames = list()#
	cutOutBlocks = list()#
	cutOutAlphas = list()#
#
	for(i in 1:length(dat$fields)){#
		temp = dat$fields[[i]]#
		rawDat[[i]] = cbind(as.numeric(temp$lng),as.numeric(temp$lat))#
		fieldNames[[i]] = temp$name#
			cutOutRaw = temp[cutOutType]#
			cutOutRaw = as.character(cutOutRaw)#
			splitting = strsplit(cutOutRaw,"\\),\\(")[[1]]#
			cutOutListTrack = list()#
			cutOutIndex = 1#
			#UTMZone_number = ceiling((180+readWKT(cutOutRaw)@polygons[[1]]@labpt[1])/6)#
			#if(readWKT(cutOutRaw)@polygons[[1]]@labpt[2]>0) UTMHemi = "north"#
			#if(readWKT(cutOutRaw)@polygons[[1]]@labpt[2]<0) UTMHemi = "south"#
			UTMZone_number = ceiling((180+airfield.location[1])/6)#
			if(airfield.location[2]>0) UTMHemi = "north"#
			if(airfield.location[2]<0) UTMHemi = "south"#
			for(z in splitting){#
				split2 = strsplit(z,",")#
				input = c()#
				for(temp in split2[[1]]){#
					temp = gsub("[A-z]","",temp)#
					temp = gsub("\\(","",temp)#
					temp = gsub("\\)","",temp)#
					temp = strsplit(temp," ")[[1]]#
					temp = c(as.numeric(temp[1]),as.numeric(temp[2]))#
					input = rbind(input,temp)#
				}#
				input = project(input,paste("+proj=utm +zone=",UTMZone_number," +",UTMHemi," +ellps=WGS84 +datum=WGS84 +units=m +no_defs",sep=""))#
				cutOutListTrack[[cutOutIndex]] = input#
			    cutOutIndex = cutOutIndex+1#
		}#
		cutOutBlocks[[i]] = cutOutListTrack #
	}#
	cutOutContainers[[cutOutType]] = cutOutBlocks#
}#
cutOutBlocks = cutOutContainers[["cutout"]]#
cutOutAlphas = cutOutContainers[["alphaHull"]]#
#
#track the names later when do cheat sheets#
allAirportsArray = rbind(airfield.location,airfield.end.location)#
allAirportsNames= c(dat$general$start_airport['name'],dat$general$end_airport['name'])#
if(length(dat$general$eligible_airport)>0){#
	for(i in 1:length(dat$general$eligible_airports)){#
		temp = dat$general$eligible_airports[[i]]#
		allAirportsArray = rbind(allAirportsArray,c(as.numeric(temp['lng']),as.numeric(temp['lat'])))#
		allAirportsNames= c(allAirportsNames,temp['name'])#
	}#
}#
airportsLatLng = allAirportsArray#
airportsLatLng = cbind(unlist(as.character(allAirportsNames)),airportsLatLng[,1],airportsLatLng[,2]) #also add abbreviation here#
colnames(airportsLatLng) = c("name","lng","lat")#
combineLog = list()#
#
#setwd("~/Desktop/Herrman_FlightPlan/")#
source("public/R/Scripts/scanTime_Estimation_Testing.R")#
keeps = c()#
for(i in 1:length(rawDat)){#
	if(is.array(rawDat[[i]])){#
		if(nrow(rawDat[[i]])>2) keeps = c(keeps,i)#
	}#
}#
#
KMLList = list()#
projected=T#
tempDat = rawDat[keeps]#
tempDat1 = do.call("rbind",tempDat)#
#project the lat lng to an equal area albers projection at the mean lat lng of data set#
if(projected){#
	airfield.location = project(airfield.location,paste("+proj=utm +zone=",UTMZone_number," +",UTMHemi," +ellps=WGS84 +datum=WGS84 +units=m +no_defs",sep=""))#
	airfield.end.location = project(airfield.end.location,paste("+proj=utm +zone=",UTMZone_number," +",UTMHemi," +ellps=WGS84 +datum=WGS84 +units=m +no_defs",sep=""))#
	allP=do.call("rbind",tempDat)[,2]#
	minMaxLat = c(min(allP),max(allP))#
	for(i in 1:length(tempDat)){#
		tempDat[[i]] = project(cbind(tempDat[[i]][,1],tempDat[[i]][,2]),paste("+proj=utm +zone=",UTMZone_number," +",UTMHemi," +ellps=WGS84 +datum=WGS84 +units=m +no_defs",sep=""))#
	}#
	allAirportsArray = project(allAirportsArray ,paste("+proj=utm +zone=",UTMZone_number," +",UTMHemi," +ellps=WGS84 +datum=WGS84 +units=m +no_defs",sep=""))#
}#
rawTemp = tempDat#
#
trackList = list()#
for(i in 1:length(rawTemp)){#
	trackList[[i]] = i#
}#
bounds = do.call("rbind",rawTemp)#
#
centroids = c()#
for(i in 1:length(tempDat)){#
	centerX = mean(tempDat[[i]][,1])#
	centerY = mean(tempDat[[i]][,2])#
	centroids = rbind(centroids,c(centerX,centerY))#
}#
#
originalCent = centroids#
#
#find centroid of each of these fields#
#
clusteringRound = -1#
dontCountList = list()#
#
print("chi")#
allFieldElevationsRaw = unlist(lapply(dat$fields, function(x) x$elevation))#
#
while(T){#
clusteringRound = clusteringRound+1#
#
centroids = c()#
for(i in 1:length(tempDat)){#
	centerX = mean(tempDat[[i]][,1])#
	centerY = mean(tempDat[[i]][,2])#
	centroids = rbind(centroids,c(centerX,centerY))#
}#
#
allFieldElevations =c()#
for(fieldElevTrack in 1:length(trackList)){#
	thisGSD = as.numeric(dat$fields[[trackList[[fieldElevTrack]][1]]]$gsd)#
	flightAltitude = (thisGSD)*cameraPixW/(2*tan(as.numeric(dat$general$viewAngle) *pi/(2*180)))   ####assuming 37 degree view angle#####
#
	allFieldElevations = c(allFieldElevations,(mean(allFieldElevationsRaw[trackList[[fieldElevTrack]]])+flightAltitude))#
	#these need to be flight altitude for given resolution, not just elevation#
}#
#
gsdList = as.numeric(unlist(lapply(trackList,function(x) dat$fields[[x[1]]]$gsd)))#
imagingTimes = list()#
removalList = list()#
clusteredTrack = list()#
for(i in 1:length(tempDat)){#
	dontCountList[[i]] = 0#
	imagingTimes[[i]]=imageTime(tempDat[[i]],F,trackList[[i]],unlist(dontCountList[[i]]),NULL,abridgedTimeEstimate=T)[[1]]#
}#
for(i in 1:length(rawTemp)){#
	removal = unlist(lapply(trackList, function(x) return(x[-which(x==i)])))#
	if(length(removal)<1){#
		time = 0#
	}else{#
		time = imageTime(tempDat[[i]],F,removal,unlist(dontCountList[[i]]),NULL,abridgedTimeEstimate=T)[[1]]#
	}#
		originalCompare = unlist(lapply(trackList, function(x){#
			if(i %in% x){#
			 return(T)#
			 }else{#
			 	return(F)#
			 	}#
			 }#
			)#
		)#
	removalList[[i]]=time#
	clusteredTrack[[i]]= which(originalCompare==T)#
}#
#
clusters = list()#
for(i in 1:length(tempDat)){#
	print(i)#
	thisCenter = centroids[i,]#
	#find closest five#
	clusterPairs = c()#
#
		distances = ((originalCent[,1]-thisCenter[1])^2+(originalCent[,2]-thisCenter[2])^2)^.5#
		#distances = ((centroids[,1]-thisCenter[1])^2+(centroids[,2]-thisCenter[2])^2)^.5#
		#distances = distances[which(distances[selects]<(3*flightSpeed*turnTime))]#
		elevChangePerc = abs((allFieldElevations[i]-allFieldElevations)/allFieldElevations[i]) #this should be a function of AGL, not field elevation#
#
		distances1 = which(distances < (3*flightSpeed*turnTime) & elevChangePerc <=.1 & gsdList ==gsdList[i])#
		distances1 = distances1[-which(distances1 %in% trackList[[i]])]#
		if(length(distances1)<1) next#
		#sortDistances = sort(distances,index.return=T)[[2]]#
		#sortedDistances = sortDistances[-which(sortDistances %in% trackList[[i]])]#
		#if(length(sortedDistances)<1) next#
		#also select fields that have same resolution#
		#selects = sortedDistances[1:min(10,length(sortedDistances))]	#
		#selects = selects[which(distances[selects]<(3*flightSpeed*turnTime)) & which(elevChangePerc[selects]<=.1 ) & which(gsdList[selects] ==gsdList[i])] #and if the field elevation is within 10%j#
		#selects = selects[which(distances[sortedDistances] < (3*flightSpeed*turnTime) & elevChangePerc[selects]<=.1 ) & gsdList[selects] ==gsdList[i])] #and if the field elevation is within 10%j#
		checkDist = distances[distances1]#
		sortDistances = sort(checkDist,index.return=T)[[2]][1:min(10,length(distances1))]#
		selects = distances1[sortDistances]#
		#selects = which(distances[sortedDistances] < (3*flightSpeed*turnTime) & elevChangePerc[selects]<=.1 ) & gsdList[selects] ==gsdList[i]) #and if the field elevation is within 10%j#
#
		#if(any(sortedDistances==0)) sortedDistances = sortedDistances[-which(sortedDistances%in% trackList[[i]])]#
		#selects = which(distances %in% sortedDistances)#
		if(all(is.na(selects))) next#
		for(k in selects){#
			if(k %in% trackList[[i]]) next	#
			#clusterImageTimeAll = imageTime(rbind(tempDat[[i]],tempDat[[k]]),F,c(trackList[[i]],trackList[[k]]),unlist(dontCountList[[i]],dontCountList[[k]]),NULL,abridgedTimeEstimate=T)#
			clusterImageTimeAll = imageTime(rbind(tempDat[[i]],rawDat[[k]]),F,c(trackList[[i]],k),unlist(dontCountList[[i]],dontCountList[[k]]),NULL,abridgedTimeEstimate=T)#
#
			clusterImageTime = clusterImageTimeAll[[1]]#
			removeCompareTime = removalList[[k]]#
			clusterImageTime = clusterImageTime+removeCompareTime #
			individualImageTime = imagingTimes[[i]]+imagingTimes[[clusteredTrack[[k]]]]	#
			#individualImageTime = imagingTimes[[i]]+imagingTimes[[k]]#
			#add the distance of two closest points here#
			checkClosestTwoFromClusterWithout = sum(sort(((centroids[i,1]-centroids[-k,1])^2+(centroids[i,2]-centroids[-k,2])^2)^.5)[2:3])#
			checkClosestTwoFromClusterWith = sum(sort(((centroids[i,1]-centroids[,1])^2+(centroids[i,2]-centroids[,2])^2)^.5)[2:3])#
#
			checkClosestTwoFromField = sum(sort(((originalCent[k,1]-centroids[,1])^2+(originalCent[k,2]-centroids[,2])^2)^.5)[2:3])#
			travelBetweenHeuristic = 0		#
			#print(travelBetweenHeuristic)#
			if(clusterImageTime<(individualImageTime+travelBetweenHeuristic)){#
				clusterPairs = rbind(clusterPairs,c(i,k,individualImageTime-clusterImageTime))#
			}#
		}#
		if(is.array(clusterPairs)){#
			colnames(clusterPairs) = c("Current Location","Point to Combine","Time Savings")#
		}#
		clusters[[i]] = clusterPairs#
#
	}#
	temp = do.call("rbind",clusters)#
	if(is.null(temp)==T) {#
		break#
	}#
	if(nrow(temp)==1){#
		#print("wut")#
		combine = temp[1:2]#
		combine = array(dim=c(1,2),combine)#
	}else{#
		#print("why here12")#
		temp = temp[order(temp[,3],decreasing=T),]#
		thisOne = temp[1,1:2]#
		combine = c()#
		combine = rbind(combine,thisOne)#
		while(T){#
			temp = temp[apply(temp[,1:2],1,function(x) any(x %in% thisOne)==F),]#
			if(is.array(temp)==F) break#
			if(nrow(temp)<1) break#
			thisOne = temp[1,1:2]#
			combine = rbind(combine,thisOne)#
		}#
	}#
	combineLog[[clusteringRound+1]] = combine#
	print("one combine loop done")#
	print(combine)#
	tCombine = combine#
	combineRemoves = c()#
	for(i in 1:nrow(tCombine)){#
		if(length(trackList[[tCombine[i,1]]])<1){#
			combineRemoves = c(combineRemoves,i)#
			next#
		}#
		if(trackList[[tCombine[i,1]]]==tCombine[i,2]){#
			combineRemoves = c(combineRemoves,i)#
			next#
		}#
		removeFrom = tCombine[i,2]#
		trackList = lapply(trackList,function(x) #
			if(removeFrom %in% x){ #
			return(x[-which(x==removeFrom)])#
			}else{#
				return(x)#
				}#
		)#
		if(any(lapply(trackList, function(x) length(x)<1))==F) combineRemoves = c(combineRemoves,i)#
			#trackList[[tCombine[i,1]]] = c(trackList[[tCombine[i,1]]],trackList[[tCombine[i,2]]])#
		trackList[[tCombine[i,1]]] = c(trackList[[tCombine[i,1]]],removeFrom)#
	}#
	trackList = trackList[unlist(lapply(trackList,function(x) return(length(x)>0)))]#
#
	lastTemp = tempDat#
#
	tempDat = list()#
	for(i in 1:length(trackList)){#
		tempDat[[i]] = do.call("rbind",rawTemp[trackList[[i]]])	#
		#tempDat[[i]] = do.call("rbind",lastTemp[trackList[[i]]])	#
	}#
	if(length(combineRemoves)){#
		combine = combine[-combineRemoves,]#
	}#
	if(is.array(combine)){#
		}else{#
		break	#
	}#
}#
#
if(projected){ #
	KMLList[["projected"]] = tempDat#
	}else{#
	KMLList[["latLng"]] = tempDat#
}#
tempDat = KMLList[["projected"]] #
centroids = c()#
for(i in 1:length(tempDat)){#
	centerX = mean(tempDat[[i]][,1])#
	centerY = mean(tempDat[[i]][,2])#
	centroids = rbind(centroids,c(centerX,centerY))#
}#
airportArray = as.data.frame(allAirportsArray)#
allPoints = cbind(paste("A",0:(nrow(airportArray)-1),sep=""),airportArray,0)#
#cameraPixW = 7348#
#swathWidth = pixelWidth*cameraPixW#
colnames(allPoints) = c("i","Lng","Lat","scanTime")#
for(i in 1:length(tempDat)){#
	flightDat = imageTime(tempDat[[i]],T,trackList[[i]],unlist(dontCountList[[i]]),NULL)#
	flightPlan = flightDat[[1]]#
	scanTime = flightDat[[2]]#
	exitStrat = rbind(flightPlan[1:2,],flightPlan[nrow(flightPlan),],flightPlan[(nrow(flightPlan)-1),])#
	exitStrat = exitStrat[duplicated(exitStrat)==F,]#
#
	rownames(exitStrat)=NULL#
	temp = cbind(as.character(i),as.data.frame(exitStrat),scanTime)#
	colnames(temp) = c("i","Lng","Lat","scanTime")#
#
	rownames(temp) = NULL#
	#temp = as.data.frame(temp)#
#
	allPoints = rbind(allPoints,temp)#
}#
#
rownames(allPoints) = 1:nrow(allPoints)#
#
distances = array(dim=c(nrow(allPoints),nrow(allPoints)))#
for(DistI in 1:nrow(distances)){#
	for(DistJ in 1:nrow(distances)){#
		distances[DistI,DistJ] = (((allPoints[DistI,2]-allPoints[DistJ,2])^2+(allPoints[DistI,3]-allPoints[DistJ,3])^2)^.5)/flightSpeed+allPoints[DistJ,4] #scan time#
	}#
}#
#
#need to add the flyover time here to distances#
#need a list that denotes exit/entry pairs (if enter in southwest corner of a flight plan with odd number of pairs, will leave from northwest), if even number of pairs, will leave from southwest#
#
dontCountListOld = dontCountList#
dontCountList = list()#
for(i in 1:length(trackList)){#
	sendDat = do.call("rbind",rawTemp[trackList[[i]]])#
	#colnames(sendDat) = c("Lng","Lat")#
	#dontCountList[[i]] = unique(imageTime(sendDat,F,i,0))[[2]]		#
}#
#
rownames(distances) = allPoints[,1]#
colnames(distances) = allPoints[,1]#
#send it over to basic TSP now
library(TSP)#
library(RColorBrewer)#
library(gtools)#
library(XML)#
library(plyr)#
source("public/R/Scripts/calculateEntryExit_2.R") #2 is simpler/better#
source("public/R/Scripts/rXLSXTesting.R")#
source("public/R/Scripts/scanTime_Estimation_Testing.R")#
#
if(file.exists(paste("public/R/Output/",uniqueInputID,sep=""))==F) dir.create(paste("public/R/Output/",uniqueInputID,sep=""))#
#
setDirection = function(directionType,inputPathDir){#
	firstPointInPath = inputPathDir[2]#
	lastPointInPath = inputPathDir[length(inputPathDir)-1]#
#
	fPP = centroids[as.numeric(firstPointInPath),]#
	lPP = centroids[as.numeric(lastPointInPath),]#
	sPP = airfield.location[1,]#
	testDirection = sum(c(fPP[2]+sPP[2])*(fPP[1]-sPP[1]),(lPP[2]+fPP[2])*(lPP[1]-fPP[1]),(sPP[2]+lPP[2])*(sPP[1]-lPP[1]))#
	#a negative sum is ccw, positive is clockwise#
	if(testDirection < 0){#
		if(directionType=="clockwise"){#
			inputPathDir = rev(inputPathDir)#
		}#
	}#
	if(testDirection > 0){#
		if(directionType !="clockwise"){#
			inputPathDir = rev(inputPathDir)#
		}#
	}#
	return(inputPathDir)#
}#
leadInDistanceCalculation = function(thisFieldPlan){#
	leadInDistance = 0 #m#
	majorSlope =lm(thisFieldPlan[1,]~thisFieldPlan[2,])$coef[2]	#move entry point ~4000 ft back#
#
	if(is.na(majorSlope)){#
		if(thisFieldPlan[2,2]>thisFieldPlan[1,2]){#
			thisFieldPlan[1,2] = thisFieldPlan[1,2]-leadInDistance#
		}else{#
			thisFieldPlan[1,2] = thisFieldPlan[1,2]+leadInDistance#
			}#
	}else if(majorSlope == 0){#
		if(thisFieldPlan[2,1]>thisFieldPlan[1,1]){#
			thisFieldPlan[1,1] = thisFieldPlan[1,1]-leadInDistance#
		}else{#
			thisFieldPlan[1,1] = thisFieldPlan[1,1]+leadInDistance#
			}#
	}else{#
		extendMajorSlope = (thisFieldPlan[2,2]-thisFieldPlan[1,2])/(thisFieldPlan[2,1]-thisFieldPlan[1,1])#
		xOffset = (leadInDistance^2/(1+extendMajorSlope^2))^.5#
		if(thisFieldPlan[2,1]>thisFieldPlan[1,1]) xOffset = -1*xOffset#
		#xOffset = (1000^2-(1000*extendMajorSlope)^2)^.5#
		yOffset = (leadInDistance^2-xOffset^2)^.5#
		if(thisFieldPlan[2,2]>thisFieldPlan[1,2]) yOffset = -1*yOffset#
			thisFieldPlan[1,1] = thisFieldPlan[1,1]+xOffset#
			thisFieldPlan[1,2] = thisFieldPlan[1,2]+yOffset#
		}#
	return(thisFieldPlan)#
}#
#
dilateFieldGeometry = function(geom,trackListIndex,targetSpeed){#
	if(F){#
		temp = gsub("[A-z]","",geom)#
		allCutouts = strsplit(temp,"\\),\\(")[[1]]#
		polygons = list()#
		for(k in 1:length(allCutouts)){#
			temp = gsub("\\(","",allCutouts[[k]])#
			temp = gsub("\\)","",temp)	#
			points = strsplit(temp,",")[[1]]#
			temp = do.call("rbind",strsplit(points," "))#
			polygonMatrix = matrix(ncol=2,cbind(as.numeric(temp[,1]), as.numeric(temp[,2])))#
			UTMZone_number = ceiling((180+polygonMatrix[1,1])/6)#
			if(polygonMatrix[1,2]>0) UTMHemi = "north"#
			if(polygonMatrix[1,2]<0) UTMHemi = "south"#
			polygonMatrix = project(polygonMatrix,paste("+proj=utm +zone=",UTMZone_number," +",UTMHemi," +ellps=WGS84 +datum=WGS84 +units=m +no_defs",sep=""))#
			#x= Polygons(list(Polygon(polygonMatrix)),1)#
			#tempProjection = CRS(paste("+proj=utm +zone=",UTMZone_number," +",UTMHemi," +ellps=WGS84 +datum=WGS84 +units=m +no_defs",sep=""))#
			#SpatialX = SpatialPolygons(list(x),proj4string = tempProjection)#
			polygons[[length(polygons)+1]] = Polygon(polygonMatrix)#
		}#
		x= Polygons(polygons,1)#
		tempProjection = CRS(paste("+proj=utm +zone=",UTMZone_number," +",UTMHemi," +ellps=WGS84 +datum=WGS84 +units=m +no_defs",sep=""))#
		SpatialX = SpatialPolygons(list(x),proj4string = tempProjection)#
		SpatialDataX = SpatialPolygonsDataFrame(SpatialX,as.data.frame(1:length(SpatialX)))#
	}#
	#expandedGeoms = list()#
	#for(i in 1:length(polygons)){#
	SpatialX = readWKT(geom)#
	tempPosition = SpatialX@polygons[[1]]@labpt#
	UTMZone_number = ceiling((180+tempPosition[1])/6)#
	if(tempPosition[2]>0) UTMHemi = "north"#
	if(tempPosition[2]<0) UTMHemi = "south"#
	proj4string(SpatialX) = "+proj=longlat +datum=WGS84"#
#
	tempProjection = CRS(paste("+proj=utm +zone=",UTMZone_number," +",UTMHemi," +ellps=WGS84 +datum=WGS84 +units=m +no_defs",sep=""))#
    SpatialX = spTransform(SpatialX,tempProjection)#
	#proj4string(SpatialX) = tempProjection #
	yRaw = gBuffer(SpatialX,byid=F,width=0) #fix self intersects...	#
	swathWidth = min(as.numeric(unlist(lapply(dat$fields,function(x) x$gsd))[trackList[[trackListIndex]]]))*cameraPixW#
	#make this swath width field specific#
	#y = gBuffer(yRaw,byid=F,width=swathWidth*.5) #<--imaging area ask yuan to be sure####, make it half a swath width boundary#
	y = gBuffer(yRaw,byid=F,width=(max(swathWidth*overlapRatio,targetSpeed *.51444444*5)))  #imaging boundary is 5 seconds of flying distance at target speed or 1/2 swath width, whichever is bigger#
	z = gBuffer(yRaw,byid=F,width=3000) #3000m usually#
	field50MBuffer = gBuffer(yRaw,byid=F,width=swathWidth*overlapRatio)#
	#field50MBuffer = gBuffer(yRaw,byid=F,width=swathWidth*.2)#
	#add a 50m buffered boundary here#
	dilatedOutput = spTransform(y,CRS("+proj=longlat +datum=WGS84"))#
	dilatedOutputZone = spTransform(z,CRS("+proj=longlat +datum=WGS84"))#
	field50MBuffer = spTransform(field50MBuffer,CRS("+proj=longlat +datum=WGS84"))#
	#	expandedGeoms[[i]] = y#
	#}#
	if(F){#
		polygonVector = c()#
		for(y in expandedGeoms){#
			temp = y@polygons[[1]]@Polygons[[1]]@coords#
			latLng = project(temp,paste("+proj=utm +zone=",UTMZone_number," +",UTMHemi," +ellps=WGS84 +datum=WGS84 +units=m +no_defs",sep=""),inv=T)#
			temp = paste(apply(latLng,1,function(x) paste(x,collapse=" ")),collapse=",")#
			polygonVector = c(polygonVector,temp)#
		}#
		dilatedOutput = paste("MULTIPOLYGON(((",paste(polygonVector,collapse="),("),")))",sep="")#
	}#
	#plot(readWKT(geom),xlim= readWKT(geom)@bbox[1,],ylim= readWKT(geom)@bbox[2,],col="green")#
	#par(new=T)#
	#plot(readWKT(dilatedOutput),,xlim= readWKT(geom)@bbox[1,],ylim= readWKT(geom)@bbox[2,])#
	thisOut = list()#
	thisOut[[1]] = writeWKT(dilatedOutput)#
	thisOut[[2]]= writeWKT(dilatedOutputZone)#
	thisOut[[3]]= writeWKT(field50MBuffer)#
#
	return(thisOut)	#
}#
#
#outputJSON[[i-1]] = createAppJSON(route[i],i,MSLAltitude,allFieldsInCluster,magneticBearingAlt[1],magneticBearingAlt[2],flightAltitude,trueBearing) #
#
createAppJSON = function(i,order,altitudeInfo,allFieldsInCluster,bearingStart,bearingAlt,flightAltitude,trueBearing){#
	print("hello")#
	tempClusterList = list()#
	#tempClusterList[["Swath Adjustment"]] = paintWidth #
	tempClusterList[["Flight Order"]] = order-1#
	tempClusterList[["Flight Altitude MSL"]] = list()#
	#tempClusterList[["Flight Altitude AGL"]] = list()#
	tempClusterList[["Ground Level"]] = list()#
	roundTo50 = function(number){#
		return(50*floor((as.numeric(number))/50+.5))#
	}#
	altitudeInfo = as.numeric(altitudeInfo)/3.28#
	AGLAltitude = as.numeric(flightAltitude)/3.28 #
#
	thisGSD = min(as.numeric(unlist(lapply(dat$fields,function(x) x$gsd)))[trackList[[as.numeric(i)]]])#
#
	if(subtractAltitude & thisGSD == .09) {#
		altitudeInfo = altitudeInfo- 675#
		AGLAltitude  =AGLAltitude -675#
	}#
#
	#mslFeet = as.numeric(altitudeInfo)/3.28#
	#mslFeet = (50*floor(mslFeet/50+.5)) #round to nearest 50#
	tempClusterList[["Flight Altitude MSL"]][["Target"]] = altitudeInfo #units#
	#tempClusterList[["Flight Altitude AGL"]][["Target"]] = as.numeric(flightAltitude)/3.28 #units#
	#AGLAltitude=  as.numeric(flightAltitude)/3.28 #units#
	#if(subtractAltitude & thisGSD == .09)	AGLAltitude = AGLAltitude-692#
	tempClusterList[["Ground Level"]][["Value"]] = altitudeInfo -AGLAltitude#
#
	tempClusterList[["Flight Altitude MSL"]][["Unit"]] = "m"#
	#tempClusterList[["Flight Altitude AGL"]][["Unit"]] = "m"#
	tempClusterList[["Ground Level"]][["Unit"]] = "m"#
	altitudeWarningThreshold = AGLAltitude*.05#
	MSLAltitudeMax =tempClusterList[["Flight Altitude MSL"]][["Target"]] + (altitudeWarningThreshold*2)#
	MSLAltitudeMin = tempClusterList[["Flight Altitude MSL"]][["Target"]] - (altitudeWarningThreshold*2)#
	tempClusterList[["Flight Altitude MSL"]][["Max"]] = MSLAltitudeMax#
	#tempClusterList[["Flight Altitude AGL"]][["Max"]] = tempClusterList[["Flight Altitude AGL"]][["Target"]]*1.1#
	tempClusterList[["Flight Altitude MSL"]][["Min"]] =	MSLAltitudeMin#
	#tempClusterList[["Flight Altitude AGL"]][["Min"]] = tempClusterList[["Flight Altitude AGL"]][["Target"]]*.9#
	tempClusterList[["Flight Altitude MSL"]][["Warning Threshold"]] = altitudeWarningThreshold#
	#tempClusterList[["Flight Altitude AGL"]][["Warning Threshold"]] = tempClusterList[["Flight Altitude AGL"]][["Target"]]*.05#
	fieldNamesJSON = dat$fields[trackList[[as.numeric(i)]]]#
	tempClusterList[["Fields in Cluster"]] = lapply(fieldNamesJSON ,function(x) x$name)#
	fieldCutouts = dat$fields[trackList[[as.numeric(i)]]]#
	print("fieldCutouts below")#
	print(fieldCutouts)#
	temps = c()#
	for(z in 1:length(fieldCutouts)){#
		temp = gsub("^MULTIPOLYGON\\(","",fieldCutouts[[z]]$cutout)#
		temp = gsub("(?<=[0-9])\\){3}$","))",temp,perl=T)#
		temp = gsub("^POLYGON","",temp)#
		temps = c(temps,temp)#
	}#
	print(temps)#
	imagingArea = paste("MULTIPOLYGON(",paste(temps,collapse=","),")",sep="")#
	print("image area")#
	print(imagingArea)#
	thisGSD = min(as.numeric(unlist(lapply(dat$fields,function(x) x$gsd)))[trackList[[as.numeric(i)]]])#
	if(thisGSD>.03) {#
		targetSpeed = 110#
		triggerOffset =0#
		}#
	if(thisGSD<=.03) {#
		triggerOffset = 1#
		targetSpeed = 90#
		}#
	imagingAreaDilated = dilateFieldGeometry(imagingArea,as.numeric(i),targetSpeed) #
	#tempClusterList[["Field Boundary"]] = imagingAreaDilated[[3]]#
	tempClusterList[["Imaging Boundary"]] = imagingAreaDilated[[1]]#
	tempClusterList[["Imaging Approach Zone"]] = imagingAreaDilated[[2]]#
	print(imagingArea)#
	print(trackList)#
	#stop("wait")#
	#get center axis points#
	#speed settings#
	tempClusterList[["Speeds"]] = list()#
	tempClusterList[["Speeds"]][["Target"]]= targetSpeed#
	tempClusterList[["Speeds"]][["Max"]] = targetSpeed+10#
	tempClusterList[["Speeds"]][["Warning Threshold"]] = 5#
	tempClusterList[["Speeds"]][["Unit"]] = "knots"#
	tempClusterList[["True to Magnetic Heading Conversion"]] = magneticDeclination #
	triggerRate= (thisGSD * 4899 * .2)/(targetSpeed*.5144444)*1000  #get vertical pixels from dat)#
	if(triggerOffset == 1) triggerRate = triggerRate*2#
	#round up to the nearest 100#
	triggerRate = round(triggerRate)#
#	floor(round(triggerRate)/100)*100#
	triggerRate = (floor(round(triggerRate)/100))*100	#
	#field specific camera settings#
	tempClusterList[["Camera Settings"]] = list()#
	tempClusterList[["Camera Settings"]][["Shutter Speed"]] = 2000#
	tempClusterList[["Camera Settings"]][["F-stop"]] = 1.8#
	tempClusterList[["Camera Settings"]][["ISO"]] = 100#
	tempClusterList[["Camera Settings"]][["Trigger offset"]] = triggerOffset#
	tempClusterList[["Camera Settings"]][["Trigger Rate"]] = triggerRate#
	tempClusterList[["Camera Settings"]][["Lens Angle"]] = as.numeric(dat$general$viewAngle)#
	if(subtractAltitude & thisGSD == .09) 	tempClusterList[["Camera Settings"]][["Lens Angle"]] = 39#
	minWidthMeter = paintWidth * (tempClusterList[["Flight Altitude MSL"]][["Min"]] - (25/3.28) - tempClusterList[["Ground Level"]][["Value"]])*tan(0174532925*.5*tempClusterList[["Camera Settings"]][["Lens Angle"]])#
	targetWidthMeter = paintWidth * (tempClusterList[["Flight Altitude MSL"]][["Target"]] - tempClusterList[["Ground Level"]][["Value"]])*tan(0174532925*.5*tempClusterList[["Camera Settings"]][["Lens Angle"]] )#
	editedMinimumOverlap= minWidthMeter/targetWidthMeter * minimumOverlap #
#
	tempClusterList[["Camera Settings"]][["Overlap Percentage"]] = editedMinimumOverlap  #minimumOverlap#
	#tempClusterList[["Camera Settings"]][["Swath Adjustment"]]=minimumOverlap#
	tempClusterList[["Entry"]] = list()#
	swathWidth = thisGSD*cameraPixW#
#
	createChannels = function(allowedError,thesePoints,entryType){#
			#errorInM = 10#m#
			rectangleList = list()#
			allPolygons = list()#
			rectIndex = 1#
			tempClusterList[["Entry"]][[entryType]][["Imaging Channels"]]=list()#
			channelsList = list()#
			newFieldBordersSide1 = c()#
			newFieldBordersSide2 = c()#
			for(zz in seq(1,nrow(thesePoints),by=2)){#
				tempPoints = thesePoints[c(zz:(zz+1)),]#
				forBorder = thesePoints[c(zz:(zz+1)),]#
				if(rectIndex %% 2 == 0)	forBorder = forBorder[2:1,]#
				vectorAToB = c(forBorder[2,1]-forBorder[1,1],forBorder[2,2]-forBorder[1,2])#
				vectorMagnitude = (vectorAToB[1]^2+vectorAToB[2]^2)^.5#
				moveUpAToB = vectorAToB/(vectorMagnitude/1000)#
				vectorBToA = c(forBorder[1,1]-forBorder[2,1],forBorder[1,2]-forBorder[2,2])#
				moveUpBToA = vectorBToA/(vectorMagnitude/1000)#
				print(tempPoints)#
				newFieldBordersSide1 = rbind(newFieldBordersSide1,forBorder[1,]+moveUpAToB)#
				newFieldBordersSide2 = rbind(newFieldBordersSide2,forBorder[2,]+moveUpBToA)#
				rectanglePoly = SpatialLines(list(Lines(list(Line(tempPoints)),1)))#
				proj4string(rectanglePoly) = paste("+proj=utm +zone=",UTMZone_number," +",UTMHemi," +ellps=WGS84 +datum=WGS84 +units=m +no_defs",sep="")#
#
				rectanglePoly=gBuffer( rectanglePoly,width=errorInM,capStyle="SQUARE")#
				#majorSlope= diff(rev(tempPoints[,2]))/diff(rev(tempPoints[,1]))#
				#minorSlope = -1*((majorSlope)^-1)#
				#xVal = errorInM*cos(atan(minorSlope))#single direction pilot error zone in meters * majorslope#
				#extensionVal = (diff(tempPoints[,2])^2+diff(tempPoints[,1])^2)^.5#
				#rectanglePoly = buildScanRectangle(tempPoints[1,],minorSlope,majorSlope,1,xVal,1,extensionVal,1,1,1)#
				#proj4string(rectanglePoly) = paste("+proj=utm +zone=",UTMZone_number," +",UTMHemi," +ellps=WGS84 +datum=WGS84 +units=m +no_defs",sep="")#
				allPolygons[[rectIndex]] = rectanglePoly@polygons[[1]]@Polygons[[1]]#
	    	       #( 1 - oP ) * 2 * ( minseaAltitude - groundAltitudeInMeters ) * tan(MN_MATH_DegToRad(0.5 * self.currentImagingArea.cameraSettings.lensAngle.doubleValue));#
				rectanglePoly = spTransform(rectanglePoly,CRS("+proj=longlat +datum=WGS84")) #
				#rectangleList[[length(rectangleList)+1]] = rectanglePoly#
				channelsList[[rectIndex]] =  list(order=rectIndex,geom=writeWKT(rectanglePoly))#
#
				#tempClusterList[["Entry"]][[entryType]][["Imaging Channels"]]	[[rectIndex]] = list(order=rectIndex,geom=writeWKT(rectanglePoly))#
				rectIndex = rectIndex+1#
			}#
			borderPoly = SpatialPolygons(list(Polygons(list(Polygon(rbind(newFieldBordersSide1,newFieldBordersSide2[nrow(newFieldBordersSide2):1,],newFieldBordersSide1[1,]))),1)))#
			proj4string(borderPoly) = paste("+proj=utm +zone=",UTMZone_number," +",UTMHemi," +ellps=WGS84 +datum=WGS84 +units=m +no_defs",sep="")#
			spatPoly = SpatialPolygons(list(Polygons(allPolygons,1)))#
			proj4string(spatPoly)= paste("+proj=utm +zone=",UTMZone_number," +",UTMHemi," +ellps=WGS84 +datum=WGS84 +units=m +no_defs",sep="")#
			imagingApproachZone = writeWKT(spTransform(gBuffer(spatPoly,width=1500),CRS("+proj=longlat +datum=WGS84")))#
			#fieldImagingWidth = paintWidth/2 * (tempClusterList[["Flight Altitude MSL"]][["Min"]] - tempClusterList[["Ground Level"]][["Value"]])*tan(0174532925*.5*tempClusterList[["Camera Settings"]][["Lens Angle"]] )#
#
			bufferedFieldBoundaryOut  = writeWKT(spTransform(gBuffer(borderPoly,width=(paintWidth/2)*swathWidth),CRS("+proj=longlat +datum=WGS84")))#
		#	bufferedFieldBoundaryOut  = writeWKT(spTransform(gBuffer(borderPoly,width=fieldImagingWidth),CRS("+proj=longlat +datum=WGS84")))#
			#bufferedFieldBoundaryOut = writeWKT(spTransform(gBuffer(spatPoly,width=overlapRatio*swathWidth),CRS("+proj=longlat +datum=WGS84")))#
#
			return(list(imagingApproach=imagingApproachZone,bufferedFieldBoundary = bufferedFieldBoundaryOut,channels=channelsList))#
		}#
	errorInM = thisGSD*cameraPixW*pilotWidthTolerance#
	for(entryType in c("Sequential","Alternative")){#
		tempClusterList[["Entry"]][[entryType]] = list()#
		if(entryType == "Sequential" ){#
			tempClusterList[["Entry"]][[entryType]][["Magnetic Heading Angle"]] = as.character(as.numeric(bearingStart))#
			tempClusterList[["Entry"]][[entryType]][["Magnetic Heading Reverse Angle"]] = as.character(as.numeric(bearingAlt))#
			tempClusterList[["Entry"]][[entryType]][["True Heading Angle"]] = as.character(as.numeric(trueBearing[1]))#
			tempClusterList[["Entry"]][[entryType]][["True Heading Reverse Angle"]] = as.character(as.numeric(trueBearing[2]))#
			tempClusterList[["Entry"]][[entryType]][["Max Threshold"]] = 4#
			tempClusterList[["Entry"]][[entryType]][["Warning Threshold"]] = 2#
			tempClusterList[["Entry"]][[entryType]][["Threshold"]] = 4#
			#fieldNamesJSON = dat$fields[trackList[[as.numeric(i)]]]#
			#tempClusterList[["Fields_in_Cluster"]] = lapply(fieldNamesJSON ,function(x) x$name)#
			wayPointList = list()#
			#thesePoints = leadInDistanceCalculation(wayPointsByField[[i]])#
			#print("here")#
			#print(i)#
			thesePoints =wayPointsByField[[i]]#
			#errorInM = 10#m#
			returnChannel = createChannels(allowedError,thesePoints,entryType)#
			imagingApproachZone = returnChannel [["imagingApproach"]]#
			tempClusterList[["Entry"]][[entryType]][["Imaging Channels"]] = returnChannel [["channels"]]#
			tempClusterList[["Imaging Approach Zone"]] = imagingApproachZone#
			tempClusterList[["Field Boundary"]] = returnChannel[["bufferedFieldBoundary"]]#
#
			#imagingApproachZone = createChannels(allowedError,thesePoints,entryType)[["imagingApproach"]]#
			#take every pair of points (1-2,3-4),create a line, buffer that line, or just #
			latLngWaypoints = project(thesePoints,paste("+proj=utm +zone=",UTMZone_number," +",UTMHemi," +ellps=WGS84 +datum=WGS84 +units=m +no_defs",sep=""),inv=T)#
		}else{#
			tempClusterList[["Entry"]][[entryType]][["Magnetic Heading Angle"]] = as.character(as.numeric(bearingAlt))#
			tempClusterList[["Entry"]][[entryType]][["Magnetic Heading Reverse Angle"]] = as.character(as.numeric(bearingStart))#
			tempClusterList[["Entry"]][[entryType]][["True Heading Angle"]] = as.character(as.numeric(trueBearing[2]))#
			tempClusterList[["Entry"]][[entryType]][["True Heading Reverse Angle"]] = as.character(as.numeric(trueBearing[1]))#
			tempClusterList[["Entry"]][[entryType]][["Max Threshold"]] = 4#
			tempClusterList[["Entry"]][[entryType]][["Warning Threshold"]] = 2#
			tempClusterList[["Entry"]][[entryType]][["Threshold"]] = 4#
			#fieldNamesJSON = dat$fields[trackList[[as.numeric(i)]]]#
			#tempClusterList[["Fields_in_Cluster"]] = lapply(fieldNamesJSON ,function(x) x$name)#
			wayPointList = list()#
			#thesePoints = leadInDistanceCalculation(apply(wayPointsByField[[i]],2,rev)) #check this //maybe get rid of this...#
			thesePoints = apply(wayPointsByField[[i]],2,rev)#
			#errorInM = 10#m#
#
			returnChannel = createChannels(allowedError,thesePoints,entryType)#
			imagingApproachZone = returnChannel [["imagingApproach"]]#
			tempClusterList[["Entry"]][[entryType]][["Imaging Channels"]] = returnChannel [["channels"]]#
			tempClusterList[["Imaging Approach Zone"]] = imagingApproachZone#
			tempClusterList[["Field Boundary"]] = returnChannel[["bufferedFieldBoundary"]]#
			latLngWaypoints = project(thesePoints,paste("+proj=utm +zone=",UTMZone_number," +",UTMHemi," +ellps=WGS84 +datum=WGS84 +units=m +no_defs",sep=""),inv=T)#
		}#
		fieldTargetPointsOut = findCenterAxisPoints(imagingArea,imagingApproachZone,trackList,i)#
		tempClusterList[["Field Target Points"]] = fieldTargetPointsOut #
#
		for(k in 1:nrow(latLngWaypoints)){#
			temp = list()#
			temp[["order"]] = k-1#
			temp[["lng"]] = latLngWaypoints[k,1]#
			temp[["lat"]] = latLngWaypoints[k,2]#
			wayPointList[[k]] = temp#
		}#
		#find which fieldTargetPointsOut is closest to first latlngwaypoints#
		entryPointTargetSelect = which.min(as.numeric(unlist(lapply(fieldTargetPointsOut,function(x) ((x$lng-latLngWaypoints[1,1])^2+(x$lat-latLngWaypoints[1,2])^2)^.5))))#
		#entry point is going to be shitty for now, just move back 1km from direction of travel	#
		#print(tempClusterList)#
		#tempClusterList[["Entry"]][[entryType]][["Entry Point Location"]] = fieldTargetPointsOut[[entryPointTargetSelect]]#
		tempClusterList[["Entry"]][[entryType]][["Entry Point Location"]] = list()#
		tempClusterList[["Entry"]][[entryType]][["Entry Point Location"]][["lng"]] = latLngWaypoints[1,1]#
		tempClusterList[["Entry"]][[entryType]][["Entry Point Location"]][["lat"]] = latLngWaypoints[1,2]#
		tempClusterList[["Entry"]][[entryType]][["Waypoints"]] = wayPointList#
	}#
	return(tempClusterList)#
}#
horizViewAngle = as.numeric(dat$general$viewAngle) #39.5 #d800 with 50mm lense is 39.5, d3200 is 37, #23 degree for high res corn count#
print("check here pre")#
print(pixelWidth)#
print(horizViewAngle)#
#this has to be calculated on per field basis#
#flightAltitude = (pixelWidth)*cameraPixW/(2*tan(horizViewAngle *pi/(2*180)))   ####assuming 37 degree view angle#####
#flightAltitude = round(flightAltitude*3.28084)#
#
distanceBetweenPasses = pixelWidth*cameraPixW*overlapRatio*3.28084#
sigDigits = 2#
while(T){#
	distanceBetweenPassesRound = signif(distanceBetweenPasses ,digits = sigDigits)#max(2,nchar(round(distanceBetweenPasses))-3)#
	if(abs((distanceBetweenPassesRound-distanceBetweenPasses)/distanceBetweenPasses)<.05){#
		break#
	}else{#
		sigDigits = sigDigits+1#
		}#
}#
airportLat = dat$general$start_airport['lat']#
airportLng=  dat$general$start_airport['lng']#
url = paste("http://www.ngdc.noaa.gov/geomag-web/calculators/calculateDeclination?lat1=",airportLat,"&lon1=",airportLng,"&resultFormat=xml",sep="")#
#
declinationDat = htmlTreeParse(url)#
magneticDeclination = as.numeric(paste(gsub("[^0-9.-]","",declinationDat[[1]][[1]][[1]][[2]][[5]]),collapse=""))#
#for(testing)#
#uniqueInputID = "testing"#
#
combineLinePolygon = function(kmlPolygonOut,testOut,routeID) {#
	out = sapply( kmlPolygonOut@polygons,function(x){#
		kmlPolygon(x,name=as(kmlPolygonOut,"data.frame")[x@ID,"Field_Name"], col="blue",lwd=1.5, border="black")#
		}#
	)#
	lineOut = sapply( testOut@lines,function(x){#
		kmlLine(x,name="Path", col="red",lwd=1.5)#
		}#
	)#
	tf <- paste("public/R/Output/",uniqueInputID,"/Route",routeID,".kml",sep="")#
	kmlFile <- file(tf, "w")#
	cat(kmlPolygon(kmlname="Path")$header, #
	    file=kmlFile, sep="\n")#
	  cat("<Folder><name>Path</name>#
	      <open>1</open>",file=kmlFile,sep="\n")#
	cat(unlist(out["style",]), file=kmlFile, sep="\n")#
	cat(unlist(out["content",]), file=kmlFile, sep="\n")#
	#cat(kmlPolygon()$footer, file=kmlFile, sep="\n")#
	#cat(kmlLine(kmlname="Path")$header, file=kmlFile, sep="\n")#
	cat(unlist(lineOut["style",]), file=kmlFile, sep="\n")#
	cat(unlist(lineOut["content",]), file=kmlFile, sep="\n")#
	cat("</Folder>",file=kmlFile,sep="\n")#
	cat(kmlLine()$footer, file=kmlFile, sep="\n")#
	#kmlLine(obj=testOut, kmlfile=paste("public/R/Output/",uniqueInputID,"/Route",graphIndex,".kml",sep="")#
	close(kmlFile)#
}#
calcBearing = function(bounds){#
	#import all points, find distance between first and second, and second and third and take the first of the longest as two points#
	#distanceTest = c()#
	#for(i in 1:4){#
	#	distanceTest = c(distanceTest,((bounds[i,1]-bounds[i+1,1])^2+(bounds[i,2]-bounds[i+1,2])^2)^.5)#
	#}#
	x = bounds[1,]#
	y = bounds[2,]#
	#x = bounds[which.max(distanceTest),]#
	#y = bounds[which.max(distanceTest)+1,]#
#
	x1 = x[1]#
	y1 = x[2]#
	x2 = y[1]#
	y2 = y[2]#
	dx = x2-x1#
	dy = y2-y1#
	if(dy != 0){#
		temp = atan(dx/dy)*180/pi#
		if(x2>x1){#
			if(y2>y1){#
			}else{#
				temp = 180+temp#
			}#
		}else{#
			if(y2>y1){#
				temp = 360+temp#
			}else{#
				temp = 180+temp	#
			}	#
		}#
	}else{#
		if(x1>x2){#
			temp = 270#
		}else{#
			temp = 90#
		}#
	}#
	if(temp<180) temp1 = temp+180#
	if(temp>=180) temp1 = temp-180#
	return(c(round(temp),round(temp1)))#
}#
#rawCheat = cheatSheet(bestPath[[graphIndex]],boundingBoxesRouteNested[[graphIndex]],routeLengths_wTurns[graphIndex])#
#
cheatSheet = function(route,boundings,routeTime){#
	newList = list()#
	startAirport = matrix(nrow=1,ncol=2,c("Start Airport",allAirportsNames[grep(route[1],allPoints[,1])[1]]))#
	endAirport = matrix(nrow=1,ncol=2,c("End Airport",allAirportsNames[grep(route[length(route)],allPoints[,1])[1]]))#
	flightAltRoundingLevel = 25#
	tempRound = flightAltitude*3.28#
	flightAltitudeOutput = matrix(nrow=1,ncol=2,c("Flight Altitude AGL (ft)",round(tempRound/flightAltRoundingLevel)*flightAltRoundingLevel))#
	hours = floor(routeTime/3600)#
	minutes = round(((routeTime-(hours*3600))/60)) #could be error here#
	if(minutes<10) minutes = paste("0",minutes,sep="")#
	routeTimeOutput= matrix(nrow=1,ncol=2,c("Expected Flight Time",paste(hours,":",minutes,sep="")))#
    distanceBetweenPassesOut = matrix(nrow=1,ncol=2,c("Distance Between Passes (ft)", distanceBetweenPassesRound))#
	fieldOrder = c()#
	abridgedFieldOrder = c()#
	outputJSON = list()#
	for(i in 2:(length(route)-1)){#
#
		pixelWidth = min(as.numeric(unlist(lapply(dat$fields,function(x) x$gsd))[trackList[[as.numeric(route[i])]]]))#
		flightAltitude = (pixelWidth)*cameraPixW/(2*tan(horizViewAngle *pi/(2*180)))   ####assuming 37 degree view angle#####
		flightAltitude = round(flightAltitude*3.28084)#
		#bearing = calcBearing(boundings[[i-1]])#
		flightPlanRaw = imageTime(tempDat[[as.numeric(route[i])]],T,trackList[[as.numeric(route[i])]],NULL,testExitBboxStart[[route[i]]])#
		flightPlan = flightPlanRaw[[1]]#
		tempPt = readWKT(dat$fields[trackList[[as.numeric(route[i])]]][[1]]$alphaHull)@polygons[[1]]@labpt#
		bearing = calcBearing(flightPlan)#
		trueBearing = bearing#
		bearingLat = tempPt[2] #
		bearingLng = tempPt[1]#
		url = paste("http://www.ngdc.noaa.gov/geomag-web/calculators/calculateDeclination?lat1=",bearingLat,"&lon1=",bearingLng,"&resultFormat=xml",sep="")#
		declinationDat = htmlTreeParse(url)#
		magneticDeclination = as.numeric(paste(gsub("[^0-9.-]","",declinationDat[[1]][[1]][[1]][[2]][[5]]),collapse=""))#
		magneticBearing = paste(round(bearing[1]-magneticDeclination),round(bearing[2]-magneticDeclination),sep="/")#
		magneticBearingAlt = c(round(bearing[1]-magneticDeclination),round(bearing[2]-magneticDeclination)) #make sure constrained to 0 360#
		if(any(magneticBearingAlt>360 | magneticBearingAlt<0 )){#
			changeThis = which((magneticBearingAlt>360 | magneticBearingAlt<0 )==T)#
			if(magneticBearingAlt[changeThis]>360) magneticBearingAlt[changeThis]=magneticBearingAlt[changeThis]-360#
			if(magneticBearingAlt[changeThis]<0) magneticBearingAlt[changeThis]=magneticBearingAlt[changeThis]+360#
		}#
		bearingPaste = paste(bearing[1],bearing[2],sep="/")#
		entry = as.numeric(route[i])#
		fieldIds = trackList[[entry]]#
		clusterAlts = dat$fields[fieldIds]#
		elevations = c()#
		warning = ""#
		for(k in clusterAlts){#
			if(is.null(k$elevation)==F){#
				 elevations=c(elevations,k$elevation)#
			}else{#
				warning = "-Warning: At least one field in this cluster had no elevation information"#
			}			#
		}#
		elevations = mean(elevations,na.rm=T) #
		MSLAltitude = elevations+flightAltitude#
		AGLAltitude = MSLAltitude-flightAltitude#
#
		sigDigits = 2#
		footPixel = pixelWidth*3.28#
		while(T){#
			MSLAltitudeRound = signif(MSLAltitude,digits = sigDigits)#
			if(all(abs((((MSLAltitudeRound-elevations)/(cameraPixW/(2*tan(horizViewAngle *pi/(2*180))))) - footPixel)/footPixel) < .05)){#
				MSLAltitudeRound = MSLAltitudeRound#
				break#
			}else{#
				sigDigits = sigDigits+1#
				}####assuming 37 degree view angle#####
			if(sigDigits == nchar(MSLAltitude)){#
				print(MSLAltitude)	#
				print(paste("we have a potential altitude clustering problem, must change altitude in cluster",i-1,sep="")) #
			} #
		}#
		altitudeInfo = paste(MSLAltitudeRound,warning,sep=" ")#
		allFieldsInCluster = paste(fieldNames[trackList[[entry]]],collapse=",")#
		estimatedTimeOverCluster = round(allPoints[which(allPoints[,1]==entry)[1],"scanTime"]/60)#
		#need to get elevation here#
		#need to calculate camera distance for resolution		#
		#fieldOrder = rbind(fieldOrder,c(i-1,allFieldsInCluster,altitudeInfo,bearingPaste,magneticBearing,estimatedTimeOverCluster))	#
		abridgedFieldOrder =  rbind(abridgedFieldOrder,c(i-1,altitudeInfo,magneticBearingAlt[1],magneticBearingAlt[2]))#,estimatedTimeOverCluster))#
		#print(magneticBearingAlt)#
		outputJSON[[i-1]] = createAppJSON(route[i],i,MSLAltitude,allFieldsInCluster,magneticBearingAlt[1],magneticBearingAlt[2],flightAltitude,trueBearing) #
		#need to say elevation of field if available, calculate MSL (based on resolution and aspect ratio, and maybe whatever else you can gleam, asbolute heading, and magnetic heading (if they gave the declination))#
	}#
#
	abridgedFieldOrder = rbind(abridgedFieldOrder,"","","")#
	abridgedFieldOrder = rbind(c("Cluster ID","Flight Altitude (MSL)","Magnetic Heading","Reverse Heading"),abridgedFieldOrder)#
#
	#fieldOrder = rbind(fieldOrder,"","","","")#
	#fieldOrder = rbind(c("Cluster ID","Fields in Cluster","Flight Altitude (MSL)","Absolute Heading","Magnetic Heading","Estimated Time to Image (minutes)"),fieldOrder)#
	#colnames(fieldOrder) = NULL#
	colnames(abridgedFieldOrder) = NULL#
	newList[["header"]] = matrix(ncol=1,"Flight SB Vineyards ex-SBA")#
	newList[["version"]] = matrix(ncol=1,"Version 1")#
	newList[["date"]] = matrix(ncol=2,c(as.character(Sys.Date()+1),"Flight SB Vineayrds Ex Airport Name")) #default next day is flight#
	newList[["startAirport"]] = startAirport#
	newList[["endAirport"]] = endAirport#
	newList[["Order"]] = matrix(ncol=2,c("Order:","List order of flight here"))#
	newList[["Flight Altitude"]] = flightAltitudeOutput#
	newList[["pass distance"]] = distanceBetweenPassesOut#
	if(pixelWidth < .06) {#
		speedDirections = "as slow as possible/comfortable"		#
	}else{#
		speedDirections = "as fast as possible/comfortable"#
		}#
	newList[["SpeedMPH"]] = matrix(ncol=2,c("Speed (mph)",speedDirections)) #in resolution <6, need to figure out caculation here#
	newList[["SpeedKnots"]] = matrix(ncol=2,c("Speed (knots)",speedDirections)) #in resolution <6, need to figure out caculation here#
	newList[["routeTimes"]] = routeTimeOutput#
	newList[["blank1"]] = matrix(ncol=4,nrow=2," ")	#
#
	newList[["fieldOrder"]] = abridgedFieldOrder#
	output = ldply(newList, function(t) as.data.frame(t))#
	#print(output)#
	colnames(output) = NULL#
	rownames(output) = NULL#
	return(list(output,outputJSON))#
	#calculate total time for route, camera distance to meet resolution requirements	#
}#
dontCountList = list()#
for(i in 1:length(tempDat)){	#
	dontCountList[[i]] = 0#
}#
#
#airportArray = rbind(airfield.location)#,c(579598,5039072))#
#allAirports = rbind(airfield.location,c(579598,5039072))#
#
airportArray = as.matrix(airportArray,ncol=2)#
allAirports = airportArray#
centroidsWAir = rbind(airportArray,centroids)#
#centroidsWAir = centroids#
#
centDistances = array(dim=c(nrow(centroidsWAir),nrow(centroidsWAir)))#
centroidsWAir=cbind(centroidsWAir,scanTime=0)#
for(i in (nrow(airportArray)+1):nrow(centroidsWAir)){#
	iMinus = nrow(airportArray)#
	centroidsWAir[i,3] = imageTime(tempDat[[(i-iMinus)]],F,trackList[[i-iMinus]],c(),NULL)[[1]]	#
}#
#
for(DistI in 1:nrow(centDistances)){#
	for(DistJ in 1:nrow(centDistances)){#
	centDistances[DistI,DistJ] = (((centroidsWAir[DistI,2]-centroidsWAir[DistJ,2])^2+(centroidsWAir[DistI,1]-centroidsWAir[DistJ,1])^2)^.5)/flightSpeed+centroidsWAir[DistJ,3] #scan time#
		#so really this is a time array right now		#
	}#
}#
rownames(centDistances) = c(paste("A",0:(nrow(airportArray)-1),sep=""),as.character(1:nrow(centroids)))#
colnames(centDistances) = c(paste("A",0:(nrow(airportArray)-1),sep=""),as.character(1:nrow(centroids)))#
#
for(i in 1:nrow(centDistances)){#
	centDistances[i,i] = 0	#
}#
#
symMatrix = centDistances#
for(DistI in 1:nrow(centDistances)){#
	for(DistJ in 1:nrow(centDistances)){#
	symMatrix [DistI,DistJ] = (((centroidsWAir[DistI,2]-centroidsWAir[DistJ,2])^2+(centroidsWAir[DistI,1]-centroidsWAir[DistJ,1])^2)^.5)/flightSpeed #scan time#
		#so really this is a time array right now		#
	}#
}#
#
rownames(symMatrix) = c(paste("A",0:(nrow(airportArray)-1),sep=""),as.character(1:nrow(centroids)))#
colnames(symMatrix) = c(paste("A",0:(nrow(airportArray)-1),sep=""),as.character(1:nrow(centroids)))#
#
airfieldSelects = colnames(symMatrix)[grep("A",colnames(symMatrix))]#
farmSelects = colnames(symMatrix)[grep("^[0-9]",colnames(symMatrix))]#
#
if(T){#
#
numAirports = nrow(allAirports)#
nonAirportCentroids = matrix(centroidsWAir[-which(centroidsWAir[,"scanTime"]==0),],ncol=3)#
colnames(nonAirportCentroids) = c("V1","V2","scanTime")#
#
toAirportsArray = array(dim=c(nrow(nonAirportCentroids),ncol=numAirports))#
fromAirportsArray = array(dim=c(nrow(nonAirportCentroids),ncol=numAirports))#
#
#nonAirportCentroids = centroidsWAir[-which(centroidsWAir[,"scanTime"]==0),]#
nonAirportCentroids = matrix(centroidsWAir[-which(centroidsWAir[,"scanTime"]==0),],ncol=3)#
#
colnames(nonAirportCentroids) = c("V1","V2","scanTime")#
#
for(DistI in 1:numAirports){#
	for(DistJ in 1:nrow(nonAirportCentroids )){#
	toAirportsArray[DistJ,DistI] = (((nonAirportCentroids[DistJ,2]-allAirports[DistI,2])^2+(nonAirportCentroids[DistJ,1]-allAirports[DistI,1])^2)^.5)/flightSpeed #
	fromAirportsArray[DistJ,DistI] = (((nonAirportCentroids[DistJ,2]-allAirports[DistI,2])^2+(nonAirportCentroids[DistJ,1]-allAirports[DistI,1])^2)^.5)/flightSpeed+nonAirportCentroids[DistJ,3] #scan time#
		#so really this is a time array right now		#
	}#
}#
#
rownames(toAirportsArray) = c(1:nrow(toAirportsArray))#
colnames(toAirportsArray) = paste("A",c(0:(ncol(toAirportsArray)-1)),sep="")#
#
rownames(fromAirportsArray) = c(1:nrow(fromAirportsArray))#
colnames(fromAirportsArray) = paste("A",c(0:(ncol(fromAirportsArray)-1)),sep="")#
}#
#rownames(toAirportsArray) = c(1:nrow(toAirportsArray))#
#colnames(toAirportsArray) = paste("A",c(1:ncol(toAirportsArray)-1),sep="")#
#rownames(symMatrix) = as.character(1:nrow(centDistances)-1)#
#colnames(symMatrix) = as.character(1:nrow(centDistances)-1)#
rawDistances = centDistances#
pathList = list()#
pathDistances = c()#
pathDistList = c()#
#
getDistance = function(path,rawDistances){#
#
	totalPathDistance = 0#
	for(i in 1:(length(path)-1)){#
		totalPathDistance = totalPathDistance+rawDistances[path[i],path[i+1]]#
	}#
	return(totalPathDistance)#
}#
#
splitAt <- function(x, pos) unname(split(x, cumsum(seq_along(x) %in% pos)))#
#overall tsp#
temp = rownames(symMatrix)#
if(length(grep("A",temp))>1 & all(airfield.location == airfield.end.location)){#
	temp = temp[-grep("A[^0]$",temp)]#
	tsp_obj = TSP(symMatrix[unique(temp),unique(temp)])#
	tour = solve_TSP(tsp_obj, method = "2-opt") #investigate differences in these methods#
	temp = labels(tour)#
	#start = grep("A",temp)[1]#
	#locationName = temp[start]#
	#endAdd = temp[start]#
	start = grep("A0",temp)[1]#
	locationName = temp[start]#
	endAdd = c()#
	if(start>1){#
	endAdd=	temp[1:(start-1)]#
	}#
	tempPath= c(temp[start:length(temp)],endAdd,locationName)#
	#tempPath = c(temp[start:length(temp)],endAdd)#
	tour_length = getDistance(tempPath,rawDistances)#
}else if(length(grep("A",temp))>1 & all(airfield.location != airfield.end.location)){#
	#identify start and end 0#
	if(length(grep("A[^(0|1)]$",temp))>0){#
		temp = temp[-grep("A[^(1|0)]$",temp)] #check this#
	}#
	symMatrix["A1",] = Inf #is it row or column#
	symMatrix["A1","A0"] = 0 #is it row or column#
	tsp_obj = ATSP(symMatrix[unique(temp),unique(temp)])#
	tour = solve_TSP(tsp_obj, method = "2-opt") #investigate differences in these methods#
	temp = labels(tour)#
	#start = grep("A",temp)[1]#
	#locationName = temp[start]#
	#endAdd = temp[start]#
	start = grep("A0",temp)[1]#
	locationName = temp[start]#
	endAdd = c()#
	if(start>1){#
	endAdd=	temp[1:(start-1)]#
	}#
	tempPath= c(temp[start:length(temp)],endAdd,locationName)#
	tempPath = tempPath[-length(tempPath)]#
	#tempPath = c(temp[start:length(temp)],endAdd)#
	tour_length = getDistance(tempPath,rawDistances)#
}else{#
#
	tsp_obj = TSP(symMatrix[unique(temp),unique(temp)])#
	tour = solve_TSP(tsp_obj, method = "2-opt") #investigate differences in these methods#
	temp = labels(tour)#
	#start = grep("A",temp)[1]#
	#locationName = temp[start]#
	#endAdd = temp[start]#
	start = grep("A0",temp)[1]#
	locationName = temp[start]#
	endAdd = c()#
	if(start>1){#
	endAdd=	temp[1:(start-1)]#
	}#
	tempPath= c(temp[start:length(temp)],endAdd,locationName)#
	#tempPath = c(temp[start:length(temp)],endAdd)#
	tour_length = getDistance(tempPath,rawDistances)#
}#
print("tour distance")#
print(tour_length)#
#
if(tour_length <= flight.range){#
	if(all(airfield.location == airfield.end.location)) tempPath = setDirection(directionType,tempPath)#
	bestPath = list(tempPath)#
	bestDistance = tour_length#
	distanceByLeg = tour_length#
}else{#
	if(length(grep("A",tempPath))>1){#
		tempPath = tempPath[-grep("A",tempPath)]#
	}#
	flightLegs = 0#
	#need to work on this#
	#problem occured here#
	while(T){#
		flightLegs = flightLegs+1#
		if(F){#
		flightOptions = combinations(length(tempPath)-2,flightLegs)+1  #this used to be combinations(length(tempPath)-1,flightLegs)+1#
		if(flightLegs>1){#
			flightOptions=flightOptions[apply(flightOptions,1,function(x) {#
			all(diff(x)<5)#
			}),]#
		}#
		}#
		print(flightLegs)#
		startSeq = seq(1,length(tempPath),length.out=flightLegs+1)#
		jumpInterval = round((startSeq[2]-startSeq[1])/2)#
#
		midSeq  = startSeq-jumpInterval#
		midSeq = round(midSeq)[2:length(midSeq)]#
		flightOptions= list()#
		buffer = min(jumpInterval,2)#
		for(i in 1:length(midSeq)){#
			endSeqTemp = seq(midSeq[i]-buffer ,midSeq[i]+buffer ,by=1)#
			endSeqTemp = endSeqTemp[which(endSeqTemp > 0 & endSeqTemp < length(tempPath))]#
			temp= cbind(do.call("rbind",rep(flightOptions,(1+(buffer*2)))),sort(rep(endSeqTemp,times=(1+(buffer*2)) ^(i-1))))#
			flightOptions[[1]] = temp#
		}#
		flightOptions = flightOptions[[1]]#
#
		keeps = apply(flightOptions,1,function(x){#
			all(diff(x)>1)#
		})#
		flightOptions = matrix(flightOptions[keeps,],ncol=flightLegs)#
		#need a smarter way of choosing these combos...#
		#flightOptions = flightOptions[-nrow(flightOptions),]#
		#flightOptions = matrix(ncol=flightLegs,flightOptions)#
		distanceList = list()#
		airportOrderList =list()#
#
		for(i in 1:nrow(flightOptions)){#
			tempOptions = flightOptions[i,]#
#
			flightOrders = splitAt(tempPath,tempOptions)#
			distanceCheck = c()#
			airportOrder = c("A0")#
			littleBreak = F#
			for(j in 1:length(flightOrders)){#
				if(littleBreak) break#
				if(length(flightOrders[[j]])>1){#
					pathDist =getDistance(flightOrders[[j]],rawDistances)#
				}else{#
					pathDist = 0#
					}#
				lastAirport = airportOrder[length(airportOrder)]#
				if(j == 1){#
					#has extra stop distance#
					tempDistanceCheck = toAirportsArray[c(flightOrders[[j]][length(flightOrders[[j]])],flightOrders[[j+1]][1]),]#
					which.min(apply(tempDistanceCheck,2,sum))#
					closestAirport = names(which.min(apply(tempDistanceCheck,2,sum)))#
					addDistance = toAirportsArray[flightOrders[[j]][length(flightOrders[[j]])],closestAirport]+fromAirportsArray[flightOrders[[j]][1],"A0"]#
#
					airportOrder = c(airportOrder,closestAirport)#
				}else if(j == length(flightOrders)){#
					addDistance = toAirportsArray[flightOrders[[j]][length(flightOrders[[j]])],"A0"]+fromAirportsArray[flightOrders[[j]][1],lastAirport]#
					airportOrder = c(airportOrder,"A0")#
#
					#start is the last start, #stop is the node airport#
				}else{#
					#just pick the closest current sum#
					tempDistanceCheck = toAirportsArray[c(flightOrders[[j]][length(flightOrders[[j]])],flightOrders[[j+1]][1]),]#
					#which.min(apply(tempDistanceCheck,2,sum))#
					closestAirport = names(which.min(apply(tempDistanceCheck,2,sum)))#
					airportOrder = c(airportOrder,closestAirport)#
					addDistance = toAirportsArray[flightOrders[[j]][length(flightOrders[[j]])],closestAirport]+fromAirportsArray[flightOrders[[j]][1],lastAirport]#
#
					#has variable start and stop#
				}#
				testDistances = pathDist+addDistance#
				if(all(testDistances > flight.range)){#
					testDistances = NULL#
					distanceCheck = rbind(distanceCheck,testDistances)#
#
					littleBreak = T	 #(make this order specific, maybe the first leg can only be an hour, but the second could be 2)#
					break#
				}else{#
					distanceCheck = rbind(distanceCheck,testDistances)#
				}#
			}#
			distanceList[[i]] = distanceCheck#
			airportOrderList[[i]] = airportOrder #
		}#
		if(length(distanceList)<1){#
			flightLegs = flightLegs+1#
			if(flightLegs == (length(tempPath)-3)) stop("too stringent flight time parameters")#
			next#
		}#
		#easy way, just check that each leg is < threshold, then take the smallest one that fits criters. #
		#loop through corresponding airportlist, adding the middle nodes to the end and beginning of each flight order path#
		#check if there are any elgible paths that meet flight time restrictions, if there arent, add a stop and continue, if the number of stops = the number of fields, really stop and give the user a warning#
		trackTotals = list()#
		airportOrders = list()#
		legDistances = list()#
		for(i in 1:length(distanceList)){#
			workDat = distanceList[[i]]#
			trackTotals[[i]] = Inf#
			if(any(is.null(workDat))) next#
			if(nrow(workDat)<=flightLegs) next#
			if(any(workDat>flight.range)) next#
			#starting from 2:nrow(distanceList[[i]]), take the sum of i and i-1, and select smallest, then sum all of those smallest ones, that is total distance for that path #
			airportNodeList = c()#
			distanceVector = c()#
			#for(j in 2:nrow(workDat)){#
			#	twoRowSum = apply(workDat,2,sum)#
			#	airportSelect = which.min(twoRowSum)#
			#	airportNodeList = c(airportNodeList,paste("A",airportSelect,sep=""))#
			#	distanceVector = c(distanceVector,min(twoRowSum))#
			#}#
			#trackTotals[[i]] = sum(distanceVector)#
			trackTotals[[i]] = sum(workDat)#
			legDistances[[i]] = distanceVector#
			airportOrders[[i]] = airportNodeList#
		}#
		#if(all(unlist(trackTotals)==Inf)) next#
		if(length(which(unlist(trackTotals) != Inf))<1){#
			#flightLegs = flightLegs+1#
			if(flightLegs == (length(tempPath)-3)) stop("too stringent flight time parameters")#
		}else{#
			shortestDistance = which.min(unlist(trackTotals))#
			#distanceByLeg = legDistances[[shortestDistance]]#
			#bestDistance = trackTotals[[shortestDistance]]#
			#airportOrder says which airport to do, know which order overall by shortestDistance#
			routePosition = flightOptions[shortestDistance,]#
			#airportPath = airportOrders[[shortestDistance]]#
			airportPath = airportOrderList[[shortestDistance]]#
			bestPath = list()#
			for(i in 1:length(routePosition)){#
				if(i == 1){#
					#bestPath = c(bestPath,tempPath[1:routePosition[i]-1])#
					bestPath[[i]] = c(airportPath[[i]],tempPath[1:routePosition[i]-1],airportPath[[i+1]])#
				}else{#
					bestPath[[i]] = c(bestPath[[i-1]][[length(bestPath[[i-1]])]],tempPath[routePosition[i-1]:routePosition[i]],airportPath[[i+1]])#
#
						}#
#					else if(i == length(routePosition)){#
#					bestPath[[i]] = c(bestPath[[i-1]][[length(bestPath[[i-1]])]],tempPath[routePosition[i-1]:routePosition[i]],tempPath[1])#
#
#				}#
			}#
			#what is purpose of this?#
			i = i+1#
			bestPath[[i]] = c(bestPath[[i-1]][[length(bestPath[[i-1]])]],tempPath[(routePosition[i-1]+1):length(tempPath)],airportPath[[i+1]])#
			break#
			}#
	}#
	#bestPath[[1]] = c("A1",bestPath[[1]])#
	#bestPath[[length(bestPath)]] = c(bestPath[[length(bestPath)]],"A1")#
}#
#find distance of tsp#
#compare to distance/target time parameters, if distance is too long, add 1 stop. for every ordered pair, find the closest distance to an eligible airport. loop through combinations saving the ones that are eliglible per timing parameters, choose shortest. Add another stop, now do a double loop, etc#
#testExits takes time, could try to just skip this during the scheduler#
if(grepl("^scheduler",uniqueInputID)==F){#
	testExitsRaw = getTestExits(bestPath,allPoints,distances,tempDat)#
	testExits = testExitsRaw[["testExits"]]#
	testExitPoint =  testExitsRaw[["entryExitTrack"]]#
	testExitBboxStart = testExitsRaw[["bboxStartPosition"]]#
	for(a in allPoints[grep("A",allPoints[,1]),1]){#
		testExits[[a]] = c(1,1)#
		#?is this wrong?#
	}#
}else{#
	testExits = list()#
	for(bestPathIter in bestPath){#
		for(bestPathIter1 in bestPathIter){#
			temp = which(allPoints[,1]==bestPathIter1)#
			if(grepl("A",bestPathIter1)) {#
				selects = 1#
				tempOut = c(temp[selects],temp[selects])#
				}else{#
				selects = c(1,min(3,nrow(temp)))#
				tempOut = temp[selects]#
				}#
			testExits[[bestPathIter1]] = tempOut#
			}#
		}#
		testExitBboxStart =testExits#
	}#
#
#alternative is just to make a list with an entry for everyBespthPath, and take the 1st and 3rd(if it exists) entry from all points that correspond to that#
tourLength = 0#
routeLengths_wTurns = c()#
for(temp in bestPath){#
	miniRoute = 0#
	for(i in 1:(length(temp)-1)){#
		if(is.na(distances[testExits[[temp[i]]][2],testExits[[temp[i+1]]][1]])) stop("pause")#
		tourLength = tourLength+distances[testExits[[temp[i]]][2],testExits[[temp[i+1]]][1]]#
		miniRoute = miniRoute+distances[testExits[[temp[i]]][2],testExits[[temp[i+1]]][1]]#
	}#
	routeLengths_wTurns = c(routeLengths_wTurns,miniRoute)#
}	#
bestDistance_wCorners = tourLength#
#
print(routeLengths_wTurns)#
#
routes = list()#
routeIndex = 1#
lngMeterConv = 1#
latMeterConv = 1#
boundingBoxes = list()#
boundingBoxesRouteNested = list()#
wayPointsByField = list()#
#routeTimes = c()#
for(i in bestPath){#
	#wayPointsByField = list()#
	graphList = as.numeric(allPoints[grep(paste("^",i[1],"$",sep=""),allPoints[,1]),2:3])#
	tempBoxes = list()#
	totalTimeRoute = 0#
	for(j in i){#
		if(grepl("A",j)) next#
		entry = testExits[[j]][1]#
		tempRows = which(rownames(distances) %in% j) #
		entryIndex = which(tempRows==entry)#
		lastScan = i[which(i==j)-1]#
		if(grepl("A",lastScan)){#
			lastScan = allPoints[which(allPoints[,1]==lastScan),c("Lng","Lat")]#
		}else{#
			lastScan = cutOutBlocks[[as.numeric(lastScan)]][[1]][1,]#
			}#
			lastScan = as.numeric(lastScan)#
			lastScan = c()#
	    if(grepl("^scheduler",uniqueInputID)==F){#
			flightPlanRaw = imageTime(tempDat[[as.numeric(j)]],T,trackList[[as.numeric(j)]],dontCountList[[as.numeric(j)]],testExitBboxStart[[j]],lastScan)#
		}else{#
			flightPlanRaw = imageTime(tempDat[[as.numeric(j)]],T,trackList[[as.numeric(j)]],dontCountList[[as.numeric(j)]],NULL,lastScan)#
#
			}#
		flightPlan = flightPlanRaw[[1]]#
		boundingBoxes[[length(boundingBoxes)+1]] = flightPlanRaw[[3]] #
		tempBoxes[[length(tempBoxes)+1]] = flightPlanRaw[[3]]#
		#totalTimeRoute = totalTimeRoute + as.numeric(flightPlanRaw[[2]])#
		#testExitBboxStart[[as.numeric(j)]]#
		wayPointsByField[[j]] = flightPlan#
		graphList = rbind(graphList,flightPlan)	#
		#graphList = rbind(graphList,flightPlan[,2:3])	#
	}#
	#routeTimes = c(routeTimes,totalTimeRoute)#
	graphList = rbind(graphList,as.numeric(allPoints[grep(paste("^",j,"$",sep=""),allPoints[,1]),2:3]))#
	routes[[routeIndex]] = graphList#
	boundingBoxesRouteNested[[routeIndex]]	= tempBoxes#
	routeIndex = routeIndex+1#
}#
colors = brewer.pal(min(9,length(routes)),"Pastel1")#
if(length(routes)>9) colors = rep(colors,times = length(routes)/9)#
graphIndex = 1#
#
#setwd("~/FlightPlan/public/R/Output/")#
#
#currentD = getwd()#
manifest = c("imaging_cluster_polygons.csv","jsonString.json")#
cheatSheetList = list()#
print("before routes")#
jsonList = list()#
for(route in routes){#
	rownames(route) = NULL#
	routeLines = list()#
	lineIndex = 1#
	routeLines[[lineIndex]] = Line(as.matrix(route))#
	routePoints = route#
	#coordinates(routePoints) = c("Lng","Lat")#
	routePoints = SpatialPoints(routePoints)#
#
	lineIndex = lineIndex+1#
	polygonList = list()#
	bestPath_getPolygons = bestPath[[graphIndex]]#
	fieldIds_thisRoute = unlist(trackList[as.numeric(bestPath_getPolygons[2:(length(bestPath_getPolygons)-1)])])#
	for(i in 1:length(fieldIds_thisRoute)){#
		#polygonList[[i]] = Polygons(list(Polygon(rawDat[[fieldIds_thisRoute[i]]])),i)#
		temp = readWKT(dat$fields[[fieldIds_thisRoute[i]]]$cutout)@polygons#
		tempList = list()#
		for(k in 1:length(temp)){#
			temp1 = temp[[k]]@Polygons#
			for(z in 1:length(temp1)){#
				tempList[[length(tempList)+1]] = temp[[k]]@Polygons[[z]]#
			}#
		}#
		polygonList[[i]] = Polygons(tempList,i)#
		#polygonList[[i]][[1]]@ID = as.character(i)#
		#length(polygonList[[i]]) readWKT(dat$fields[[fieldIds_thisRoute[1]]]$cutout)@polygons)#
		#polygonList[[i]][[1]]@ID = as.character(i)#
	}#
	namesDataFrame = data.frame(cbind(1:length(fieldIds_thisRoute)),unlist(fieldNames[fieldIds_thisRoute]))#
	colnames(namesDataFrame) = c("ID","Field_Name")#
	#kmlPolygonOut= SpatialPolygonsDataFrame(SpatialPolygons(polygonList),namesDataFrame)#
	kmlPolygonOut= SpatialPolygonsDataFrame(SpatialPolygons(polygonList),namesDataFrame)#
	routeLines= Lines(routeLines,1)#
	kmlLine = SpatialLines(list(routeLines),CRS(paste("+proj=utm +zone=",UTMZone_number," +",UTMHemi," +ellps=WGS84 +datum=WGS84 +units=m +no_defs",sep=""))) #CRS("+proj=longlat +datum=WGS84")#
	testOut = SpatialLinesDataFrame(kmlLine,data=as.data.frame(bounds))#
	testOut <- spTransform(testOut, CRS("+proj=longlat +datum=WGS84"))#
	routepointsTest = SpatialPoints(routePoints,CRS(paste("+proj=utm +zone=",UTMZone_number," +",UTMHemi," +ellps=WGS84 +datum=WGS84 +units=m +no_defs",sep="")))#
	testPoints = SpatialPointsDataFrame(routepointsTest, as.data.frame(route))#
	testPointsOut <- spTransform(testPoints, CRS("+proj=longlat +datum=WGS84"))#
	#setwd("~/FlightPlan/public/R/Output/")#
	write.csv(route,paste("public/R/Output/",uniqueInputID,"/Route",graphIndex,".csv",sep=""))#
	writeOGR(testPointsOut, paste("public/R/Output/",uniqueInputID,"/Points",graphIndex,".kml",sep=""), layer="points1", driver="KML",overwrite_layer=T)#
	#kmlLine(obj=testOut, kmlfile=paste("public/R/Output/",uniqueInputID,"/Route",graphIndex,".kml",sep=""),name="R Lines",col=colors[graphIndex],lwd=3)#
	manifest = c(manifest,paste("Route",graphIndex,".csv",sep=""),paste("Points",graphIndex,".kml",sep=""),paste("Route",graphIndex,".kml",sep=""))#
	combineLinePolygon(kmlPolygonOut,testOut,graphIndex)#
	if(grepl("^scheduler",uniqueInputID)==F){#
		rawCheat = cheatSheet(bestPath[[graphIndex]],boundingBoxesRouteNested[[graphIndex]],routeLengths_wTurns[graphIndex])#
		cheatSheetList[[graphIndex]] = rawCheat[[1]]#
		jsonOut = rawCheat[[2]] #
		jsonList[[graphIndex]] = jsonOut#
		rownames(cheatSheetList[[graphIndex]]) = paste(paste(rep("|",times=graphIndex),collapse=""),1:nrow(cheatSheetList[[graphIndex]]),sep="")#
		#replaces = which(is.na(cheatSheetList[[graphIndex]]),arr.ind=T)#
		#for(z in 1:nrow(replaces)){#
		#	cheatSheetList[[graphIndex]][replaces[z,1],replaces[z,2]] = ""#
		#}#
		colnames(cheatSheetList[[graphIndex]]) = 1:ncol(cheatSheetList[[graphIndex]])#
	}#
	#print(cheatSheetList[[graphIndex]])#
	graphIndex = graphIndex+1#
	print("before routes")#
#
	#create cheat sheet entry for each route#
}#
#
#print out imaging cluster geometries to define projects#
bboxOutputArray = c()#
countIndex = 1#
for(j in 1:length(boundingBoxesRouteNested)){#
	pathNoAirports = bestPath[[j]][-grep("A",bestPath[[j]])]#
	for(i in 1:length(boundingBoxesRouteNested[[j]])){#
		temp = boundingBoxesRouteNested[[j]][[i]]#
		temp = project(cbind(as.numeric(temp[,1]),as.numeric(temp[,2])),paste("+proj=utm +zone=",UTMZone_number," +",UTMHemi," +ellps=WGS84 +datum=WGS84 +units=m +no_defs",sep=""),inv=T)#
		coords = c()#
		for(k in 1:nrow(temp)){#
			coords = c(coords,paste(temp[k,],collapse=" "))#
		}#
		fieldIds = paste(unlist(lapply(dat$fields[trackList[[as.numeric(pathNoAirports[i])]]], function(x) return(x$id))),collapse="|")#
		tempOut = paste("POLYGON((",paste(coords,collapse=","),"))",sep="")#
		bboxOutputArray = rbind(bboxOutputArray,c(uniqueInputID,countIndex,tempOut,fieldIds))#
		countIndex = countIndex+1#
	}#
}#
#
colnames(bboxOutputArray) = c("flightID","Cluster_ID","GEOM","Field_IDS")#
#
#do.call(rbind.data.frame,cheatSheetList[[1]])#
if(grepl("^scheduler",uniqueInputID)==F){#
#
	for(z in 1:length(cheatSheetList)){#
		cheatSheetOut = ldply(cheatSheetList[z], function(t) t)#
		cheatSheetOut = cheatSheetOut[,-1]#
		formatXLSX(cheatSheetOut,uniqueInputID,z)#
		manifest = c(manifest,paste("cheat_sheet_",z,".xlsx",sep=""))#
	}#
}#
#write.csv(cheatSheetOut,paste("public/R/Output/",uniqueInputID,"/cheat_sheet.csv",sep=""),row.names=F,na="")#
write.csv(bboxOutputArray,paste("public/R/Output/",uniqueInputID,"/imaging_cluster_polygons.csv",sep=""),row.names=F)#
#
writeLines(paste(manifest,collapse=","),paste("public/R/Output/",uniqueInputID,"/manifest.txt",sep=""),sep="")#
writeLines(paste("totalDistance: ",bestDistance_wCorners,sep=""),paste("public/R/Output/",uniqueInputID,"/distance_summary.txt",sep=""),sep="")#
polygonList = list()#
for(i in 1:length(rawDat)){#
	polygonList[[i]] = Polygons(list(Polygon(rawDat[[i]])),i) #
}#
#
namesDataFrame = data.frame(cbind(1:length(rawDat)),unlist(fieldNames))#
colnames(namesDataFrame) = c("ID","Field_Name")#
#
kmlPolygonOut= SpatialPolygonsDataFrame(SpatialPolygons(polygonList),namesDataFrame)#
if(grepl("^scheduler",uniqueInputID)==F){#
	jsonClusterIter = 1#
	jsonOut = list()#
	for(jsonListIter in 1:length(jsonList)){#
		tempJSON = jsonList[[jsonListIter]]#
		for(jsonListIter1 in 1:length(tempJSON)){#
			jsonList[[jsonListIter]][[jsonListIter1]][["Flight Order"]] = jsonClusterIter#
			jsonOut[[jsonClusterIter]] = jsonList[[jsonListIter]][[jsonListIter1]]#
			jsonClusterIter = jsonClusterIter+1#
		}	#
	}	#
	outputJSON = list()#
	airportJSON = list()#
	cameraSettingsJSON = list()#
	cameraSettingsJSON[[1]] = list()#
	cameraSettingsJSON[[1]][["Camera Number"]] = 1#
	cameraSettingsJSON[[1]][["Camera Serial"]] = 1358902 #
	cameraSettingsJSON[[1]][["Format Cards"]] = T#
	cameraSettingsJSON[[1]][["Lens"]] = "50mm f/1.8D"#
	cameraSettingsJSON[[2]] = list()#
	cameraSettingsJSON[[2]][["Camera Number"]] = 2#
	cameraSettingsJSON[[2]][["Camera Serial"]] = 3735257#
	cameraSettingsJSON[[2]][["Format Cards"]] = T#
	cameraSettingsJSON[[2]][["Lens"]] = "50mm f/1.8D"#
	cameraSettingsJSON[[3]] = list()#
	cameraSettingsJSON[[3]][["Camera Number"]] = 3#
	cameraSettingsJSON[[3]][["Camera Serial"]] = 3735250#
	cameraSettingsJSON[[3]][["Format Cards"]] = T#
	cameraSettingsJSON[[3]][["Lens"]] = "50mm f/1.8D"#
	airportJSON[["Estimated Flight Time"]]= 100*floor(bestDistance_wCorners/100+.5)#
	airportJSON[["Start Location"]]=list()#
	airportJSON[["End Location"]]=list()#
	#routeLinesSpatial= SpatialLines(list(routeLines),proj4string=CRS(paste("+proj=utm +zone=",UTMZone_number," +",UTMHemi," +ellps=WGS84 +datum=WGS84 +units=m +no_defs",sep="")))#
	#routeLinesSpatial= spTransform(routeLinesSpatial,CRS("+proj=longlat +datum=WGS84"))#
	#airportJSON[["Full_Flight_Path"]]= writeWKT(routeLinesSpatial)#
	latLngGraphList = project(graphList,paste("+proj=utm +zone=",UTMZone_number," +",UTMHemi," +ellps=WGS84 +datum=WGS84 +units=m +no_defs",sep=""),inv=T)#
	airportJSON[["Start Location"]][["lng"]]=latLngGraphList[1,1]#
	airportJSON[["Start Location"]][["lat"]]=latLngGraphList[1,2]#
	startSelect = which(allPoints[,1]==bestPath[[1]][1])#
	airportJSON[["Start Location"]][["Airport Code"]] = as.character(airportsLatLng[startSelect,"name"])#
	airportJSON[["End Location"]][["lng"]]=latLngGraphList[nrow(latLngGraphList),1]#
	airportJSON[["End Location"]][["lat"]]=latLngGraphList[nrow(latLngGraphList),2]#
	stopSelect = which(allPoints[,1]==bestPath[[length(bestPath)]][length(bestPath[[length(bestPath)]])])#
	airportJSON[["End Location"]][["Airport Code"]] = as.character(airportsLatLng[stopSelect,"name"])#
	airportJSON[["Refueling Locations"]]=list()#
	for(bestPathIter in 1:length(bestPath)){#
		if(bestPathIter != length(bestPath)){#
			airportJSON[["Refueling Locations"]][[bestPathIter]] = list()#
			temp123 = bestPath[[bestPathIter]]#
			select = which(allPoints[,1]==temp123[length(temp123)])#
			airportJSON[["Refueling Locations"]][[bestPathIter]][["lng"]] = as.numeric(airportsLatLng[select,"lng"])#
			airportJSON[["Refueling Locations"]][[bestPathIter]][["lat"]] = as.numeric(airportsLatLng[select,"lat"])#
			airportJSON[["Refueling Locations"]][[bestPathIter]][["Airport Code"]] = as.character(airportsLatLng[select,"name"]) #turn into code#
			imagingAreaAfter = 0#
			for(zz in 1:bestPathIter){#
				imagingAreaAfter = imagingAreaAfter+length(bestPath[[zz]])-2#
			}#
			imagingAreaAfter = imagingAreaAfter#
			airportJSON[["Refueling Locations"]][[bestPathIter]][["After Imaging Area"]] = as.character(imagingAreaAfter) #turn into code#
		}#
	}#
	outputJSON[["Camera Values"]] = cameraSettingsJSON#
	outputJSON[["Airport Locations"]] = airportJSON #
	outputJSON[["Flight Plan"]] = jsonOut #
	jsonString = toJSON(outputJSON)#
	writeLines(jsonString,paste("public/R/Output/",uniqueInputID,"/jsonString.json",sep=""))#
}#
#need to create cheat sheet#
#start/end airport names#
#field names in order#
#use track list to track clusters#
#field raw elevation, estimated MSL altitude for a given resolution#
#empty column for "complete"#
#if(dat$general$doy){#
	#for each flight (bestPath)#
#build fligth schedulerJson here as well#
#time is routeLengths_wTurns[[bestPathIndex]]#
scheduleMetricsList = list()#
unlistedFields = unlist(lapply(dat$fields, function(x) x$id))#
for(bestPathIndex in 1:length(bestPath)){#
#
	bestPath[[bestPathIndex]]#
	marginalDistanceList = list()#
	individualFieldIds = c()#
	for(cluster in 2:(length(bestPath[[bestPathIndex]])-1)){#
		marginalDistance = (centDistances[bestPath[[bestPathIndex]][cluster],bestPath[[bestPathIndex]][cluster+1]]+centDistances[bestPath[[bestPathIndex]][cluster],bestPath[[bestPathIndex]][cluster-1]])-centDistances[bestPath[[bestPathIndex]][cluster-1],bestPath[[bestPathIndex]][cluster+1]]#
		marginalDistanceList[[length(marginalDistanceList)+1]]  = c(bestPath[[bestPathIndex]][cluster],marginalDistance,centroids[as.numeric(bestPath[[bestPathIndex]][cluster]),1],centroids[as.numeric(bestPath[[bestPathIndex]][cluster]),2],paste(unlistedFields[trackList[[as.numeric(bestPath[[bestPathIndex]][cluster])]]],collapse=","))#
		individualFieldIds  = c(individualFieldIds,trackList[[as.numeric(bestPath[[bestPathIndex]][cluster])]])#
	}#
	#colnames(marginalDistanceArray) = c("ID","marginalDistance","lng","lat")#
	totalAcres = 0#
	for(thisfieldBlockID in individualFieldIds ){#
			temp = cutOutBlocks[[thisfieldBlockID]]#
			PolygonsList = list()#
			for(temp1 in 1:length(temp)){#
				#tBoundsPolygon = Polygon(temp[temp1])#
					PolygonsList[[temp1]] =  Polygon(temp[temp1])#
			}#
			tBoundsPolygons = Polygons(PolygonsList,1)#
			tBoundsSpatial = SpatialPolygons(list(tBoundsPolygons))#
			proj4string(tBoundsSpatial) = paste("+proj=utm +zone=",UTMZone_number," +",UTMHemi," +ellps=WGS84 +datum=WGS84 +units=m +no_defs",sep="")#
		acres = tBoundsSpatial@polygons[[1]]@area/10000*2.47105#
		totalAcres = totalAcres +acres#
	}#
	#also need to track the fieldIDs that are associated with each cluster#
		scheduleMetricsList[[bestPathIndex]] = list(doy=135,time=routeLengths_wTurns[[bestPathIndex]],acreage=	totalAcres,acreEffeciency=routeLengths_wTurns[[bestPathIndex]]/totalAcres,clusters =marginalDistanceList,fieldIds = as.numeric(unlist(lapply(dat$fields, function(x) x$id ))))#
	#ratio acreage to time#
	#save all possible routes in array json#
	#construct outputjson here#
	print("wut")#
	writeLines(toJSON(scheduleMetricsList),paste("public/R/Output/",uniqueInputID,"/schedulerInfo.json",sep=""))#
#
}#
#writeitOuthere#
#
#calculate total area from the cutout blocks in the track list relevant to these#
#}
setwd("~/Desktop")#
#
dat = read.csv("stateCountyFIPs.csv",stringsAsFactors=F)
length(unique(dat[,1]))
outputTable
as.POSIXct(dateTime)
?as.POSIXct
dateTime
dateTime = format(paste(newDates," ",workTable[,2],":00",sep=""))
dateTime
library(rjson)#
library(XML)#
setwd("~/Desktop/currentWeather")#
#so pass each field center lat lng here in here:#
dat = fromJSON(file="http://forecast.weather.gov/MapClick.php?lat=38.4247341&lon=-86.9624086&FcstType=json")#
#
stationID = dat$currentobservation$id#
stationLocation = c(dat$location$longitude,dat$location$latitude)#
currentObservations = dat$currentobservation#
#
currentTextDescription = dat$data$text[1]#
vagueWeatherDescription = dat$data$weather#
timePeriods = dat$time$startValidTime#
fullOut = c()#
#
timeToSearch = "4:00" #4am, its on military time#
searchTable = paste("Output/",stationID,".csv",sep="")#
if(file.exists(searchTable )==F){#
	#potentially hang on to these tables and re-use the tables without having to re-scrape these too much#
	 nextLevelURL = paste("http://forecast.weather.gov/data/obhistory/",stationID,".html",sep="")#
	 doc = htmlParse(readLines(nextLevelURL))#
	 tableNodes = getNodeSet(doc, "//table")#
	 tb = readHTMLTable(doc=tableNodes[[4]],header=T) #
	 write.csv(tb,paste("Output/",stationID,".csv",sep=""),row.names=F)#
#
 }else{#
 	tb = read.csv(searchTable ,stringsAsFactors=F)#
 }#
currentDay = format(Sys.Date(),"%d")#
currentMonth = format(Sys.Date(),"%m")#
currentYear = format(Sys.Date(),"%Y")#
lastMonth = as.numeric(currentMonth)-1#
lastYear = currentYear#
if(currentMonth == "1") lastMonth = 12#
if(currentMonth == "1") lastYear = as.numeric(currentYear)-1#
#
workTable= tb[grep("^[0-9]*$",tb[,1]),]#
subtractDays = as.numeric(currentDay)-as.numeric(as.character(workTable[,1]))#
newDates = Sys.Date()-subtractDays#
if(any(subtractDays<1)){#
	modifyIndex = which(subtractDays<1)#
	changeMonthDates = as.Date(paste(lastYear,"-",lastMonth,"-",workTable[modifyIndex,1],sep=""))#
	newDates[modifyIndex] = changeMonthDates#
}#
#
dateTime = format(paste(newDates," ",workTable[,2],":00",sep="")) #will prb need mod#
colPull = c(1,3,4,5,6,7,11,16)#
outputTable = workTable[,colPull]#
outputTable[,1] = dateTime#
#add station id to output table!!!!####
#
#outputTable should go to a db after checking and removing duplicates based on station id an d#
#need a more sophisticated way of getting exact date of prediction,#
#them, check database for existing prediction for that date/station, and only update the ones that don't match#
 #get current day of month, look for the first occurence of that along with a time before cront ask started (4am)#
#
#ehh just find the first occurence of 4am, and then go down the next occurence of 4 am, and figure out the date of the first#
#this bit may not be necessary#
convertedTimes = strptime(tb[,2],format="%H:%M")#
selectFirst = which(convertedTimes <strptime(timeToSearch,format="%H:%M"))[1]#
selectSecond = which(convertedTimes==convertedTimes[selectFirst])[2]#
rangeTable = c(selectFirst:selectSecond)#
totalRainfallInPeriod = sum(as.numeric(as.character(tb[rangeTable,16])),na.rm=T)#
#
thisOut = c(timePeriods[1],vagueWeatherDescription[1],currentTextDescription[1],totalRainfallInPeriod)#
fullOut = rbind(fullOut,thisOut)#
#
#ehh, probably just rainfall and text description#
#what does output look like#
Sys.sleep(1)#
#
colnames(fullOut) = c("Valid Time","Short Description","Long Description","24 Hour Rainfall (in)")#
#
#at the end of all this, delete the tempTables
fullOut
outputTable
weather scrape procedure#
setwd("~/Desktop/gddGetter")#
#
list.of.packages = c("RMySQL","mailR","maptools","RColorBrewer","sp")#
	new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]#
	if(length(new.packages)) install.packages(new.packages,repos="http://cran.rstudio.com/"#
	)#
gdd_calculate = function(weather,max_threshold,min_threshold){#
	#assumes input array starts at plant date,#
	dailyGDD = matrix(ncol=1,apply(weather,1,function(temp){#
		(((max(min_threshold,min(max_threshold,as.numeric(temp["t_max"])))+min(max_threshold,max(min_threshold,as.numeric(temp["t_min"])))))/2)-min_threshold#
	}))#
	cumulativeGDD = cumsum(dailyGDD)#
	output = cbind(dailyGDD,cumulativeGDD)#
	colnames(output) = c("Daily","Cumulative")#
	return(output)#
}#
library(RMySQL)#
library(mailR)#
library(maptools)#
library(sp)#
library(RColorBrewer)#
#
DBNAME = "mavrx"#
db = dbConnect(MySQL(), user="mavrxclients",password="nP3zMsMYCYtHE5KM",dbname=DBNAME,host="prod.ccuddobdp8d5.us-east-1.rds.amazonaws.com")#
query = paste("SELECT fieldID,name,defaultLatitude,defaultLongitude,planting_date from fields")#
rs = dbSendQuery(db, query)#
allFields = fetch(rs, n=-1)#
#
fullOutput = c()#
#
for(eachFieldIndex in 1:nrow(allFields)){#
	fieldID = allFields[eachFieldIndex,"fieldID"]#
	name = allFields[eachFieldIndex,"name"]#
	lat =  allFields[eachFieldIndex,"defaultLatitude"]#
	lng =   allFields[eachFieldIndex,"defaultLongitude"]#
	plantDat =  allFields[eachFieldIndex,"planting_date"]#
	### #need to look up plant date, if that fails, look for USDA estimate for that state, if that fails use April 1 ####
	if(is.null(plantDat)) next#
	query = paste("SELECT * from weatherdata where field_id = '",fieldID,"' AND date >= '",as.Date(plantDat),"'",sep="")#
	rs = dbSendQuery(db, query)#
	weather = fetch(rs, n=-1)#
	if(nrow(weather)<1) {#
		print(paste("No weather date for fieldID ",fieldID))#
		next#
	}#
	query = paste("SELECT crop_id from fields_crops where fields_id = '",fieldID,"'",sep="")#
	rs = dbSendQuery(db, query)#
	crop = fetch(rs, n=-1)#
	crop = matrix(nrow=1,"corn")#
	if(nrow(crop)<1){#
		print(paste("No crop type for fieldID ",fieldID))#
		next#
	}#
	gdd_profile = gdd_calculate(weather,30,10)#
	stage_gdd_mapping = read.csv("Input/110DayCorn.csv",stringsAsFactors=F)  #need smarter way of choosing this reference#
	stage_gdd_mapping[,"Estimate"] = gsub("[^0-9]","",stage_gdd_mapping[,"Estimate"])#
	firstOccurences = c()#
	for(eachStage in unique(stage_gdd_mapping[,"Stage"])){#
		firstMatch = which(stage_gdd_mapping[,"Stage"]==eachStage)[1]#
		firstOccurences = rbind(firstOccurences,stage_gdd_mapping[firstMatch,c("Stage","Estimate")])#
	}#
	firstOccurences = as.data.frame(as.matrix(firstOccurences))#
	firstOccurences[,2] = as.numeric(as.character(firstOccurences[,2]))#
	firstOccurences[,1] = as.character(firstOccurences[,1])#
#
	#forecast next 5 days by taking the average of last 5 days and extending#
#	totalGDD = gdd_profile[nrow(gdd_profile),"Cumulative"]+(3*)#
	timeLag = as.numeric(Sys.Date()-max(as.Date(weather[,"date"])))#
	totalGDD = gdd_profile[nrow(gdd_profile),"Cumulative"]+(timeLag*gdd_profile[nrow(gdd_profile),"Daily"])#
	day5Extend = totalGDD + (5*gdd_profile[nrow(gdd_profile),"Daily"])#
	currentStage = which(firstOccurences[,2]>totalGDD)[1]-1#
	comingSoonStage = which(firstOccurences[,2]>day5Extend)[1]-1#
	tempOut = c(as.character(Sys.Date()),fieldID,name,totalGDD,firstOccurences[currentStage,"Stage"],firstOccurences[comingSoonStage,"Stage"],lat,lng)#
	fullOutput = rbind(fullOutput,tempOut)#
#
}#
if(nrow(fullOutput)<1) stop("No data")#
colnames(fullOutput) = c("Estimate Date","fieldID","fieldName","Estimated GDD","Current Stage","Stage In Next 5 Days","Lat","Lng")#
#subset of fullOutput goes to gdd table#
#
tempDat = as.data.frame(fullOutput)#
rownames(tempDat) = tempDat[,"fieldID"]#
pins = SpatialPointsDataFrame(SpatialPoints(cbind(as.numeric(fullOutput[,"Lng"]),as.numeric(fullOutput[,"Lat"]))),data=tempDat)#
proj4string(pins) = "+proj=longlat +datum=WGS84" #
#now to make this into a kml shape file with colored points#
#make kml from scratch..#
pinData = as.data.frame(as.matrix(cbind(pins@data,"colorCurrent Stage"="Black","colorStage In Next 5 Days"="Black")))#
pinData[,"colorCurrent Stage"] = as.character(pinData[,"colorCurrent Stage"])#
pinData[,"colorStage In Next 5 Days"] = as.character(pinData[,"colorStage In Next 5 Days"])#
pinData[,"Current Stage"] = gsub("^$","Not Emerged",pinData[,"Current Stage"])#
pinData[,"Stage In Next 5 Days"] = gsub("^$","Not Emerged",pinData[,"Stage In Next 5 Days"])#
library(RColorBrewer)#
allStages = unique(c(as.character(unique(pinData[,"Current Stage"])),as.character(unique(pinData[,"Stage In Next 5 Days"]))))#
colors = brewer.pal(length(allStages),"RdYlGn")#
if(length(colors)<length(allStages)) colors = rep(colors,times=ceiling(length(allStages)/length(colors)))#
#
for(i in 1:length(allStages)){#
	pinData[which(pinData[,"Current Stage"]==allStages[i]),"colorCurrent Stage"] = paste(64,substr(colors[i],6,7),substr(colors[i],4,5),substr(colors[i],2,3),sep="") #paste(99,substr(colors[i],2,7),sep="")##
#rgb(col2rgb(colors[i])[,1][1],col2rgb(colors[i])[,1][2],col2rgb(colors[i])[,1][3],1,maxColorValue=255)#
	pinData[which(pinData[,"Stage In Next 5 Days"]==allStages[i]),"colorStage In Next 5 Days"] = paste(64,substr(colors[i],6,7),substr(colors[i],4,5),substr(colors[i],2,3),sep="") #paste(99,substr(colors[i],2,7),sep="")##
#rgb(col2rgb(colors[i])[,1][1],col2rgb(colors[i])[,1][2],col2rgb(colors[i])[,1][3],1,maxColorValue=255)#
}#
#
pins@data = pinData#
stageEstimate_outputName = paste("Output/CropStageEstimate_",as.character(Sys.Date()),".kml")#
tf <- stageEstimate_outputName #
kmlFile <- file(tf, "w")#
#
cat(kmlPolygon(kmlname="PolygonViz")$header, #
file=kmlFile, sep="\n")#
for(stageForecast in c("Current Stage","Stage In Next 5 Days")){#
		cat(paste("<Folder><name>",stageForecast,"</name>",sep=""),   file=kmlFile, sep="\n")#
	for(k in unique(pins@data[,stageForecast])){    #
		cat(paste("<Folder><name>",k,"</name>",sep=""),   file=kmlFile, sep="\n")#
		tempD = pins@data[which(pins@data[,stageForecast]==k),]#
	    for(i in 1:nrow(tempD )){#
		    	addText = paste('#
		  <Placemark> <name> ',gsub("&","",tempD [i,"fieldName"]),' </name> <Style id="Mavrx Airport">      <IconStyle>        <Icon>          <href>http://www.clker.com/cliparts/4/5/c/0/12249615002008292168Japanese_Map_symbol_(Orchard).svg.med.png</href>             <scale> 0.5 </scale></Icon> <color> ',tempD [i,paste("color",stageForecast,sep="")],'</color> </IconStyle>    </Style>  <Point><coordinates> ',tempD [i,"Lng"],',',tempD [i,"Lat"],',0</coordinates> </Point> </Placemark>',sep='')#
		cat(addText,file=kmlFile,sep="\n")#
		}#
		cat("</Folder>",   file=kmlFile, sep="\n")#
	}#
	cat("</Folder>",   file=kmlFile, sep="\n")#
}#
#
cat(kmlPolygon()$footer, file=kmlFile, sep="\n")#
close(kmlFile)#
#just plot all fields we have in db with pins#
tf <- paste("Output/AllFieldsPin_",as.character(Sys.Date()),".kml",sep="")#
kmlFile <- file(tf, "w")#
#
cat(kmlPolygon(kmlname=paste("All_Fields_",as.character(Sys.Date())))$header, #
file=kmlFile, sep="\n")#
#
 for(i in 1:nrow(allFields )){#
		   addText = paste('#
		  <Placemark> <name> ',gsub("&","",allFields[i,"name"]),' </name> <Style id="Mavrx Airport">      <IconStyle>        <Icon>          <href>http://www.clker.com/cliparts/4/5/c/0/12249615002008292168Japanese_Map_symbol_(Orchard).svg.med.png</href>             <scale> 0.5 </scale></Icon> <color> 501400E6</color> </IconStyle>    </Style>  <Point><coordinates> ',allFields[i,"defaultLongitude"],',',allFields[i,"defaultLatitude"],',0</coordinates> </Point> </Placemark>',sep='')#
		cat(addText,file=kmlFile,sep="\n")#
		}#
cat(kmlPolygon()$footer, file=kmlFile, sep="\n")#
close(kmlFile)#
send.mail(from = "chris@mavrx.co",#
          to = c("chris@mavrx.co"),#
          subject = paste("GDD Update for",Sys.Date(),sep=""),#
          body = "Get it",#
          html = TRUE,#
          smtp = list(host.name = "email-smtp.us-east-1.amazonaws.com", port = 587, user.name = "AKIAIZEDN7OGY6OXDSQQ", passwd = "AroYrbRjGv6RChvPTbPcGc2c4aH15C6EZjot4CRfl30b", ssl = TRUE),#
          attach.files = stageEstimate_outputName,#
          authenticate = TRUE,#
          send = TRUE)#
#make a kml output to just show all fields as well#
#
#map this to csv list of gdd ranges
pinData
pinData[,1:5]
pinData[,1:6]
stageEstimate_outputName
csv_outputName = gsub(".kml$",".csv",stageEstimate_outputName)
csv_outputName
write.csv(pinData[,1:6],csv_outputName,row.names=F)#
#
send.mail(from = "chris@mavrx.co",#
          to = c("chris@mavrx.co"),#
          subject = paste("GDD Update for ",Sys.Date(),sep=""),#
          body = "Get it",#
          html = TRUE,#
          smtp = list(host.name = "email-smtp.us-east-1.amazonaws.com", port = 587, user.name = "AKIAIZEDN7OGY6OXDSQQ", passwd = "AroYrbRjGv6RChvPTbPcGc2c4aH15C6EZjot4CRfl30b", ssl = TRUE),#
          attach.files = c(stageEstimate_outputName,csv_outputName)#
          authenticate = TRUE,#
          send = TRUE)
send.mail(from = "chris@mavrx.co",#
          to = c("chris@mavrx.co"),#
          subject = paste("GDD Update for ",Sys.Date(),sep=""),#
          body = "Get it",#
          html = TRUE,#
          smtp = list(host.name = "email-smtp.us-east-1.amazonaws.com", port = 587, user.name = "AKIAIZEDN7OGY6OXDSQQ", passwd = "AroYrbRjGv6RChvPTbPcGc2c4aH15C6EZjot4CRfl30b", ssl = TRUE),#
          attach.files = c(stageEstimate_outputName,csv_outputName),#
          authenticate = TRUE,#
          send = TRUE)
getwd()
csv_outputName
list.files("Output")
ENV = fromJSON(file="environment_variables.json")
ENV
weather scrape procedure#
setwd("~/Desktop/gddGetter/Output")#
#
removeOldFiles = list.files()#
for(eachFile in removeOldFiles){#
	unlink(eachFile)#
}#
#
setwd("~/Desktop/gddGetter")#
list.of.packages = c("RMySQL","mailR","maptools","RColorBrewer","sp")#
#
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]#
if(length(new.packages)) install.packages(new.packages,repos="http://cran.rstudio.com/")#
gdd_calculate = function(weather,max_threshold,min_threshold){#
	#assumes input array starts at plant date,#
	dailyGDD = matrix(ncol=1,apply(weather,1,function(temp){#
		(((max(min_threshold,min(max_threshold,as.numeric(temp["t_max"])))+min(max_threshold,max(min_threshold,as.numeric(temp["t_min"])))))/2)-min_threshold#
	}))#
	cumulativeGDD = cumsum(dailyGDD)#
	output = cbind(dailyGDD,cumulativeGDD)#
	colnames(output) = c("Daily","Cumulative")#
	return(output)#
}#
library(RMySQL)#
library(mailR)#
library(maptools)#
library(sp)#
library(RColorBrewer)#
#
DBNAME = "mavrx"#
#
ENV = fromJSON(file="environment_variables.json")#
#
db = dbConnect(MySQL(), user=ENV[["USER"]],password=ENV[["PASSWD"]],dbname=ENV[["DB"]],host=ENV[["HOST"]])#
#
query = paste("SELECT fieldID,name,defaultLatitude,defaultLongitude,planting_date from fields")#
rs = dbSendQuery(db, query)#
allFields = fetch(rs, n=-1)#
#
fullOutput = c()#
#
for(eachFieldIndex in 1:nrow(allFields)){#
	fieldID = allFields[eachFieldIndex,"fieldID"]#
	name = allFields[eachFieldIndex,"name"]#
	lat =  allFields[eachFieldIndex,"defaultLatitude"]#
	lng =   allFields[eachFieldIndex,"defaultLongitude"]#
	plantDat =  allFields[eachFieldIndex,"planting_date"]#
	### #need to look up plant date, if that fails, look for USDA estimate for that state, if that fails use April 1 ####
	if(is.null(plantDat)) next#
	query = paste("SELECT * from weatherdata where field_id = '",fieldID,"' AND date >= '",as.Date(plantDat),"'",sep="")#
	rs = dbSendQuery(db, query)#
	weather = fetch(rs, n=-1)#
	if(nrow(weather)<1) {#
		print(paste("No weather date for fieldID ",fieldID))#
		next#
	}#
	query = paste("SELECT crop_id from fields_crops where fields_id = '",fieldID,"'",sep="")#
	rs = dbSendQuery(db, query)#
	crop = fetch(rs, n=-1)#
	crop = matrix(nrow=1,"corn")#
	if(nrow(crop)<1){#
		print(paste("No crop type for fieldID ",fieldID))#
		next#
	}#
	gdd_profile = gdd_calculate(weather,30,10)#
	stage_gdd_mapping = read.csv("Input/110DayCorn.csv",stringsAsFactors=F)  #need smarter way of choosing this reference#
	stage_gdd_mapping[,"Estimate"] = gsub("[^0-9]","",stage_gdd_mapping[,"Estimate"])#
	firstOccurences = c()#
	for(eachStage in unique(stage_gdd_mapping[,"Stage"])){#
		firstMatch = which(stage_gdd_mapping[,"Stage"]==eachStage)[1]#
		firstOccurences = rbind(firstOccurences,stage_gdd_mapping[firstMatch,c("Stage","Estimate")])#
	}#
	firstOccurences = as.data.frame(as.matrix(firstOccurences))#
	firstOccurences[,2] = as.numeric(as.character(firstOccurences[,2]))#
	firstOccurences[,1] = as.character(firstOccurences[,1])#
#
	#forecast next 5 days by taking the average of last 5 days and extending#
#	totalGDD = gdd_profile[nrow(gdd_profile),"Cumulative"]+(3*)#
	timeLag = as.numeric(Sys.Date()-max(as.Date(weather[,"date"])))#
	totalGDD = gdd_profile[nrow(gdd_profile),"Cumulative"]+(timeLag*gdd_profile[nrow(gdd_profile),"Daily"])#
	day5Extend = totalGDD + (5*gdd_profile[nrow(gdd_profile),"Daily"])#
	currentStage = which(firstOccurences[,2]>totalGDD)[1]-1#
	comingSoonStage = which(firstOccurences[,2]>day5Extend)[1]-1#
	tempOut = c(as.character(Sys.Date()),fieldID,name,totalGDD,firstOccurences[currentStage,"Stage"],firstOccurences[comingSoonStage,"Stage"],lat,lng)#
	fullOutput = rbind(fullOutput,tempOut)#
#
}#
if(nrow(fullOutput)<1) stop("No data")#
colnames(fullOutput) = c("Estimate Date","fieldID","fieldName","Estimated GDD","Current Stage","Stage In Next 5 Days","Lat","Lng")#
#subset of fullOutput goes to gdd table#
#
tempDat = as.data.frame(fullOutput)#
rownames(tempDat) = tempDat[,"fieldID"]#
pins = SpatialPointsDataFrame(SpatialPoints(cbind(as.numeric(fullOutput[,"Lng"]),as.numeric(fullOutput[,"Lat"]))),data=tempDat)#
proj4string(pins) = "+proj=longlat +datum=WGS84" #
#now to make this into a kml shape file with colored points#
#make kml from scratch..#
pinData = as.data.frame(as.matrix(cbind(pins@data,"colorCurrent Stage"="Black","colorStage In Next 5 Days"="Black")))#
pinData[,"colorCurrent Stage"] = as.character(pinData[,"colorCurrent Stage"])#
pinData[,"colorStage In Next 5 Days"] = as.character(pinData[,"colorStage In Next 5 Days"])#
pinData[,"Current Stage"] = gsub("^$","Not Emerged",pinData[,"Current Stage"])#
pinData[,"Stage In Next 5 Days"] = gsub("^$","Not Emerged",pinData[,"Stage In Next 5 Days"])#
library(RColorBrewer)#
allStages = unique(c(as.character(unique(pinData[,"Current Stage"])),as.character(unique(pinData[,"Stage In Next 5 Days"]))))#
colors = brewer.pal(length(allStages),"RdYlGn")#
if(length(colors)<length(allStages)) colors = rep(colors,times=ceiling(length(allStages)/length(colors)))#
#
for(i in 1:length(allStages)){#
	pinData[which(pinData[,"Current Stage"]==allStages[i]),"colorCurrent Stage"] = paste(64,substr(colors[i],6,7),substr(colors[i],4,5),substr(colors[i],2,3),sep="") #paste(99,substr(colors[i],2,7),sep="")##
#rgb(col2rgb(colors[i])[,1][1],col2rgb(colors[i])[,1][2],col2rgb(colors[i])[,1][3],1,maxColorValue=255)#
	pinData[which(pinData[,"Stage In Next 5 Days"]==allStages[i]),"colorStage In Next 5 Days"] = paste(64,substr(colors[i],6,7),substr(colors[i],4,5),substr(colors[i],2,3),sep="") #paste(99,substr(colors[i],2,7),sep="")##
#rgb(col2rgb(colors[i])[,1][1],col2rgb(colors[i])[,1][2],col2rgb(colors[i])[,1][3],1,maxColorValue=255)#
}#
#
pins@data = pinData#
stageEstimate_outputName = paste("Output/CropStageEstimate_",as.character(Sys.Date()),".kml",sep="")#
tf <- stageEstimate_outputName #
kmlFile <- file(tf, "w")#
#
cat(kmlPolygon(kmlname="PolygonViz")$header, #
file=kmlFile, sep="\n")#
for(stageForecast in c("Current Stage","Stage In Next 5 Days")){#
		cat(paste("<Folder><name>",stageForecast,"</name>",sep=""),   file=kmlFile, sep="\n")#
	for(k in unique(pins@data[,stageForecast])){    #
		cat(paste("<Folder><name>",k,"</name>",sep=""),   file=kmlFile, sep="\n")#
		tempD = pins@data[which(pins@data[,stageForecast]==k),]#
	    for(i in 1:nrow(tempD )){#
		    	addText = paste('#
		  <Placemark> <name> ',gsub("&","",tempD [i,"fieldName"]),' </name> <Style id="Mavrx Airport">      <IconStyle>        <Icon>          <href>http://www.clker.com/cliparts/4/5/c/0/12249615002008292168Japanese_Map_symbol_(Orchard).svg.med.png</href>             <scale> 0.5 </scale></Icon> <color> ',tempD [i,paste("color",stageForecast,sep="")],'</color> </IconStyle>    </Style>  <Point><coordinates> ',tempD [i,"Lng"],',',tempD [i,"Lat"],',0</coordinates> </Point> </Placemark>',sep='')#
		cat(addText,file=kmlFile,sep="\n")#
		}#
		cat("</Folder>",   file=kmlFile, sep="\n")#
	}#
	cat("</Folder>",   file=kmlFile, sep="\n")#
}#
#
cat(kmlPolygon()$footer, file=kmlFile, sep="\n")#
close(kmlFile)#
#just plot all fields we have in db with pins#
tf <- paste("Output/AllFieldsPin_",as.character(Sys.Date()),".kml",sep="")#
kmlFile <- file(tf, "w")#
#
cat(kmlPolygon(kmlname=paste("All_Fields_",as.character(Sys.Date())))$header, #
file=kmlFile, sep="\n")#
#
 for(i in 1:nrow(allFields )){#
		   addText = paste('#
		  <Placemark> <name> ',gsub("&","",allFields[i,"name"]),' </name> <Style id="Mavrx Airport">      <IconStyle>        <Icon>          <href>http://www.clker.com/cliparts/4/5/c/0/12249615002008292168Japanese_Map_symbol_(Orchard).svg.med.png</href>             <scale> 0.5 </scale></Icon> <color> 501400E6</color> </IconStyle>    </Style>  <Point><coordinates> ',allFields[i,"defaultLongitude"],',',allFields[i,"defaultLatitude"],',0</coordinates> </Point> </Placemark>',sep='')#
		cat(addText,file=kmlFile,sep="\n")#
		}#
cat(kmlPolygon()$footer, file=kmlFile, sep="\n")#
close(kmlFile)#
#
csv_outputName = gsub(".kml$",".csv",stageEstimate_outputName)#
#
write.csv(pinData[,1:6],csv_outputName,row.names=F)#
#
#make these read from external#
#
emailUser = vars[["EMAIL_USER"]]#
emailPassword = vars[["EMAIL_PASSWORD"]]#
send.mail(from = "chris@mavrx.co",#
          to = c("chris@mavrx.co"),#
          subject = paste("GDD Update for ",Sys.Date(),sep=""),#
          body = "See attached.",#
          html = TRUE,#
          smtp = list(host.name = "email-smtp.us-east-1.amazonaws.com", port = 587, user.name = emailUser, passwd = emailPassword , ssl = TRUE),#
          attach.files = c(stageEstimate_outputName,csv_outputName),#
          authenticate = TRUE,#
          send = TRUE)#
#make a kml output to just show all fields as well#
#
#map this to csv list of gdd ranges
emailUser = ENV[["EMAIL_USER"]]#
emailPassword = ENV[["EMAIL_PASSWORD"]]
emailUser
emailPassword
Sys.getenv("SOCIALTEETHCREDENTIALS")
Sys.getenv("SOCIALTEETH_CREDENTIALS")
Sys.getenv("OLD_PWD")
Sys.getenv("Home")
Sys.getenv("HOME")
Sys.getenv("LOGNAME")
Sys.getenv("SOCIALTEETH_CREDENTIALS")
Sys.getenv()
?Sys.getenv
Sys.getenv(names=T)
stage_gdd_mapping
cornDates = read.csv("Input/corn_imaging_periods.csv",stringsAsFactors=F)
getwd()
weather scrape procedure#
setwd("~/Desktop/aeolous_scripts/gddGetter/Output")#
#
removeOldFiles = list.files()#
for(eachFile in removeOldFiles){#
	unlink(eachFile)#
}#
#
setwd("~/Desktop/gddGetter")#
list.of.packages = c("RMySQL","mailR","maptools","RColorBrewer","sp")#
#
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]#
if(length(new.packages)) install.packages(new.packages,repos="http://cran.rstudio.com/")#
gdd_calculate = function(weather,max_threshold,min_threshold){#
	#assumes input array starts at plant date,#
	dailyGDD = matrix(ncol=1,apply(weather,1,function(temp){#
		(((max(min_threshold,min(max_threshold,as.numeric(temp["t_max"])))+min(max_threshold,max(min_threshold,as.numeric(temp["t_min"])))))/2)-min_threshold#
	}))#
	cumulativeGDD = cumsum(dailyGDD)#
	output = cbind(dailyGDD,cumulativeGDD)#
	colnames(output) = c("Daily","Cumulative")#
	return(output)#
}#
library(RMySQL)#
library(mailR)#
library(maptools)#
library(sp)#
library(RColorBrewer)#
#
DBNAME = "mavrx"#
cornDates = read.csv("Input/corn_imaging_periods.csv",stringsAsFactors=F)
weather scrape procedure#
setwd("~/Desktop/aeolous_script/gddGetter/Output")#
#
removeOldFiles = list.files()#
for(eachFile in removeOldFiles){#
	unlink(eachFile)#
}#
#
setwd("~/Desktop/gddGetter")#
list.of.packages = c("RMySQL","mailR","maptools","RColorBrewer","sp")#
#
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]#
if(length(new.packages)) install.packages(new.packages,repos="http://cran.rstudio.com/")#
gdd_calculate = function(weather,max_threshold,min_threshold){#
	#assumes input array starts at plant date,#
	dailyGDD = matrix(ncol=1,apply(weather,1,function(temp){#
		(((max(min_threshold,min(max_threshold,as.numeric(temp["t_max"])))+min(max_threshold,max(min_threshold,as.numeric(temp["t_min"])))))/2)-min_threshold#
	}))#
	cumulativeGDD = cumsum(dailyGDD)#
	output = cbind(dailyGDD,cumulativeGDD)#
	colnames(output) = c("Daily","Cumulative")#
	return(output)#
}#
library(RMySQL)#
library(mailR)#
library(maptools)#
library(sp)#
library(RColorBrewer)
DBNAME = "mavrx"#
cornDates = read.csv("Input/corn_imaging_periods.csv",stringsAsFactors=F)
getwd()
weather scrape procedure#
setwd("~/Desktop/aeolus_scripts/gddGetter/Output")#
#
removeOldFiles = list.files()#
for(eachFile in removeOldFiles){#
	unlink(eachFile)#
}#
#
setwd("~/Desktop/gddGetter")#
list.of.packages = c("RMySQL","mailR","maptools","RColorBrewer","sp")#
#
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]#
if(length(new.packages)) install.packages(new.packages,repos="http://cran.rstudio.com/")#
gdd_calculate = function(weather,max_threshold,min_threshold){#
	#assumes input array starts at plant date,#
	dailyGDD = matrix(ncol=1,apply(weather,1,function(temp){#
		(((max(min_threshold,min(max_threshold,as.numeric(temp["t_max"])))+min(max_threshold,max(min_threshold,as.numeric(temp["t_min"])))))/2)-min_threshold#
	}))#
	cumulativeGDD = cumsum(dailyGDD)#
	output = cbind(dailyGDD,cumulativeGDD)#
	colnames(output) = c("Daily","Cumulative")#
	return(output)#
}#
library(RMySQL)#
library(mailR)#
library(maptools)#
library(sp)#
library(RColorBrewer)#
#
DBNAME = "mavrx"#
cornDates = read.csv("Input/corn_imaging_periods.csv",stringsAsFactors=F)
getwd()
setwd("~/Desktop/aeolus_scripts/gddGetter")#
list.of.packages = c("RMySQL","mailR","maptools","RColorBrewer","sp")#
#
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]#
if(length(new.packages)) install.packages(new.packages,repos="http://cran.rstudio.com/")#
gdd_calculate = function(weather,max_threshold,min_threshold){#
	#assumes input array starts at plant date,#
	dailyGDD = matrix(ncol=1,apply(weather,1,function(temp){#
		(((max(min_threshold,min(max_threshold,as.numeric(temp["t_max"])))+min(max_threshold,max(min_threshold,as.numeric(temp["t_min"])))))/2)-min_threshold#
	}))#
	cumulativeGDD = cumsum(dailyGDD)#
	output = cbind(dailyGDD,cumulativeGDD)#
	colnames(output) = c("Daily","Cumulative")#
	return(output)#
}#
library(RMySQL)#
library(mailR)#
library(maptools)#
library(sp)#
library(RColorBrewer)#
#
DBNAME = "mavrx"#
cornDates = read.csv("Input/corn_imaging_periods.csv",stringsAsFactors=F)
cornDates
ENV = fromJSON(file="environment_variables.json")#
#
db = dbConnect(MySQL(), user=ENV[["USER"]],password=ENV[["PASSWD"]],dbname=ENV[["DB"]],host=ENV[["HOST"]])#
#
query = paste("SELECT fieldID,name,defaultLatitude,defaultLongitude,planting_date from fields")#
rs = dbSendQuery(db, query)#
allFields = fetch(rs, n=-1)#
#
fullOutput = c()
stage_gdd
stage_gdd
totalGDD
corn_imagingDates
corn_imaging_dates
cornDates
which(cornDates[,"GDD.END"]>totalGDD)
which(cornDates[,"GDD.End"]>totalGDD)
which(cornDates[,"GDD.End"]>totalGDD)[1]
gdd_profile
mean(gdd_profile[max(1,(nrow(gdd_profile)-3):nrow(gdd_profile)),"Daily"],na.rm=T)
GDDtilNextImage = cornDates[which(cornDates[,"GDD.End"]>totalGDD)[1],"GDD.Start"]-totalGDD#
	daysTilnextImage = GDDtilNextImage/mean(gdd_profile[max(1,(nrow(gdd_profile)-3):nrow(gdd_profile)),"Daily"],na.rm=T)
GDDtilNextImage = cornDates[which(cornDates[,"GDD.End"]>totalGDD)[1],"GDD.Start"]-totalGDD
GDDtilNextImage
round(GDDtilNextImage/mean(gdd_profile[max(1,(nrow(gdd_profile)-3):nrow(gdd_profile)),"Daily"],na.rm=T))
cornDates[which(cornDates[,"GDD.End"]>totalGDD)[1],"GDD.Start"]
cornDates
fullOutput = c()#
#
for(eachFieldIndex in 1:nrow(allFields)){#
	fieldID = allFields[eachFieldIndex,"fieldID"]#
	name = allFields[eachFieldIndex,"name"]#
	lat =  allFields[eachFieldIndex,"defaultLatitude"]#
	lng =   allFields[eachFieldIndex,"defaultLongitude"]#
	plantDat =  allFields[eachFieldIndex,"planting_date"]#
	### #need to look up plant date, if that fails, look for USDA estimate for that state, if that fails use April 1 ####
	if(is.null(plantDat)) next#
	query = paste("SELECT * from weatherdata where field_id = '",fieldID,"' AND date >= '",as.Date(plantDat),"'",sep="")#
	rs = dbSendQuery(db, query)#
	weather = fetch(rs, n=-1)#
	if(nrow(weather)<1) {#
		print(paste("No weather date for fieldID ",fieldID))#
		next#
	}#
	query = paste("SELECT crop_id from fields_crops where fields_id = '",fieldID,"'",sep="")#
	rs = dbSendQuery(db, query)#
	crop = fetch(rs, n=-1)#
	crop = matrix(nrow=1,"corn")#
	if(nrow(crop)<1){#
		print(paste("No crop type for fieldID ",fieldID))#
		next#
	}#
	gdd_profile = gdd_calculate(weather,30,10)#
	stage_gdd_mapping = read.csv("Input/110DayCorn.csv",stringsAsFactors=F)  #need smarter way of choosing this reference#
	stage_gdd_mapping[,"Estimate"] = gsub("[^0-9]","",stage_gdd_mapping[,"Estimate"])#
	firstOccurences = c()#
	for(eachStage in unique(stage_gdd_mapping[,"Stage"])){#
		firstMatch = which(stage_gdd_mapping[,"Stage"]==eachStage)[1]#
		firstOccurences = rbind(firstOccurences,stage_gdd_mapping[firstMatch,c("Stage","Estimate")])#
	}#
	firstOccurences = as.data.frame(as.matrix(firstOccurences))#
	firstOccurences[,2] = as.numeric(as.character(firstOccurences[,2]))#
	firstOccurences[,1] = as.character(firstOccurences[,1])#
#
	#forecast next 5 days by taking the average of last 5 days and extending#
#	totalGDD = gdd_profile[nrow(gdd_profile),"Cumulative"]+(3*)#
	timeLag = as.numeric(Sys.Date()-max(as.Date(weather[,"date"])))#
	totalGDD = gdd_profile[nrow(gdd_profile),"Cumulative"]+(timeLag*gdd_profile[nrow(gdd_profile),"Daily"])#
	if(length(which(cornDates[,"GDD.End"]>totalGDD))){#
	     GDDtilNextImage = cornDates[which(cornDates[,"GDD.End"]>totalGDD)[1],"GDD.Start"]-totalGDD#
	     nextEventName = cornDates[which(cornDates[,"GDD.End"]>totalGDD)[1],"ImagingEvent"]#
	     daysTilNextImage = round(GDDtilNextImage/mean(gdd_profile[max(1,(nrow(gdd_profile)-3):nrow(gdd_profile)),"Daily"],na.rm=T))#
		dateOfImagingEvent = Sys.Date()+daysTilNextImage#
	}else{#
		nextEventName = "Complete"#
		dateOfImagingEvent = "Complete"#
		daysTilNextImage = "Complete"#
		next#
	}#
	day5Extend = totalGDD + (5*gdd_profile[nrow(gdd_profile),"Daily"])#
	currentStage = which(firstOccurences[,2]>totalGDD)[1]-1#
	comingSoonStage = which(firstOccurences[,2]>day5Extend)[1]-1#
	tempOut = c(as.character(Sys.Date()),fieldID,name,totalGDD,firstOccurences[currentStage,"Stage"],firstOccurences[comingSoonStage,"Stage"],  nextEventName ,dateOfImagingEvent,daysTilNextImage,lat,lng)#
	fullOutput = rbind(fullOutput,tempOut)#
#
}
fullOutput
if(nrow(fullOutput)<1) stop("No data")#
colnames(fullOutput) = c("Estimate Date","fieldID","fieldName","Estimated GDD","Current Stage","Stage In Next 5 Days","Next Imaging Event Stage","Date of next Image Event","Days till Flight","Lat","Lng")
nextEventName
totalGDD
GDDtilNextImage = cornDates[which(cornDates[,"GDD.End"]>totalGDD)[1],"GDD.Start"]-totalGDD
GDDtilNextImage
cornDates[which(cornDates[,"GDD.End"]>totalGDD)[1],"ImagingEvent"]
which(cornDates[,"GDD.End"]>totalGDD)[1]
cornDates
nextEventName = cornDates[which(cornDates[,"GDD.End"]>totalGDD)[1],"Imaging.Event"]#
	     daysTilNextImage = round(GDDtilNextImage/mean(gdd_profile[max(1,(nrow(gdd_profile)-3):nrow(gdd_profile)),"Daily"],na.rm=T))
nextEventName
daysTilNextImage
dateOfImagingEvent
Sys.Date()+daysTilNextImage
daysTilNextImage
fullOutput = c()#
#
for(eachFieldIndex in 1:nrow(allFields)){#
	fieldID = allFields[eachFieldIndex,"fieldID"]#
	name = allFields[eachFieldIndex,"name"]#
	lat =  allFields[eachFieldIndex,"defaultLatitude"]#
	lng =   allFields[eachFieldIndex,"defaultLongitude"]#
	plantDat =  allFields[eachFieldIndex,"planting_date"]#
	### #need to look up plant date, if that fails, look for USDA estimate for that state, if that fails use April 1 ####
	if(is.null(plantDat)) next#
	query = paste("SELECT * from weatherdata where field_id = '",fieldID,"' AND date >= '",as.Date(plantDat),"'",sep="")#
	rs = dbSendQuery(db, query)#
	weather = fetch(rs, n=-1)#
	if(nrow(weather)<1) {#
		print(paste("No weather date for fieldID ",fieldID))#
		next#
	}#
	query = paste("SELECT crop_id from fields_crops where fields_id = '",fieldID,"'",sep="")#
	rs = dbSendQuery(db, query)#
	crop = fetch(rs, n=-1)#
	crop = matrix(nrow=1,"corn")#
	if(nrow(crop)<1){#
		print(paste("No crop type for fieldID ",fieldID))#
		next#
	}#
	gdd_profile = gdd_calculate(weather,30,10)#
	stage_gdd_mapping = read.csv("Input/110DayCorn.csv",stringsAsFactors=F)  #need smarter way of choosing this reference#
	stage_gdd_mapping[,"Estimate"] = gsub("[^0-9]","",stage_gdd_mapping[,"Estimate"])#
	firstOccurences = c()#
	for(eachStage in unique(stage_gdd_mapping[,"Stage"])){#
		firstMatch = which(stage_gdd_mapping[,"Stage"]==eachStage)[1]#
		firstOccurences = rbind(firstOccurences,stage_gdd_mapping[firstMatch,c("Stage","Estimate")])#
	}#
	firstOccurences = as.data.frame(as.matrix(firstOccurences))#
	firstOccurences[,2] = as.numeric(as.character(firstOccurences[,2]))#
	firstOccurences[,1] = as.character(firstOccurences[,1])#
#
	#forecast next 5 days by taking the average of last 5 days and extending#
#	totalGDD = gdd_profile[nrow(gdd_profile),"Cumulative"]+(3*)#
	timeLag = as.numeric(Sys.Date()-max(as.Date(weather[,"date"])))#
	totalGDD = gdd_profile[nrow(gdd_profile),"Cumulative"]+(timeLag*gdd_profile[nrow(gdd_profile),"Daily"])#
	if(length(which(cornDates[,"GDD.End"]>totalGDD))){#
	     GDDtilNextImage = cornDates[which(cornDates[,"GDD.End"]>totalGDD)[1],"GDD.Start"]-totalGDD#
	     nextEventName = cornDates[which(cornDates[,"GDD.End"]>totalGDD)[1],"Imaging.Event"]#
	     daysTilNextImage = round(GDDtilNextImage/mean(gdd_profile[max(1,(nrow(gdd_profile)-3):nrow(gdd_profile)),"Daily"],na.rm=T))#
		dateOfImagingEvent = Sys.Date()+daysTilNextImage#
	}else{#
		nextEventName = "Complete"#
		dateOfImagingEvent = "Complete"#
		daysTilNextImage = "Complete"#
		next#
	}#
	day5Extend = totalGDD + (5*gdd_profile[nrow(gdd_profile),"Daily"])#
	currentStage = which(firstOccurences[,2]>totalGDD)[1]-1#
	comingSoonStage = which(firstOccurences[,2]>day5Extend)[1]-1#
	tempOut = c(as.character(Sys.Date()),fieldID,name,totalGDD,firstOccurences[currentStage,"Stage"],firstOccurences[comingSoonStage,"Stage"],  nextEventName ,dateOfImagingEvent,daysTilNextImage,lat,lng)#
	fullOutput = rbind(fullOutput,tempOut)#
#
}#
if(nrow(fullOutput)<1) stop("No data")#
colnames(fullOutput) = c("Estimate Date","fieldID","fieldName","Estimated GDD","Current Stage","Stage In Next 5 Days","Next Imaging Event Stage","Date of next Image Event","Days till Flight","Lat","Lng")
fullOutput
Sys.Date()+daysTilNextImage
fullOutput = c()#
#
for(eachFieldIndex in 1:nrow(allFields)){#
	fieldID = allFields[eachFieldIndex,"fieldID"]#
	name = allFields[eachFieldIndex,"name"]#
	lat =  allFields[eachFieldIndex,"defaultLatitude"]#
	lng =   allFields[eachFieldIndex,"defaultLongitude"]#
	plantDat =  allFields[eachFieldIndex,"planting_date"]#
	### #need to look up plant date, if that fails, look for USDA estimate for that state, if that fails use April 1 ####
	if(is.null(plantDat)) next#
	query = paste("SELECT * from weatherdata where field_id = '",fieldID,"' AND date >= '",as.Date(plantDat),"'",sep="")#
	rs = dbSendQuery(db, query)#
	weather = fetch(rs, n=-1)#
	if(nrow(weather)<1) {#
		print(paste("No weather date for fieldID ",fieldID))#
		next#
	}#
	query = paste("SELECT crop_id from fields_crops where fields_id = '",fieldID,"'",sep="")#
	rs = dbSendQuery(db, query)#
	crop = fetch(rs, n=-1)#
	crop = matrix(nrow=1,"corn")#
	if(nrow(crop)<1){#
		print(paste("No crop type for fieldID ",fieldID))#
		next#
	}#
	gdd_profile = gdd_calculate(weather,30,10)#
	stage_gdd_mapping = read.csv("Input/110DayCorn.csv",stringsAsFactors=F)  #need smarter way of choosing this reference#
	stage_gdd_mapping[,"Estimate"] = gsub("[^0-9]","",stage_gdd_mapping[,"Estimate"])#
	firstOccurences = c()#
	for(eachStage in unique(stage_gdd_mapping[,"Stage"])){#
		firstMatch = which(stage_gdd_mapping[,"Stage"]==eachStage)[1]#
		firstOccurences = rbind(firstOccurences,stage_gdd_mapping[firstMatch,c("Stage","Estimate")])#
	}#
	firstOccurences = as.data.frame(as.matrix(firstOccurences))#
	firstOccurences[,2] = as.numeric(as.character(firstOccurences[,2]))#
	firstOccurences[,1] = as.character(firstOccurences[,1])#
#
	#forecast next 5 days by taking the average of last 5 days and extending#
#	totalGDD = gdd_profile[nrow(gdd_profile),"Cumulative"]+(3*)#
	timeLag = as.numeric(Sys.Date()-max(as.Date(weather[,"date"])))#
	totalGDD = gdd_profile[nrow(gdd_profile),"Cumulative"]+(timeLag*gdd_profile[nrow(gdd_profile),"Daily"])#
	if(length(which(cornDates[,"GDD.End"]>totalGDD))){#
	     GDDtilNextImage = cornDates[which(cornDates[,"GDD.End"]>totalGDD)[1],"GDD.Start"]-totalGDD#
	     nextEventName = cornDates[which(cornDates[,"GDD.End"]>totalGDD)[1],"Imaging.Event"]#
	     daysTilNextImage = max(0,round(GDDtilNextImage/mean(gdd_profile[max(1,(nrow(gdd_profile)-3):nrow(gdd_profile)),"Daily"],na.rm=T)))#
		dateOfImagingEvent = as.character(Sys.Date()+daysTilNextImage)#
	}else{#
		nextEventName = "Complete"#
		dateOfImagingEvent = "Complete"#
		daysTilNextImage = "Complete"#
		next#
	}#
	day5Extend = totalGDD + (5*gdd_profile[nrow(gdd_profile),"Daily"])#
	currentStage = which(firstOccurences[,2]>totalGDD)[1]-1#
	comingSoonStage = which(firstOccurences[,2]>day5Extend)[1]-1#
	tempOut = c(as.character(Sys.Date()),fieldID,name,totalGDD,firstOccurences[currentStage,"Stage"],firstOccurences[comingSoonStage,"Stage"],  nextEventName ,dateOfImagingEvent,daysTilNextImage,lat,lng)#
	fullOutput = rbind(fullOutput,tempOut)#
#
}#
if(nrow(fullOutput)<1) stop("No data")#
colnames(fullOutput) = c("Estimate Date","fieldID","fieldName","Estimated GDD","Current Stage","Stage In Next 5 Days","Next Imaging Event Stage","Date of next Image Event","Days till Flight","Lat","Lng")
fullOutput
ln(gdd_prodile[,1],1:nrow(gdd_profile))
lm(gdd_prodile[,1],1:nrow(gdd_profile))
?lm
gdd_profile
GDDtilNextImage
as.Date(plantDat)
weather
Sys.Date()-365
query = paste("SELECT * from weatherdata where field_id = '",fieldID,"' AND date >= '",(Sys.Date()-365)," AND 'date <='",Sys.Date()-330,"'",sep="")
query
rs = dbSendQuery(db, query)#
		weather = fetch(rs, n=-1)
query
query = paste("SELECT * from weatherdata where field_id = '",fieldID,"' AND date >= '",(Sys.Date()-365),"' AND 'date <='",Sys.Date()-330,"'",sep="")#
		rs = dbSendQuery(db, query)#
		weather = fetch(rs, n=-1)
query
query = paste("SELECT * from weatherdata where field_id = '",fieldID,"' AND date >= '",(Sys.Date()-365),"' AND date <='",Sys.Date()-330,"'",sep="")#
		rs = dbSendQuery(db, query)#
		weather = fetch(rs, n=-1)
weather
date
weather
fullOut
fullOutput
fieldID="226"
query = paste("SELECT * from weatherdata where field_id = '",fieldID,"' AND date >= '",(Sys.Date()-365),"' AND date <='",Sys.Date()-330,"'",sep="")#
		rs = dbSendQuery(db, query)#
		weather = fetch(rs, n=-1)
weather
gdd_forecast_profile = gdd_calculate(weather,30,10)
gdd_forecast_profile
GDDtilNextImage
which(gdd_forecast_profile>GDDtilNextImage)[1]
gdd_forecast_profile
which(gdd_forecast_profile[,"Cumulative"]>GDDtilNextImage)[1]
fullOutput = c()#
#
for(eachFieldIndex in 1:nrow(allFields)){#
	fieldID = allFields[eachFieldIndex,"fieldID"]#
	name = allFields[eachFieldIndex,"name"]#
	lat =  allFields[eachFieldIndex,"defaultLatitude"]#
	lng =   allFields[eachFieldIndex,"defaultLongitude"]#
	plantDat =  allFields[eachFieldIndex,"planting_date"]#
	### #need to look up plant date, if that fails, look for USDA estimate for that state, if that fails use April 1 ####
	if(is.null(plantDat)) next#
	query = paste("SELECT * from weatherdata where field_id = '",fieldID,"' AND date >= '",as.Date(plantDat),"'",sep="")#
	rs = dbSendQuery(db, query)#
	weather = fetch(rs, n=-1)#
	if(nrow(weather)<1) {#
		print(paste("No weather date for fieldID ",fieldID))#
		next#
	}#
	query = paste("SELECT crop_id from fields_crops where fields_id = '",fieldID,"'",sep="")#
	rs = dbSendQuery(db, query)#
	crop = fetch(rs, n=-1)#
	crop = matrix(nrow=1,"corn")#
	if(nrow(crop)<1){#
		print(paste("No crop type for fieldID ",fieldID))#
		next#
	}#
	gdd_profile = gdd_calculate(weather,30,10)#
	stage_gdd_mapping = read.csv("Input/110DayCorn.csv",stringsAsFactors=F)  #need smarter way of choosing this reference#
	stage_gdd_mapping[,"Estimate"] = gsub("[^0-9]","",stage_gdd_mapping[,"Estimate"])#
	firstOccurences = c()#
	for(eachStage in unique(stage_gdd_mapping[,"Stage"])){#
		firstMatch = which(stage_gdd_mapping[,"Stage"]==eachStage)[1]#
		firstOccurences = rbind(firstOccurences,stage_gdd_mapping[firstMatch,c("Stage","Estimate")])#
	}#
	firstOccurences = as.data.frame(as.matrix(firstOccurences))#
	firstOccurences[,2] = as.numeric(as.character(firstOccurences[,2]))#
	firstOccurences[,1] = as.character(firstOccurences[,1])#
#
	#forecast next 5 days by taking the average of last 5 days and extending#
#	totalGDD = gdd_profile[nrow(gdd_profile),"Cumulative"]+(3*)#
	timeLag = as.numeric(Sys.Date()-max(as.Date(weather[,"date"])))#
	totalGDD = gdd_profile[nrow(gdd_profile),"Cumulative"]+(timeLag*gdd_profile[nrow(gdd_profile),"Daily"])#
	if(length(which(cornDates[,"GDD.End"]>totalGDD))){#
		query = paste("SELECT * from weatherdata where field_id = '",fieldID,"' AND date >= '",(Sys.Date()-365),"' AND date <='",Sys.Date()-330,"'",sep="")#
		rs = dbSendQuery(db, query)#
		weather = fetch(rs, n=-1)#
		gdd_forecast_profile = gdd_calculate(weather,30,10)#
	     GDDtilNextImage = cornDates[which(cornDates[,"GDD.End"]>totalGDD)[1],"GDD.Start"]-totalGDD#
	    daysTilNextImage = which(gdd_forecast_profile[,"Cumulative"]>GDDtilNextImage)[1]#
	     if(length(   daysTilNextImage )){#
		     nextEventName = cornDates[which(cornDates[,"GDD.End"]>totalGDD)[1],"Imaging.Event"]#
			dateOfImagingEvent = as.character(Sys.Date()+daysTilNextImage)#
		}else{#
			daysTilNextImage = "More than 30 days"#
			dateOfImagingEvent = "More than 30 days"			#
			}#
		}else#
		nextEventName = "Complete"#
		dateOfImagingEvent = "Complete"#
		daysTilNextImage = "Complete"#
		next#
	}#
	day5Extend = totalGDD + (5*gdd_profile[nrow(gdd_profile),"Daily"])#
	currentStage = which(firstOccurences[,2]>totalGDD)[1]-1#
	comingSoonStage = which(firstOccurences[,2]>day5Extend)[1]-1#
	tempOut = c(as.character(Sys.Date()),fieldID,name,totalGDD,firstOccurences[currentStage,"Stage"],firstOccurences[comingSoonStage,"Stage"],  nextEventName ,dateOfImagingEvent,daysTilNextImage,lat,lng)#
	fullOutput = rbind(fullOutput,tempOut)#
#
}
fullOutput = c()#
#
for(eachFieldIndex in 1:nrow(allFields)){#
	fieldID = allFields[eachFieldIndex,"fieldID"]#
	name = allFields[eachFieldIndex,"name"]#
	lat =  allFields[eachFieldIndex,"defaultLatitude"]#
	lng =   allFields[eachFieldIndex,"defaultLongitude"]#
	plantDat =  allFields[eachFieldIndex,"planting_date"]#
	### #need to look up plant date, if that fails, look for USDA estimate for that state, if that fails use April 1 ####
	if(is.null(plantDat)) next#
	query = paste("SELECT * from weatherdata where field_id = '",fieldID,"' AND date >= '",as.Date(plantDat),"'",sep="")#
	rs = dbSendQuery(db, query)#
	weather = fetch(rs, n=-1)#
	if(nrow(weather)<1) {#
		print(paste("No weather date for fieldID ",fieldID))#
		next#
	}#
	query = paste("SELECT crop_id from fields_crops where fields_id = '",fieldID,"'",sep="")#
	rs = dbSendQuery(db, query)#
	crop = fetch(rs, n=-1)#
	crop = matrix(nrow=1,"corn")#
	if(nrow(crop)<1){#
		print(paste("No crop type for fieldID ",fieldID))#
		next#
	}#
	gdd_profile = gdd_calculate(weather,30,10)#
	stage_gdd_mapping = read.csv("Input/110DayCorn.csv",stringsAsFactors=F)  #need smarter way of choosing this reference#
	stage_gdd_mapping[,"Estimate"] = gsub("[^0-9]","",stage_gdd_mapping[,"Estimate"])#
	firstOccurences = c()#
	for(eachStage in unique(stage_gdd_mapping[,"Stage"])){#
		firstMatch = which(stage_gdd_mapping[,"Stage"]==eachStage)[1]#
		firstOccurences = rbind(firstOccurences,stage_gdd_mapping[firstMatch,c("Stage","Estimate")])#
	}#
	firstOccurences = as.data.frame(as.matrix(firstOccurences))#
	firstOccurences[,2] = as.numeric(as.character(firstOccurences[,2]))#
	firstOccurences[,1] = as.character(firstOccurences[,1])#
#
	#forecast next 5 days by taking the average of last 5 days and extending#
#	totalGDD = gdd_profile[nrow(gdd_profile),"Cumulative"]+(3*)#
	timeLag = as.numeric(Sys.Date()-max(as.Date(weather[,"date"])))#
	totalGDD = gdd_profile[nrow(gdd_profile),"Cumulative"]+(timeLag*gdd_profile[nrow(gdd_profile),"Daily"])#
	if(length(which(cornDates[,"GDD.End"]>totalGDD))){#
		query = paste("SELECT * from weatherdata where field_id = '",fieldID,"' AND date >= '",(Sys.Date()-365),"' AND date <='",Sys.Date()-330,"'",sep="")#
		rs = dbSendQuery(db, query)#
		weather = fetch(rs, n=-1)#
		gdd_forecast_profile = gdd_calculate(weather,30,10)#
	     GDDtilNextImage = cornDates[which(cornDates[,"GDD.End"]>totalGDD)[1],"GDD.Start"]-totalGDD#
	    daysTilNextImage = which(gdd_forecast_profile[,"Cumulative"]>GDDtilNextImage)[1]#
	     if(length(   daysTilNextImage )){#
		     nextEventName = cornDates[which(cornDates[,"GDD.End"]>totalGDD)[1],"Imaging.Event"]#
			dateOfImagingEvent = as.character(Sys.Date()+daysTilNextImage)#
		}else{#
			daysTilNextImage = "More than 30 days"#
			dateOfImagingEvent = "More than 30 days"			#
			}#
		}else{#
		nextEventName = "Complete"#
		dateOfImagingEvent = "Complete"#
		daysTilNextImage = "Complete"#
		next#
	}#
	day5Extend = totalGDD + (5*gdd_profile[nrow(gdd_profile),"Daily"])#
	currentStage = which(firstOccurences[,2]>totalGDD)[1]-1#
	comingSoonStage = which(firstOccurences[,2]>day5Extend)[1]-1#
	tempOut = c(as.character(Sys.Date()),fieldID,name,totalGDD,firstOccurences[currentStage,"Stage"],firstOccurences[comingSoonStage,"Stage"],  nextEventName ,dateOfImagingEvent,daysTilNextImage,lat,lng)#
	fullOutput = rbind(fullOutput,tempOut)#
#
}#
if(nrow(fullOutput)<1) stop("No data")#
colnames(fullOutput) = c("Estimate Date","fieldID","fieldName","Estimated GDD","Current Stage","Stage In Next 5 Days","Next Imaging Event Stage","Date of next Image Event","Days till Flight","Lat","Lng")
fullOutput
fieldID = "221"
fieldID = "251"
query = paste("SELECT * from weatherdata where field_id = '",fieldID,"' AND date >= '",(Sys.Date()-365),"' AND date <='",Sys.Date()-330,"'",sep="")#
		rs = dbSendQuery(db, query)#
		weather = fetch(rs, n=-1)
weather
gdd_forecast_profile = gdd_calculate(weather,30,10)
gdd_forecast_profile
cornDates[which(cornDates[,"GDD.End"]>totalGDD)[1],"GDD.Start"]-totalGDD
totalGDD
allFields
eachFieldIndex = 33
fieldID = allFields[eachFieldIndex,"fieldID"]#
	name = allFields[eachFieldIndex,"name"]#
	lat =  allFields[eachFieldIndex,"defaultLatitude"]#
	lng =   allFields[eachFieldIndex,"defaultLongitude"]#
	plantDat =  allFields[eachFieldIndex,"planting_date"]
fieldID
need to look up plant date, if that fails, look for USDA estimate for that state, if that fails use April 1 ####
	if(is.null(plantDat)) next#
	query = paste("SELECT * from weatherdata where field_id = '",fieldID,"' AND date >= '",as.Date(plantDat),"'",sep="")#
	rs = dbSendQuery(db, query)#
	weather = fetch(rs, n=-1)#
	if(nrow(weather)<1) {#
		print(paste("No weather date for fieldID ",fieldID))#
		next#
	}#
	query = paste("SELECT crop_id from fields_crops where fields_id = '",fieldID,"'",sep="")#
	rs = dbSendQuery(db, query)#
	crop = fetch(rs, n=-1)#
	crop = matrix(nrow=1,"corn")#
	if(nrow(crop)<1){#
		print(paste("No crop type for fieldID ",fieldID))#
		next#
	}#
	gdd_profile = gdd_calculate(weather,30,10)#
	stage_gdd_mapping = read.csv("Input/110DayCorn.csv",stringsAsFactors=F)  #need smarter way of choosing this reference#
	stage_gdd_mapping[,"Estimate"] = gsub("[^0-9]","",stage_gdd_mapping[,"Estimate"])
firstOccurences = c()#
	for(eachStage in unique(stage_gdd_mapping[,"Stage"])){#
		firstMatch = which(stage_gdd_mapping[,"Stage"]==eachStage)[1]#
		firstOccurences = rbind(firstOccurences,stage_gdd_mapping[firstMatch,c("Stage","Estimate")])#
	}#
	firstOccurences = as.data.frame(as.matrix(firstOccurences))#
	firstOccurences[,2] = as.numeric(as.character(firstOccurences[,2]))#
	firstOccurences[,1] = as.character(firstOccurences[,1])#
#
	#forecast next 5 days by taking the average of last 5 days and extending#
#	totalGDD = gdd_profile[nrow(gdd_profile),"Cumulative"]+(3*)#
	timeLag = as.numeric(Sys.Date()-max(as.Date(weather[,"date"])))#
	totalGDD = gdd_profile[nrow(gdd_profile),"Cumulative"]+(timeLag*gdd_profile[nrow(gdd_profile),"Daily"])
totalGDD
query = paste("SELECT * from weatherdata where field_id = '",fieldID,"' AND date >= '",(Sys.Date()-365),"' AND date <='",Sys.Date()-330,"'",sep="")#
		rs = dbSendQuery(db, query)#
		weather = fetch(rs, n=-1)
weather
gdd_forecast_profile = gdd_calculate(weather,30,10)
gdd_forecast_profile
cornDates[which(cornDates[,"GDD.End"]>totalGDD)[1],"GDD.Start"]-totalGDD
gdd_forecast_profile = gdd_calculate(weather,30,10)
GDDtilNextImage = cornDates[which(cornDates[,"GDD.End"]>totalGDD)[1],"GDD.Start"]-totalGDD
GDDtilNextImage
which(gdd_forecast_profile[,"Cumulative"]>GDDtilNextImage)
daysTilNextImage = which(gdd_forecast_profile[,"Cumulative"]>GDDtilNextImage)[1]
daysTilNextImage
fullOutput = c()#
#
for(eachFieldIndex in 1:nrow(allFields)){#
	fieldID = allFields[eachFieldIndex,"fieldID"]#
	name = allFields[eachFieldIndex,"name"]#
	lat =  allFields[eachFieldIndex,"defaultLatitude"]#
	lng =   allFields[eachFieldIndex,"defaultLongitude"]#
	plantDat =  allFields[eachFieldIndex,"planting_date"]#
	### #need to look up plant date, if that fails, look for USDA estimate for that state, if that fails use April 1 ####
	if(is.null(plantDat)) next#
	query = paste("SELECT * from weatherdata where field_id = '",fieldID,"' AND date >= '",as.Date(plantDat),"'",sep="")#
	rs = dbSendQuery(db, query)#
	weather = fetch(rs, n=-1)#
	if(nrow(weather)<1) {#
		print(paste("No weather date for fieldID ",fieldID))#
		next#
	}#
	query = paste("SELECT crop_id from fields_crops where fields_id = '",fieldID,"'",sep="")#
	rs = dbSendQuery(db, query)#
	crop = fetch(rs, n=-1)#
	crop = matrix(nrow=1,"corn")#
	if(nrow(crop)<1){#
		print(paste("No crop type for fieldID ",fieldID))#
		next#
	}#
	gdd_profile = gdd_calculate(weather,30,10)#
	stage_gdd_mapping = read.csv("Input/110DayCorn.csv",stringsAsFactors=F)  #need smarter way of choosing this reference#
	stage_gdd_mapping[,"Estimate"] = gsub("[^0-9]","",stage_gdd_mapping[,"Estimate"])#
	firstOccurences = c()#
	for(eachStage in unique(stage_gdd_mapping[,"Stage"])){#
		firstMatch = which(stage_gdd_mapping[,"Stage"]==eachStage)[1]#
		firstOccurences = rbind(firstOccurences,stage_gdd_mapping[firstMatch,c("Stage","Estimate")])#
	}#
	firstOccurences = as.data.frame(as.matrix(firstOccurences))#
	firstOccurences[,2] = as.numeric(as.character(firstOccurences[,2]))#
	firstOccurences[,1] = as.character(firstOccurences[,1])#
#
	#forecast next 5 days by taking the average of last 5 days and extending#
#	totalGDD = gdd_profile[nrow(gdd_profile),"Cumulative"]+(3*)#
	timeLag = as.numeric(Sys.Date()-max(as.Date(weather[,"date"])))#
	totalGDD = gdd_profile[nrow(gdd_profile),"Cumulative"]+(timeLag*gdd_profile[nrow(gdd_profile),"Daily"])#
	if(length(which(cornDates[,"GDD.End"]>totalGDD))){#
		query = paste("SELECT * from weatherdata where field_id = '",fieldID,"' AND date >= '",(Sys.Date()-365),"' AND date <='",Sys.Date()-330,"'",sep="")#
		rs = dbSendQuery(db, query)#
		weather = fetch(rs, n=-1)#
		gdd_forecast_profile = gdd_calculate(weather,30,10)#
	     GDDtilNextImage = cornDates[which(cornDates[,"GDD.End"]>totalGDD)[1],"GDD.Start"]-totalGDD#
	    daysTilNextImage = which(gdd_forecast_profile[,"Cumulative"]>GDDtilNextImage)[1]#
	     if(length( daysTilNextImage )){#
		     nextEventName = cornDates[which(cornDates[,"GDD.End"]>totalGDD)[1],"Imaging.Event"]#
			dateOfImagingEvent = as.character(Sys.Date()+daysTilNextImage)#
		}else{#
			daysTilNextImage = "More than 30 days"#
			dateOfImagingEvent = "More than 30 days"			#
			}#
		}else{#
		nextEventName = "Complete"#
		dateOfImagingEvent = "Complete"#
		daysTilNextImage = "Complete"#
		next#
	}#
	day5Extend = totalGDD + (5*gdd_profile[nrow(gdd_profile),"Daily"])#
	currentStage = which(firstOccurences[,2]>totalGDD)[1]-1#
	comingSoonStage = which(firstOccurences[,2]>day5Extend)[1]-1#
	tempOut = c(as.character(Sys.Date()),fieldID,name,totalGDD,firstOccurences[currentStage,"Stage"],firstOccurences[comingSoonStage,"Stage"],  nextEventName ,dateOfImagingEvent,daysTilNextImage,lat,lng)#
	fullOutput = rbind(fullOutput,tempOut)#
#
}
if(nrow(fullOutput)<1) stop("No data")#
colnames(fullOutput) = c("Estimate Date","fieldID","fieldName","Estimated GDD","Current Stage","Stage In Next 5 Days","Next Imaging Event Stage","Date of next Image Event","Days till Flight","Lat","Lng")#
#subset of fullOutput goes to gdd table#
#
tempDat = as.data.frame(fullOutput)#
rownames(tempDat) = tempDat[,"fieldID"]#
pins = SpatialPointsDataFrame(SpatialPoints(cbind(as.numeric(fullOutput[,"Lng"]),as.numeric(fullOutput[,"Lat"]))),data=tempDat)#
proj4string(pins) = "+proj=longlat +datum=WGS84" #
#now to make this into a kml shape file with colored points#
#make kml from scratch..#
pinData = as.data.frame(as.matrix(cbind(pins@data,"colorCurrent Stage"="Black","colorStage In Next 5 Days"="Black")))#
pinData[,"colorCurrent Stage"] = as.character(pinData[,"colorCurrent Stage"])#
pinData[,"colorStage In Next 5 Days"] = as.character(pinData[,"colorStage In Next 5 Days"])#
pinData[,"Current Stage"] = gsub("^$","Not Emerged",pinData[,"Current Stage"])#
pinData[,"Stage In Next 5 Days"] = gsub("^$","Not Emerged",pinData[,"Stage In Next 5 Days"])#
library(RColorBrewer)#
allStages = unique(c(as.character(unique(pinData[,"Current Stage"])),as.character(unique(pinData[,"Stage In Next 5 Days"]))))#
colors = brewer.pal(length(allStages),"RdYlGn")#
if(length(colors)<length(allStages)) colors = rep(colors,times=ceiling(length(allStages)/length(colors)))#
#
for(i in 1:length(allStages)){#
	pinData[which(pinData[,"Current Stage"]==allStages[i]),"colorCurrent Stage"] = paste(64,substr(colors[i],6,7),substr(colors[i],4,5),substr(colors[i],2,3),sep="") #paste(99,substr(colors[i],2,7),sep="")##
#rgb(col2rgb(colors[i])[,1][1],col2rgb(colors[i])[,1][2],col2rgb(colors[i])[,1][3],1,maxColorValue=255)#
	pinData[which(pinData[,"Stage In Next 5 Days"]==allStages[i]),"colorStage In Next 5 Days"] = paste(64,substr(colors[i],6,7),substr(colors[i],4,5),substr(colors[i],2,3),sep="") #paste(99,substr(colors[i],2,7),sep="")##
#rgb(col2rgb(colors[i])[,1][1],col2rgb(colors[i])[,1][2],col2rgb(colors[i])[,1][3],1,maxColorValue=255)#
}#
#
pins@data = pinData#
stageEstimate_outputName = paste("Output/CropStageEstimate_",as.character(Sys.Date()),".kml",sep="")#
tf <- stageEstimate_outputName #
kmlFile <- file(tf, "w")#
#
cat(kmlPolygon(kmlname="PolygonViz")$header, #
file=kmlFile, sep="\n")#
for(stageForecast in c("Current Stage","Stage In Next 5 Days")){#
		cat(paste("<Folder><name>",stageForecast,"</name>",sep=""),   file=kmlFile, sep="\n")#
	for(k in unique(pins@data[,stageForecast])){    #
		cat(paste("<Folder><name>",k,"</name>",sep=""),   file=kmlFile, sep="\n")#
		tempD = pins@data[which(pins@data[,stageForecast]==k),]#
	    for(i in 1:nrow(tempD )){#
		    	addText = paste('#
		  <Placemark> <name> ',gsub("&","",tempD [i,"fieldName"]),' </name> <Style id="Mavrx Airport">      <IconStyle>        <Icon>          <href>http://www.clker.com/cliparts/4/5/c/0/12249615002008292168Japanese_Map_symbol_(Orchard).svg.med.png</href>             <scale> 0.5 </scale></Icon> <color> ',tempD [i,paste("color",stageForecast,sep="")],'</color> </IconStyle>    </Style>  <Point><coordinates> ',tempD [i,"Lng"],',',tempD [i,"Lat"],',0</coordinates> </Point> </Placemark>',sep='')#
		cat(addText,file=kmlFile,sep="\n")#
		}#
		cat("</Folder>",   file=kmlFile, sep="\n")#
	}#
	cat("</Folder>",   file=kmlFile, sep="\n")#
}#
#
cat(kmlPolygon()$footer, file=kmlFile, sep="\n")#
close(kmlFile)#
#just plot all fields we have in db with pins#
tf <- paste("Output/AllFieldsPin_",as.character(Sys.Date()),".kml",sep="")#
kmlFile <- file(tf, "w")#
#
cat(kmlPolygon(kmlname=paste("All_Fields_",as.character(Sys.Date())))$header, #
file=kmlFile, sep="\n")#
#
 for(i in 1:nrow(allFields )){#
		   addText = paste('#
		  <Placemark> <name> ',gsub("&","",allFields[i,"name"]),' </name> <Style id="Mavrx Airport">      <IconStyle>        <Icon>          <href>http://www.clker.com/cliparts/4/5/c/0/12249615002008292168Japanese_Map_symbol_(Orchard).svg.med.png</href>             <scale> 0.5 </scale></Icon> <color> 501400E6</color> </IconStyle>    </Style>  <Point><coordinates> ',allFields[i,"defaultLongitude"],',',allFields[i,"defaultLatitude"],',0</coordinates> </Point> </Placemark>',sep='')#
		cat(addText,file=kmlFile,sep="\n")#
		}#
cat(kmlPolygon()$footer, file=kmlFile, sep="\n")#
close(kmlFile)#
#
csv_outputName = gsub(".kml$",".csv",stageEstimate_outputName)
pinData
cornDates
pinData[,1:9],
pinData[,1:9],
pinData[,1:9]
write.csv(pinData[,1:9],csv_outputName,row.names=F)
