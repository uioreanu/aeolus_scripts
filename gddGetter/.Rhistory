"~/Desktop/geotag_v2.json"
x=fromJSON("~/Desktop/geotag_v2.json")
x=fromJSON("/Users/raufoo/Desktop/geotag_v2.json")
dat = readLines("~/Desktop/polygon.txt")
dat
strsplit(dat,",")[[1]]
polygon = c()#
for(i in coords){#
	temp = gsub("[^0-9-]","",i)#
	temps = strsplit(temp," ")[[1]]#
	polygon = rbind(polygon,temps)	#
}
coords = strsplit(dat,",")[[1]]#
polygon = c()#
for(i in coords){#
	temp = gsub("[^0-9-]","",i)#
	temps = strsplit(temp," ")[[1]]#
	polygon = rbind(polygon,temps)	#
}
polygon
temops
temps
temp
coords = strsplit(dat,",")[[1]]#
polygon = c()#
for(i in coords){#
	temp = gsub("[^0-9- ]","",i)#
	temps = strsplit(temp," ")[[1]]#
	polygon = rbind(polygon,temps)	#
}
polygon
coords = strsplit(dat,",")[[1]]#
polygon = c()#
for(i in coords){#
	temp = gsub("[^0-9- \\.]","",i)#
	temps = strsplit(temp," ")[[1]]#
	polygon = rbind(polygon,temps)	#
}
coords = strsplit(dat,",")[[1]]#
polygon = c()#
for(i in coords){#
	temp = gsub("[^0-9- .]","",i)#
	temps = strsplit(temp," ")[[1]]#
	polygon = rbind(polygon,temps)	#
}
temps
coords = strsplit(dat,",")[[1]]#
polygon = c()#
for(i in coords){#
	temp = gsub("[^0-9 \\.-]","",i)#
	temps = strsplit(temp," ")[[1]]#
	polygon = rbind(polygon,temps)	#
}
polygon
as.numeric(temps)
library(sp)#
coords = strsplit(dat,",")[[1]]#
polygon = c()#
for(i in coords){#
	temp = gsub("[^0-9 \\.-]","",i)#
	temps = as.numeric(strsplit(temp," ")[[1]])#
	polygon = rbind(polygon,temps)	#
}#
#
Polygon1 = Polygon(list(polygon))#
Polygons1 = Polygons(list(Polygon1),1)#
SpatialPolygons1 = SpatialPolygons(Polygons1,1)
Polygons1
SpatialPolygons(Polygons1,as.data.frame(1))
?SpatialPolygons
SpatialPolygons1 = SpatialPolygons(Polygons1)
SpatialPolygons1 = SpatialPolygons(list(Polygons1))
proj4string(SpatialPolygons)
proj4string(SpatialPolygons1)
?kmlLine
library(maptools)
kmlLine
?kmlLine
proj4string(SpatialPolygons) = "ellps=WGS84 +datum=WGS84 +units=m +no_defs"
proj4string(SpatialPolygons) = "+proj=longlat +datum=WGS84"
proj4string(SpatialPolygons) = CRS("+proj=longlat +datum=WGS84")
proj4string(SpatialPolygons)
proj4string(SpatialPolygons1) = "+proj=longlat +datum=WGS84"
getwd()
kmlPolygon(SpatialPolygons1 ,name="~/Desktop/geovantagetest.kmk")
SpatialPolygons2 = SpatialPolygonsDataFrame(SpatialPolygons1,1)
SpatialPolygons2 = SpatialPolygonsDataFrame(SpatialPolygons1,as.data.frame(1))
kmlPolygon(SpatialPolygons2 ,name="~/Desktop/geovantagetest.kmk")
kmlPolygon(SpatialPolygons2 ,name="~/Desktop/geovantagetest.kml")
x = kmlPolygon(SpatialPolygons2 ,name="~/Desktop/geovantagetest.kml")
x
library(rgdal)
writeOGR(SpatialPolygons2, dsn="~/Desktop/polygonWGS.kml", layer="polygonWGS", driver="KML")
writeOGR(SpatialPolygons2, dsn="~/Desktop/wut.kml", layer="polygonWGS", driver="KML")
writeOGR(SpatialPolygons2, dsn="~/Desktop/wut.kml", layer="wut", driver="KML")
writeOGR(SpatialPolygons1, dsn="~/Desktop/wut.kml", layer="wut", driver="KML")
writeOGR(SpatialPolygons2, dsn="/Users/raulfoo/Desktop/wut.kml", layer="wut", driver="KML")
proj4string(SpatialPolygons)
proj4string(SpatialPolygons2)
library(maptools)
?writeWKT
library(rgeos)
?readWKT
poly = "MULTIPOLYGON (((18.8914034400000013 -34.0856031900000005, 18.8925965699999985 -34.0864864500000024, 18.8921121999999997 -34.0869660899999971, 18.8919529200000014 -34.0875314600000010, 18.8919018200000011 -34.0881375199999965, 18.8906184099999983 -34.0882615399999978, 18.8896551200000005 -34.0884382699999975, 18.8889568600000004 -34.0884866700000018, 18.8885206799999992 -34.0881874299999978, 18.8882910200000005 -34.0875396300000020, 18.8882216499999984 -34.0868430599999996, 18.8883132799999984 -34.0860530799999992, 18.8892881300000006 -34.0857846800000033, 18.8914034400000013 -34.0856031900000005)), ((18.8926859699999987 -34.0936428699999965, 18.8957481899999991 -34.0954702699999999, 18.8979169899999988 -34.0956383799999969, 18.9019953200000010 -34.0959639000000010, 18.9018904799999987 -34.0967691600000009, 18.8994484900000010 -34.0971938599999973, 18.8978574200000011 -34.0969802299999998, 18.8957325800000007 -34.0965595699999966, 18.8918654400000001 -34.0956450099999984, 18.8926859699999987 -34.0936
428699999965)), ((18.9029422300000007 -34.0946870000000004, 18.9044054300000006 -34.0957501700000023, 18.9051837800000015 -34.0960368200000019, 18.9064328400000008 -34.0961572599999982, 18.9065879000000017 -34.0964571800000016, 18.9055977300000002 -34.0968063099999981, 18.9050241200000002 -34.0968083500000034, 18.9051426400000011 -34.0984495100000018, 18.9037250800000010 -34.0980947999999984, 18.9037211300000010 -34.0968635600000027, 18.9040871599999996 -34.0966035399999967, 18.9024139799999986 -34.0962634300000005, 18.9029422300000007 -34.0946870000000004)), ((18.9076750599999990 -34.0900148200000004, 18.9087696299999983 -34.0897556700000024, 18.9085264500000001 -34.0884173999999973, 18.9080726199999987 -34.0878966000000005, 18.9074062599999984 -34.0875906200000003, 18.9052306399999992 -34.0872317400000000, 18.9048144600000008 -34.0854232399999972, 18.9016178799999999 -34.0859619200000026, 18.9018190200000014 -34.0846008299999994, 18.9017124199999991 -34.0838914200000005, 18.9016544400000015 -34.0832242999
999977, 18.9019988400000010 -34.0832547600000026, 18.9023659200000012 -34.0831569300000012, 18.9025385200000002 -34.0831224699999993, 18.9025773900000011 -34.0829677999999987, 18.9022783799999985 -34.0827850599999991, 18.9017838900000008 -34.0831190000000035, 18.9003823400000002 -34.0819887299999991, 18.9004368000000014 -34.0810996200000034, 18.9013535300000015 -34.0803160800000029, 18.9002206299999997 -34.0799812599999967, 18.8988081200000018 -34.0801727799999981, 18.8994054399999989 -34.0788383300000035, 18.9005960100000010 -34.0776018500000006, 18.9017291100000016 -34.0769129399999997, 18.9023743199999998 -34.0763027100000002, 18.9021057100000007 -34.0755310300000005, 18.9011893999999998 -34.0757278199999973, 18.9007565799999995 -34.0754440600000024, 18.9012429299999987 -34.0747380899999968, 18.9015127199999995 -34.0742034100000026, 18.9020519699999987 -34.0741326699999973, 18.9027523899999998 -34.0740901400000027, 18.9030222300000013 -34.0738615100000004, 18.9035609399999984 -34.0738640100000012, 18.904
0441799999996 -34.0742327099999969, 18.9044734100000014 -34.0745532999999980, 18.9053346200000014 -34.0743295400000008, 18.9066763999999985 -34.0745629099999974, 18.9066719899999995 -34.0751988600000004, 18.9070941200000000 -34.0760183399999974, 18.9076288599999991 -34.0767775300000011, 18.9082631100000000 -34.0775042799999994, 18.9083110800000007 -34.0781343399999983, 18.9075020800000004 -34.0788988600000025, 18.9066396499999989 -34.0793554899999975, 18.9066340799999999 -34.0801609399999990, 18.9069017499999994 -34.0811308600000018, 18.9068943599999990 -34.0819794100000024, 18.9073676299999995 -34.0825147999999984, 18.9079361100000014 -34.0831896500000013, 18.9084004899999982 -34.0835068100000029, 18.9098625300000016 -34.0830020399999967, 18.9109696199999995 -34.0833590800000010, 18.9117619800000014 -34.0834049899999982, 18.9125503399999992 -34.0836720699999987, 18.9124361299999997 -34.0842464099999987, 18.9117811499999995 -34.0846926600000018, 18.9110627499999993 -34.0849672499999983, 18.9115658300000007
-34.0855855699999992, 18.9110419699999994 -34.0862944100000007, 18.9112510200000017 -34.0865543199999976, 18.9117245800000013 -34.0872036299999976, 18.9121977699999988 -34.0878099899999967, 18.9122131300000014 -34.0885463999999985, 18.9117962000000013 -34.0890215000000012, 18.9110134300000006 -34.0894965700000014, 18.9123808999999987 -34.0900161900000001, 18.9135725400000005 -34.0917570200000029, 18.9135151599999993 -34.0924494200000012, 18.9138781999999992 -34.0929683700000012, 18.9142999900000000 -34.0931427900000017, 18.9137043300000016 -34.0968208000000033, 18.9112538900000011 -34.0971234599999988, 18.9097797900000018 -34.0970269800000025, 18.9084193599999999 -34.0970246099999983, 18.9082055400000009 -34.0956786599999973, 18.9069036699999984 -34.0957262599999993, 18.9074321400000009 -34.0945655599999995, 18.9065029799999991 -34.0936264600000030, 18.9058272100000018 -34.0931122799999997, 18.9058815500000001 -34.0923317299999979, 18.9067073699999995 -34.0920167900000024, 18.9072267099999998 -34.0918406300
000001, 18.9080059899999995 -34.0919240599999966, 18.9076750599999990 -34.0900148200000004)), ((18.9095411599999998 -34.0765851299999980, 18.9103405699999989 -34.0764286100000007, 18.9105474300000012 -34.0732445900000016, 18.9120248699999998 -34.0731998500000017, 18.9120943799999992 -34.0746771600000002, 18.9108055499999992 -34.0763372199999992, 18.9117197799999985 -34.0759631800000022, 18.9122144699999986 -34.0757446200000018, 18.9126006800000006 -34.0757480600000022, 18.9131352300000017 -34.0757183999999995, 18.9135415400000007 -34.0751433900000009, 18.9138114799999997 -34.0752090800000005, 18.9137584399999987 -34.0778937700000029, 18.9137003899999989 -34.0787338000000020, 18.9131491800000013 -34.0789141599999965, 18.9121737799999998 -34.0784978000000010, 18.9108519999999984 -34.0784409999999980, 18.9098108099999997 -34.0777407499999967, 18.9095411599999998 -34.0765851299999980)))"#
#
library(sp)#
library(rgeos)#
library(rjson)#
#
json = fromJSON(file="geotag_v2.json")
json = fromJSON(file="~/Desktop/geotag_v2.json")
polygon = readWKT(poly)#
buffered = gBuffer(polygon,width=.002)
plot(buffered)
plot(polygon)
buffered = gBuffer(polygon,width=.0005)
plot(polygon)
buffered = gBuffer(polygon,width=.001)
plot(polygon)
plot(buffered)
buffered = gBuffer(polygon,width=.0005)
buffered = gBuffer(polygon,width=.0015)
plot(buffered)
?over
json[[1]]
points = sapply(json,function(x) c(x$Longitude,x$Latitude))
points
points = t(sapply(json,function(x) c(x$Longitude,x$Latitude)))
points
points[1,]
json[[1]]
points[1,]
points = SpatialPoints(t(sapply(json,function(x) c(x$Longitude,x$Latitude))))
points
proj4string(polygon)
proj4string(polygon) = "+proj=latlong +datum=WGS84"
proj4string(polygon) = "+proj=longat +datum=WGS84"
points = SpatialPoints(t(sapply(json,function(x) c(x$Longitude,x$Latitude))))#
proj4string(polygon) = "+proj=longat +datum=WGS84"#
proj4string(points) = proj4string(polygon)#
#
overlays = over(points,polygon)
overlays
polygon = readWKT(poly)#
proj4string(polygon) = "+proj=longat +datum=WGS84"#
#
buffered = gBuffer(polygon,width=.0015)#
#
points = SpatialPoints(t(sapply(json,function(x) c(x$Longitude,x$Latitude))))
proj4string(buffered)
overlays = over(points,buffered)
proj4string(buffered)
proj4string(points)
proj4string(points) = proj4string(polygon)
overlays = over(points,buffered)
overlays
which(is.na(overlays)==F)
newJSON = json[which(is.na(overlays)==F)]
newJSON
plot(points[which(is.na(overlays)==F,])
plot(points[which(is.na(overlays)==F),])
bbox(buffered)
bbox(buffered)[1,]
range(bbox(buffered)[1,])
xlims = range(bbox(buffered)[1,])#
ylims = range(bbox(buffered)[2,])#
plot(points[which(is.na(overlays)==F),],ylim=ylims,xlim=xlims)#
par(new=T)#
plot(buffered,ylim=ylims,xlim=xlims)
writeLines(fromJSON(newJSON),"geotag_v2_reduced.json")
writeLines(toJSON(newJSON),"geotag_v2_reduced.json")
writeLines(toJSON(newJSON),"~/Desktop/geotag_v2_reduced.json")
length(which(is.na(overlays)==F))
rm(list = ls())
gc()
?Sys.time
format(Sys.time(),%Y")
format(Sys.time(), %Y")
Sys.time
Sys.time()
library(zoo)
?kriging
library(kriging)
?krigign
?kriging
library(akima)
x = c(-119.9817, -120.4083, -119.8961, -120.4514, -119.8797, -119.7914, -119.8425, -120.3211, -120.4486, -119.6822,-119.6844, -119.6828, -119.5069, -120.6831, -120.6414, -120.5039, -120.4525, -120.6619, -120.6375)#
#
y = c( 34.5822, 34.5686, 34.4397, 34.6539, 34.4142, 34.5444, 34.4258, 34.9881, 34.8994, 34.5225, 34.4167, 34.9456, 34.4908, 35.1597, 35.2372, 35.3372, 35.3805, 35.3056, 35.3742)#
#
z =  c(  8,   0 ,  5,   0,   0,   0,   0,   0,   0,  97,   0,   0, 198,   0,  0,   0,   0,   0,   0)
length(x)
length(y)
length(z)
interTest = interp(x,y,z)
interTest
max(interTest$z)
max(interTest$z,na.rm=T)
min(interTest$z,na.rm=T)
?interp
expand.grid(x,y)
minMaxTemps[,]
?interp
?inter[]
?interp
rm(list = ls())
gc()
groupingFunc = function(x){#
	temp = c(x[1,c("date","contributor_type","recipient_party")],sum(x[,"amount"],na.rm=T))#
	names(temp) = c("date","contributor_type","recipient_party","amount")#
	return(temp)#
}
library(RMySQL)#
db = dbConnect(dbDriver("MySQL"),dbname='cfdb',group='destination')  #the trick was to specicy TCP
totalRows = 1000
totalRows = 3000
allSteps = seq(0,totalRows,by=limitStep)
limitStep = 1000#
allSteps = seq(0,totalRows,by=limitStep)
alLSteps
allSteps
i = 0
offset = NA#
	if(i>0) offset = i#
	query = paste("select date,contributor_type,bonica_cid,recipient_party,amount from newconts limit ",limitStep," offset ",offset,sep="")
query
query = paste("select date,contributor_type,bonica_cid,recipient_party,amount from newconts limit ",limitStep,sep="")
query
rs = dbSendQuery(db, query)#
	ordered_data = fetch(rs, n=-1)
nrow(ordered_data)
fullTrack = c()
output = by(ordered_data,ordered_data[,c("date","contributor_type","recipient_party")],groupingFunc,simplify=F)#
	track = do.call("rbind",output)#
	fullTrack = rbind(fullTrack,track)
nrow(fullTrack)
i = allSteps[2]
offset = NA#
	if(i>0) offset = i#
	if(is.na(offset)){#
		query = paste("select date,contributor_type,bonica_cid,recipient_party,amount from newconts limit ",limitStep,sep="")#
#
	}else{#
		query = paste("select date,contributor_type,bonica_cid,recipient_party,amount from newconts limit ",limitStep," offset ",offset,sep="")#
	}
offset
query
ordered_data[1000,]
lastOrdered = ordered_data[1000,]
query
rs = dbSendQuery(db, query)#
	ordered_data = fetch(rs, n=-1)
ordered_data[1,]
last_ordered
lastOrdered
query = paste("SELECT COUNT(*) FROM newconts")
rs = dbSendQuery(db, query)
totalRows =  fetch(rs, n=-1)
totalRows
as.numeric(totalRows)
totalRows = as.numeric(fetch(rs, n=-1))
totalRows
fetch(rs, n=-1)
rs = dbSendQuery(db, query)#
totalRows = as.numeric(fetch(rs, n=-1))
totalRows
totalRows = 15000
allSteps = seq(0,totalRows,by=limitStep)
fullTrack = c()
i = allSteps[1]
offset = NA#
	if(i>0) offset = i#
	if(is.na(offset)){#
		query = paste("select date,contributor_type,bonica_cid,recipient_party,amount from newconts limit ",limitStep,sep="")#
#
	}else{#
		query = paste("select date,contributor_type,bonica_cid,recipient_party,amount from newconts limit ",limitStep," offset ",offset,sep="")#
	}
query
limitStep = 5000
limitStep = 5000#
allSteps = seq(0,totalRows,by=limitStep)#
fullTrack = c()
i
offset = NA#
	if(i>0) offset = i#
	if(is.na(offset)){#
		query = paste("select date,contributor_type,bonica_cid,recipient_party,amount from newconts limit ",limitStep,sep="")#
#
	}else{#
		query = paste("select date,contributor_type,bonica_cid,recipient_party,amount from newconts limit ",limitStep," offset ",offset,sep="")#
	}
query
rs = dbSendQuery(db, query)#
	ordered_data = fetch(rs, n=-1)#
		output = by(ordered_data,ordered_data[,c("date","contributor_type","recipient_party")],groupingFunc,simplify=F)#
	track = do.call("rbind",output)#
	fullTrack = rbind(fullTrack,track)
nrow(fullTrack)
fullTrack[1,]
fullTrack[2,]
fullTrack[3,]
fullTrack[4,]
fullTrack[5,]
fullTrack[6,]
fullTrack[7,]
?is.Date
?is.date
as.Date("1992-10-29")
as.Date("hello")
apply(as.Data[,fullTrack[,1]])
test = as.Date[,fullTrack[,1]]
test = as.Date(fullTrack[,"date"])
fullTrack[,"date"]
fullTrack[1,]
fullTrack[2,]
fullTrack[1:2,]
fullTrack[,"date"]
lapply(fullTrack[,"date"],function(x) as.Date(x))
lapply(fullTrack[10,"date"],function(x) as.Date(x))
grep("[A-z]",fullTrack[,"date"])
invalidDates = grep("[A-z]",ordered_data[,"date"])#
	if(length(invalidDates)>0){#
		badRows = c(badRows,(invalidDates+i))#
		ordered_data =  ordered_data[-invalidDates,]#
	}
badRows = c()
invalidDates = grep("[A-z]",ordered_data[,"date"])#
	if(length(invalidDates)>0){#
		badRows = c(badRows,(invalidDates+i))#
		ordered_data =  ordered_data[-invalidDates,]#
	}
badRows
ordered_data[badRows,]
rm(list=ls())
gc()
currentDate = as.Date(commandArgs(trailingOnly=T)[[1]])#
	setwd("~/Desktop/aeolus_scripts/gddGetter")#
	unlink("ImagingPackagesLookup/*")#
	source('Scripts/createImagingPackage.R')#
	source('Scripts/parseCloudCoverXML.R')#
	list.of.packages = c("RMySQL","mailR","maptools","RColorBrewer","sp","rgeos","rjson","XML")#
	new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]#
	if(length(new.packages)) install.packages(new.packages,repos="http://cran.rstudio.com/")#
	library(RMySQL)#
	library(mailR)#
	library(maptools)#
	library(sp)#
	library(RColorBrewer)#
	library(rgeos)#
	library(rjson)#
	library(XML)#
	setwd("~/Desktop/aeolus_scripts/gddGetter/Output")#
	removeOldFiles = list.files()#
	for(eachFile in removeOldFiles){#
		unlink(eachFile)#
	}#
	grabClientImageOrder = function(driveAuthUser ,driveAuthSecret ){#
		list.of.packages = c("devtools")	#
		new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]#
		if(length(new.packages)) install.packages(new.packages,repos="http://cran.rstudio.com/")#
		library(devtools)#
		list.of.packages = c("RGoogleDocs")#
		if(length(new.packages)) {#
			install_github("RGoogleDocs", "duncantl")#
		}#
		library(RGoogleDocs)#
		ts = getWorksheets("ClientImagingPackages22", con = getGoogleDocsConnection(getGoogleAuth(driveAuthUser, driveAuthSecret,"wise")))#
		allSheets = names(ts)#
		#then split out GDDs, and find the most recent date available#
		#get the most recent, assuming the formatting is always month-day fro the current year#
		firstSheet = allSheets[1]#
		dat = sheetAsMatrix(ts[[firstSheet]], header = TRUE, as.data.frame = T, trim = TRUE,stringsAsFactors=T)#
		return(dat)	#
	}#
	gdd_calculate = function(weather,max_threshold,min_threshold){#
		#assumes input array starts at plant date,#
		dailyGDD = matrix(ncol=1,apply(weather,1,function(temp){#
			(((max(min_threshold,min(max_threshold,as.numeric(temp["t_max"])))+min(max_threshold,max(min_threshold,as.numeric(temp["t_min"])))))/2)-min_threshold#
		}))#
		cumulativeGDD = cumsum(dailyGDD)#
		output = cbind(dailyGDD,cumulativeGDD)#
		colnames(output) = c("Daily","Cumulative")#
		return(output)#
	}#
	get_average_weather = function(weather,plantDate){#
		thisYear = format(plantDate,"%Y")#
		saveColNames = colnames(weather)#
		weather[,"date"] = paste(format(as.Date(weather[,"date"]),"%m"),"-",format(as.Date(weather[,"date"]),"%d"),sep="")#
		output = by(weather,weather[,"date"],function(x){#
			return(as.data.frame(matrix(nrow=1,c(x[1,1],x[1,2],paste(thisYear,"-",x[1,3],sep=""),mean(x[,4],na.rm=T),mean(x[,5],na.rm=T),mean(x[,6],na.rm=T))),stringsAsFactors=F))#
		})#
		output = do.call("rbind",output)#
		output[,4] = as.numeric(output[,4])#
		output[,5] = as.numeric(output[,5])#
		output[,6] = as.numeric(output[,6])#
		output = output[which(as.Date(output[,3])>=plantDate),]#
		colnames(output) = saveColNames#
		return(output)#
	}#
	setwd("~/Desktop/aeolus_scripts/gddGetter")#
	cornDatesRaw = read.csv("Input/corn_imaging_periods.csv",stringsAsFactors=F)#
	ENV = fromJSON(file="environment_variables.json")#
	driveAuthUser  = ENV[["FROM"]]    #
	driveAuthSecret = ENV[["DRIVE"]]     #
	current_imaging_orders = c()#
	current_imaging_orders = grabClientImageOrder(driveAuthUser ,driveAuthSecret )#
	db = dbConnect(MySQL(), user=ENV[["USER"]],password=ENV[["PASSWD"]],dbname=ENV[["DB"]],host=ENV[["HOST"]])#
	query = paste("SELECT fieldID,name,defaultLatitude,defaultLongitude,planting_date from fields where defaultLatitude != 'NULL' AND is_active ='1' AND planting_date != 'NULL'")#
	rs = dbSendQuery(db, query)#
	allFields = fetch(rs, n=-1)#
	fullOutput = c()#
	stageList = c()#
	getDistances = function(source,targets,threshold){#
		temp=((source[1]-targets[,1])^2+(source[2]-targets[,2])^2)^.5#
		if(any(temp>threshold)){#
			return(F)#
		}else{#
			return(T)#
		}#
	}#
	#create clusters such that all points are within .5 lat/lng of a center#
	centers = nrow(allFields)#
	fieldCenters = allFields[,c("defaultLongitude","defaultLatitude")]#
	allFieldsIds = allFields[,c("fieldID")]#
	#fieldCenters = fieldCenters[duplicated(fieldCenters)==F,]#
	rownames(fieldCenters) = 1:nrow(fieldCenters)#
	numCentersStart = floor(nrow(fieldCenters)/10)#
	while(T){#
		kMeanResult = kmeans(fieldCenters,numCentersStart)#
		kMeanCenters = kMeanResult$centers#
		rownames(kMeanCenters) = c(1:nrow(kMeanCenters))#
		allDistances = c()#
		for(i in 1:nrow(kMeanCenters)){#
				returnVal = getDistances(kMeanCenters[i,],fieldCenters[as.numeric(names(kMeanResult$cluster[which(kMeanResult$cluster==i)])),],.7)#
				allDistances = c(allDistances,returnVal)#
		}#
		if(all(allDistances)) break#
		numCentersStart = numCentersStart+2#
		numCentersStart = min(numCentersStart,nrow(fieldCenters))#
	}#
	#plot(kMeanResult$centers,xlim=c(-100,-85),ylim=c(38,47),col="red")#
	#par(new=T)#
	#plot(	fieldCenters ,xlim=c(-100,-85),ylim=c(38,47),col="blue")#
	#ok that is prb fine, now make a lit to map forecast nodes to fieldIDs#
	#weatherNodeList = list()#
	#for(k in 1:nrow(kMeanResult$centers)){#
	#	weatherNodeList[[k]] = list("centers"=kMeanResult$centers[k,],"fieldIDs"=allFieldsIds[as.numeric(names(kMeanResult$cluster[which(kMeanResult$cluster==k)]))]		#
	#}#
	weatherNodeMapping=matrix(ncol=4,nrow=length(allFieldsIds))#
	weatherNodeMapping[,1]=allFieldsIds#
	weatherNodeMapping[,2] = as.numeric(as.character(kMeanResult$cluster))#
	for(z in 1:nrow(weatherNodeMapping)){#
		weatherNodeMapping[z,3:4] = kMeanCenters[weatherNodeMapping[z,2],]#
	}#
	colnames(weatherNodeMapping) = c("fieldID","weatherNodeID","defaultLongitude","defaultLatitude")#
	#dont really want to store all these#
	weatherNodeMapping=weatherNodeMapping[order(weatherNodeMapping[,2]),]#
	#allFields[order(allFields),]#
	allFields$fieldID = factor(allFields$fieldID, levels = weatherNodeMapping[,1])#
#
	allFields = allFields[order(allFields$fieldID),]#
	allFields[,"fieldID"] = as.numeric(as.character(allFields[,"fieldID"]))#
	lastNode =-99#
	weatherForecastScrape = NULL
currentDate = as.Date(commandArgs(trailingOnly=T)[[1]])#
	setwd("~/Desktop/aeolus_scripts/gddGetter")#
	unlink("ImagingPackagesLookup/*")#
	source('Scripts/createImagingPackage.R')#
	source('Scripts/parseCloudCoverXML.R')#
	list.of.packages = c("RMySQL","mailR","maptools","RColorBrewer","sp","rgeos","rjson","XML")#
	new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]#
	if(length(new.packages)) install.packages(new.packages,repos="http://cran.rstudio.com/")#
	library(RMySQL)#
	library(mailR)#
	library(maptools)#
	library(sp)#
	library(RColorBrewer)#
	library(rgeos)#
	library(rjson)#
	library(XML)#
	setwd("~/Desktop/aeolus_scripts/gddGetter/Output")#
	removeOldFiles = list.files()#
	for(eachFile in removeOldFiles){#
		unlink(eachFile)#
	}#
	grabClientImageOrder = function(driveAuthUser ,driveAuthSecret ){#
		list.of.packages = c("devtools")	#
		new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]#
		if(length(new.packages)) install.packages(new.packages,repos="http://cran.rstudio.com/")#
		library(devtools)#
		list.of.packages = c("RGoogleDocs")#
		if(length(new.packages)) {#
			install_github("RGoogleDocs", "duncantl")#
		}#
		library(RGoogleDocs)#
		ts = getWorksheets("ClientImagingPackages22", con = getGoogleDocsConnection(getGoogleAuth(driveAuthUser, driveAuthSecret,"wise")))#
		allSheets = names(ts)#
		#then split out GDDs, and find the most recent date available#
		#get the most recent, assuming the formatting is always month-day fro the current year#
		firstSheet = allSheets[1]#
		dat = sheetAsMatrix(ts[[firstSheet]], header = TRUE, as.data.frame = T, trim = TRUE,stringsAsFactors=T)#
		return(dat)	#
	}#
	gdd_calculate = function(weather,max_threshold,min_threshold){#
		#assumes input array starts at plant date,#
		dailyGDD = matrix(ncol=1,apply(weather,1,function(temp){#
			(((max(min_threshold,min(max_threshold,as.numeric(temp["t_max"])))+min(max_threshold,max(min_threshold,as.numeric(temp["t_min"])))))/2)-min_threshold#
		}))#
		cumulativeGDD = cumsum(dailyGDD)#
		output = cbind(dailyGDD,cumulativeGDD)#
		colnames(output) = c("Daily","Cumulative")#
		return(output)#
	}#
	get_average_weather = function(weather,plantDate){#
		thisYear = format(plantDate,"%Y")#
		saveColNames = colnames(weather)#
		weather[,"date"] = paste(format(as.Date(weather[,"date"]),"%m"),"-",format(as.Date(weather[,"date"]),"%d"),sep="")#
		output = by(weather,weather[,"date"],function(x){#
			return(as.data.frame(matrix(nrow=1,c(x[1,1],x[1,2],paste(thisYear,"-",x[1,3],sep=""),mean(x[,4],na.rm=T),mean(x[,5],na.rm=T),mean(x[,6],na.rm=T))),stringsAsFactors=F))#
		})#
		output = do.call("rbind",output)#
		output[,4] = as.numeric(output[,4])#
		output[,5] = as.numeric(output[,5])#
		output[,6] = as.numeric(output[,6])#
		output = output[which(as.Date(output[,3])>=plantDate),]#
		colnames(output) = saveColNames#
		return(output)#
	}#
	setwd("~/Desktop/aeolus_scripts/gddGetter")#
	cornDatesRaw = read.csv("Input/corn_imaging_periods.csv",stringsAsFactors=F)#
	ENV = fromJSON(file="environment_variables.json")#
	driveAuthUser  = ENV[["FROM"]]    #
	driveAuthSecret = ENV[["DRIVE"]]     #
	current_imaging_orders = c()#
	current_imaging_orders = grabClientImageOrder(driveAuthUser ,driveAuthSecret )#
	db = dbConnect(MySQL(), user=ENV[["USER"]],password=ENV[["PASSWD"]],dbname=ENV[["DB"]],host=ENV[["HOST"]])#
	query = paste("SELECT fieldID,name,defaultLatitude,defaultLongitude,planting_date from fields where defaultLatitude != 'NULL' AND is_active ='1' AND planting_date != 'NULL'")#
	rs = dbSendQuery(db, query)#
	allFields = fetch(rs, n=-1)#
	fullOutput = c()#
	stageList = c()#
	getDistances = function(source,targets,threshold){#
		temp=((source[1]-targets[,1])^2+(source[2]-targets[,2])^2)^.5#
		if(any(temp>threshold)){#
			return(F)#
		}else{#
			return(T)#
		}#
	}#
	#create clusters such that all points are within .5 lat/lng of a center#
	centers = nrow(allFields)#
	fieldCenters = allFields[,c("defaultLongitude","defaultLatitude")]#
	allFieldsIds = allFields[,c("fieldID")]#
	#fieldCenters = fieldCenters[duplicated(fieldCenters)==F,]#
	rownames(fieldCenters) = 1:nrow(fieldCenters)#
	numCentersStart = floor(nrow(fieldCenters)/10)#
	while(T){#
		kMeanResult = kmeans(fieldCenters,numCentersStart)#
		kMeanCenters = kMeanResult$centers#
		rownames(kMeanCenters) = c(1:nrow(kMeanCenters))#
		allDistances = c()#
		for(i in 1:nrow(kMeanCenters)){#
				returnVal = getDistances(kMeanCenters[i,],fieldCenters[as.numeric(names(kMeanResult$cluster[which(kMeanResult$cluster==i)])),],.7)#
				allDistances = c(allDistances,returnVal)#
		}#
		if(all(allDistances)) break#
		numCentersStart = numCentersStart+2#
		numCentersStart = min(numCentersStart,nrow(fieldCenters))#
	}#
	#plot(kMeanResult$centers,xlim=c(-100,-85),ylim=c(38,47),col="red")#
	#par(new=T)#
	#plot(	fieldCenters ,xlim=c(-100,-85),ylim=c(38,47),col="blue")#
	#ok that is prb fine, now make a lit to map forecast nodes to fieldIDs#
	#weatherNodeList = list()#
	#for(k in 1:nrow(kMeanResult$centers)){#
	#	weatherNodeList[[k]] = list("centers"=kMeanResult$centers[k,],"fieldIDs"=allFieldsIds[as.numeric(names(kMeanResult$cluster[which(kMeanResult$cluster==k)]))]		#
	#}#
	weatherNodeMapping=matrix(ncol=4,nrow=length(allFieldsIds))#
	weatherNodeMapping[,1]=allFieldsIds#
	weatherNodeMapping[,2] = as.numeric(as.character(kMeanResult$cluster))#
	for(z in 1:nrow(weatherNodeMapping)){#
		weatherNodeMapping[z,3:4] = kMeanCenters[weatherNodeMapping[z,2],]#
	}#
	colnames(weatherNodeMapping) = c("fieldID","weatherNodeID","defaultLongitude","defaultLatitude")#
	#dont really want to store all these#
	weatherNodeMapping=weatherNodeMapping[order(weatherNodeMapping[,2]),]#
	#allFields[order(allFields),]#
	allFields$fieldID = factor(allFields$fieldID, levels = weatherNodeMapping[,1])#
#
	allFields = allFields[order(allFields$fieldID),]#
	allFields[,"fieldID"] = as.numeric(as.character(allFields[,"fieldID"]))#
	lastNode =-99#
	weatherForecastScrape = NULL
currentDate = Sys.Date()
currentDate = as.Date(commandArgs(trailingOnly=T)[[1]])#
	setwd("~/Desktop/aeolus_scripts/gddGetter")#
	unlink("ImagingPackagesLookup/*")#
	source('Scripts/createImagingPackage.R')#
	source('Scripts/parseCloudCoverXML.R')#
	list.of.packages = c("RMySQL","mailR","maptools","RColorBrewer","sp","rgeos","rjson","XML")#
	new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]#
	if(length(new.packages)) install.packages(new.packages,repos="http://cran.rstudio.com/")#
	library(RMySQL)#
	library(mailR)#
	library(maptools)#
	library(sp)#
	library(RColorBrewer)#
	library(rgeos)#
	library(rjson)#
	library(XML)#
	setwd("~/Desktop/aeolus_scripts/gddGetter/Output")#
	removeOldFiles = list.files()#
	for(eachFile in removeOldFiles){#
		unlink(eachFile)#
	}#
	grabClientImageOrder = function(driveAuthUser ,driveAuthSecret ){#
		list.of.packages = c("devtools")	#
		new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]#
		if(length(new.packages)) install.packages(new.packages,repos="http://cran.rstudio.com/")#
		library(devtools)#
		list.of.packages = c("RGoogleDocs")#
		if(length(new.packages)) {#
			install_github("RGoogleDocs", "duncantl")#
		}#
		library(RGoogleDocs)#
		ts = getWorksheets("ClientImagingPackages22", con = getGoogleDocsConnection(getGoogleAuth(driveAuthUser, driveAuthSecret,"wise")))#
		allSheets = names(ts)#
		#then split out GDDs, and find the most recent date available#
		#get the most recent, assuming the formatting is always month-day fro the current year#
		firstSheet = allSheets[1]#
		dat = sheetAsMatrix(ts[[firstSheet]], header = TRUE, as.data.frame = T, trim = TRUE,stringsAsFactors=T)#
		return(dat)	#
	}#
	gdd_calculate = function(weather,max_threshold,min_threshold){#
		#assumes input array starts at plant date,#
		dailyGDD = matrix(ncol=1,apply(weather,1,function(temp){#
			(((max(min_threshold,min(max_threshold,as.numeric(temp["t_max"])))+min(max_threshold,max(min_threshold,as.numeric(temp["t_min"])))))/2)-min_threshold#
		}))#
		cumulativeGDD = cumsum(dailyGDD)#
		output = cbind(dailyGDD,cumulativeGDD)#
		colnames(output) = c("Daily","Cumulative")#
		return(output)#
	}#
	get_average_weather = function(weather,plantDate){#
		thisYear = format(plantDate,"%Y")#
		saveColNames = colnames(weather)#
		weather[,"date"] = paste(format(as.Date(weather[,"date"]),"%m"),"-",format(as.Date(weather[,"date"]),"%d"),sep="")#
		output = by(weather,weather[,"date"],function(x){#
			return(as.data.frame(matrix(nrow=1,c(x[1,1],x[1,2],paste(thisYear,"-",x[1,3],sep=""),mean(x[,4],na.rm=T),mean(x[,5],na.rm=T),mean(x[,6],na.rm=T))),stringsAsFactors=F))#
		})#
		output = do.call("rbind",output)#
		output[,4] = as.numeric(output[,4])#
		output[,5] = as.numeric(output[,5])#
		output[,6] = as.numeric(output[,6])#
		output = output[which(as.Date(output[,3])>=plantDate),]#
		colnames(output) = saveColNames#
		return(output)#
	}#
	setwd("~/Desktop/aeolus_scripts/gddGetter")#
	cornDatesRaw = read.csv("Input/corn_imaging_periods.csv",stringsAsFactors=F)#
	ENV = fromJSON(file="environment_variables.json")#
	driveAuthUser  = ENV[["FROM"]]    #
	driveAuthSecret = ENV[["DRIVE"]]     #
	current_imaging_orders = c()#
	current_imaging_orders = grabClientImageOrder(driveAuthUser ,driveAuthSecret )#
	db = dbConnect(MySQL(), user=ENV[["USER"]],password=ENV[["PASSWD"]],dbname=ENV[["DB"]],host=ENV[["HOST"]])#
	query = paste("SELECT fieldID,name,defaultLatitude,defaultLongitude,planting_date from fields where defaultLatitude != 'NULL' AND is_active ='1' AND planting_date != 'NULL'")#
	rs = dbSendQuery(db, query)#
	allFields = fetch(rs, n=-1)#
	fullOutput = c()#
	stageList = c()#
	getDistances = function(source,targets,threshold){#
		temp=((source[1]-targets[,1])^2+(source[2]-targets[,2])^2)^.5#
		if(any(temp>threshold)){#
			return(F)#
		}else{#
			return(T)#
		}#
	}#
	#create clusters such that all points are within .5 lat/lng of a center#
	centers = nrow(allFields)#
	fieldCenters = allFields[,c("defaultLongitude","defaultLatitude")]#
	allFieldsIds = allFields[,c("fieldID")]#
	#fieldCenters = fieldCenters[duplicated(fieldCenters)==F,]#
	rownames(fieldCenters) = 1:nrow(fieldCenters)#
	numCentersStart = floor(nrow(fieldCenters)/10)#
	while(T){#
		kMeanResult = kmeans(fieldCenters,numCentersStart)#
		kMeanCenters = kMeanResult$centers#
		rownames(kMeanCenters) = c(1:nrow(kMeanCenters))#
		allDistances = c()#
		for(i in 1:nrow(kMeanCenters)){#
				returnVal = getDistances(kMeanCenters[i,],fieldCenters[as.numeric(names(kMeanResult$cluster[which(kMeanResult$cluster==i)])),],.7)#
				allDistances = c(allDistances,returnVal)#
		}#
		if(all(allDistances)) break#
		numCentersStart = numCentersStart+2#
		numCentersStart = min(numCentersStart,nrow(fieldCenters))#
	}#
	#plot(kMeanResult$centers,xlim=c(-100,-85),ylim=c(38,47),col="red")#
	#par(new=T)#
	#plot(	fieldCenters ,xlim=c(-100,-85),ylim=c(38,47),col="blue")#
	#ok that is prb fine, now make a lit to map forecast nodes to fieldIDs#
	#weatherNodeList = list()#
	#for(k in 1:nrow(kMeanResult$centers)){#
	#	weatherNodeList[[k]] = list("centers"=kMeanResult$centers[k,],"fieldIDs"=allFieldsIds[as.numeric(names(kMeanResult$cluster[which(kMeanResult$cluster==k)]))]		#
	#}#
	weatherNodeMapping=matrix(ncol=4,nrow=length(allFieldsIds))#
	weatherNodeMapping[,1]=allFieldsIds#
	weatherNodeMapping[,2] = as.numeric(as.character(kMeanResult$cluster))#
	for(z in 1:nrow(weatherNodeMapping)){#
		weatherNodeMapping[z,3:4] = kMeanCenters[weatherNodeMapping[z,2],]#
	}#
	colnames(weatherNodeMapping) = c("fieldID","weatherNodeID","defaultLongitude","defaultLatitude")#
	#dont really want to store all these#
	weatherNodeMapping=weatherNodeMapping[order(weatherNodeMapping[,2]),]#
	#allFields[order(allFields),]#
	allFields$fieldID = factor(allFields$fieldID, levels = weatherNodeMapping[,1])#
#
	allFields = allFields[order(allFields$fieldID),]#
	allFields[,"fieldID"] = as.numeric(as.character(allFields[,"fieldID"]))#
	lastNode =-99#
	weatherForecastScrape = NULL
ENV
currentDate = as.Date(commandArgs(trailingOnly=T)[[1]])#
	setwd("~/Desktop/aeolus_scripts/gddGetter")#
	unlink("ImagingPackagesLookup/*")#
	source('Scripts/createImagingPackage.R')#
	source('Scripts/parseCloudCoverXML.R')
getwd()
list.of.packages = c("devtools","rjson","RMySQL")#
#
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]#
if(length(new.packages)) install.packages(new.packages,repos="http://cran.rstudio.com/")#
library(devtools)#
#
list.of.packages = c("RGoogleDocs")#
if(length(new.packages)) {#
	install_github("RGoogleDocs", "duncantl")#
}#
#
library(RGoogleDocs)#
library(rjson)	#
library(RMySQL)#
#
ENV = fromJSON(file="environment_variables.json")#
driveAuthUser  = ENV[["FROM"]]    #
driveAuthSecret = ENV[["DRIVE"]]
db = dbConnect(MySQL(), user=ENV[["USER"]],password=ENV[["PASSWD"]],dbname=ENV[["DB"]],host=ENV[["HOST"]])#
#
query = paste("Select name,clientID from clients")#
rs = dbSendQuery(db, query)#
data= fetch(rs, n=-1)#
allPackages = list()#
allPackages[["6-Image"]] =  c("First Vegetative","Second Vegetative","Third Vegetative","Fourth Vegetative","Fifth Vegetative","Sixth Vegetative")#
allPackages[["3-Image"]] =  c("Second Vegetative","Fourth Vegetative","Sixth Vegetative")#
allPackages[["Stand-Count-Special"]] = c("Stand Count","Third Vegetative","Fifth Vegetative")
con = getGoogleDocsConnection(getGoogleAuth(driveAuthUser, driveAuthSecret ))#
docs = getDocs(con)#
#
trickShit = getWorksheets("Trick Shit (Field Exception Imaging Package)", con = getGoogleDocsConnection(getGoogleAuth(driveAuthUser, driveAuthSecret ,"wise")))#
allSheets = names(trickShit )#
#then split out GDDs, and find the most recent date available#
#get the most recent, assuming the formatting is always month-day fro the current year#
firstSheet = allSheets[1]#
trickShit = sheetAsMatrix(trickShit [[firstSheet]], header = TRUE, as.data.frame = T, trim = TRUE,stringsAsFactors=F)
driveAuthUser  = ENV[["FROM"]]    #
driveAuthSecret = ENV[["DRIVE"]]
driveAuthUser
driveAuthSecret
data
query = paste("Select name,clientID from clients")#
rs = dbSendQuery(db, query)#
data= fetch(rs, n=-1)#
allPackages = list()#
allPackages[["6-Image"]] =  c("First Vegetative","Second Vegetative","Third Vegetative","Fourth Vegetative","Fifth Vegetative","Sixth Vegetative")#
allPackages[["3-Image"]] =  c("Second Vegetative","Fourth Vegetative","Sixth Vegetative")#
allPackages[["Stand-Count-Special"]] = c("Stand Count","Third Vegetative","Fifth Vegetative")#
#
con = getGoogleDocsConnection(getGoogleAuth(driveAuthUser, driveAuthSecret ))#
docs = getDocs(con)
getGoogleAuth(driveAuthUser, driveAuthSecret )
library(RGoogleDocs)
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]#
if(length(new.packages)) install.packages(new.packages,repos="http://cran.rstudio.com/")#
library(devtools)#
#
list.of.packages = c("RGoogleDocs")#
if(length(new.packages)) {#
	install_github("RGoogleDocs", "duncantl")#
}
library(RGoogleDocs)#
library(rjson)	#
library(RMySQL)#
#
ENV = fromJSON(file="environment_variables.json")#
driveAuthUser  = ENV[["FROM"]]    #
driveAuthSecret = ENV[["DRIVE"]]     #
#
db = dbConnect(MySQL(), user=ENV[["USER"]],password=ENV[["PASSWD"]],dbname=ENV[["DB"]],host=ENV[["HOST"]])#
#
query = paste("Select name,clientID from clients")#
rs = dbSendQuery(db, query)#
data= fetch(rs, n=-1)
data
allPackages = list()#
allPackages[["6-Image"]] =  c("First Vegetative","Second Vegetative","Third Vegetative","Fourth Vegetative","Fifth Vegetative","Sixth Vegetative")#
allPackages[["3-Image"]] =  c("Second Vegetative","Fourth Vegetative","Sixth Vegetative")#
allPackages[["Stand-Count-Special"]] = c("Stand Count","Third Vegetative","Fifth Vegetative")
allPackages
con = getGoogleDocsConnection(getGoogleAuth(driveAuthUser, driveAuthSecret ))#
docs = getDocs(con)
list.of.packages = c("RMySQL","mailR","maptools","RColorBrewer","sp","rgeos","rjson","XML")#
	new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]#
	if(length(new.packages)) install.packages(new.packages,repos="http://cran.rstudio.com/")#
	library(RMySQL)#
	library(mailR)#
	library(maptools)#
	library(sp)#
	library(RColorBrewer)#
	library(rgeos)#
	library(rjson)#
	library(XML)#
	setwd("~/Desktop/aeolus_scripts/gddGetter/Output")#
	removeOldFiles = list.files()#
	for(eachFile in removeOldFiles){#
		unlink(eachFile)#
	}
grabClientImageOrder = function(driveAuthUser ,driveAuthSecret ){#
		list.of.packages = c("devtools")	#
		new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]#
		if(length(new.packages)) install.packages(new.packages,repos="http://cran.rstudio.com/")#
		library(devtools)#
		list.of.packages = c("RGoogleDocs")#
		if(length(new.packages)) {#
			install_github("RGoogleDocs", "duncantl")#
		}#
		library(RGoogleDocs)#
		ts = getWorksheets("ClientImagingPackages22", con = getGoogleDocsConnection(getGoogleAuth(driveAuthUser, driveAuthSecret,"wise")))#
		allSheets = names(ts)#
		#then split out GDDs, and find the most recent date available#
		#get the most recent, assuming the formatting is always month-day fro the current year#
		firstSheet = allSheets[1]#
		dat = sheetAsMatrix(ts[[firstSheet]], header = TRUE, as.data.frame = T, trim = TRUE,stringsAsFactors=T)#
		return(dat)	#
	}#
	gdd_calculate = function(weather,max_threshold,min_threshold){#
		#assumes input array starts at plant date,#
		dailyGDD = matrix(ncol=1,apply(weather,1,function(temp){#
			(((max(min_threshold,min(max_threshold,as.numeric(temp["t_max"])))+min(max_threshold,max(min_threshold,as.numeric(temp["t_min"])))))/2)-min_threshold#
		}))#
		cumulativeGDD = cumsum(dailyGDD)#
		output = cbind(dailyGDD,cumulativeGDD)#
		colnames(output) = c("Daily","Cumulative")#
		return(output)#
	}#
	get_average_weather = function(weather,plantDate){#
		thisYear = format(plantDate,"%Y")#
		saveColNames = colnames(weather)#
		weather[,"date"] = paste(format(as.Date(weather[,"date"]),"%m"),"-",format(as.Date(weather[,"date"]),"%d"),sep="")#
		output = by(weather,weather[,"date"],function(x){#
			return(as.data.frame(matrix(nrow=1,c(x[1,1],x[1,2],paste(thisYear,"-",x[1,3],sep=""),mean(x[,4],na.rm=T),mean(x[,5],na.rm=T),mean(x[,6],na.rm=T))),stringsAsFactors=F))#
		})#
		output = do.call("rbind",output)#
		output[,4] = as.numeric(output[,4])#
		output[,5] = as.numeric(output[,5])#
		output[,6] = as.numeric(output[,6])#
		output = output[which(as.Date(output[,3])>=plantDate),]#
		colnames(output) = saveColNames#
		return(output)#
	}#
	setwd("~/Desktop/aeolus_scripts/gddGetter")#
	cornDatesRaw = read.csv("Input/corn_imaging_periods.csv",stringsAsFactors=F)#
	ENV = fromJSON(file="environment_variables.json")#
	driveAuthUser  = ENV[["FROM"]]    #
	driveAuthSecret = ENV[["DRIVE"]]     #
	current_imaging_orders = c()#
	current_imaging_orders = grabClientImageOrder(driveAuthUser ,driveAuthSecret )
currentDate = as.Date(commandArgs(trailingOnly=T)[[1]])#
	setwd("~/Desktop/aeolus_scripts/gddGetter")#
	unlink("ImagingPackagesLookup/*")#
	source('Scripts/createImagingPackage.R')#
	source('Scripts/parseCloudCoverXML.R')
ENV
